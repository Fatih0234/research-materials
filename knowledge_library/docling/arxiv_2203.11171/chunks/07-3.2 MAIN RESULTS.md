## 3.2 MAIN RESULTS

We report the results of self-consistency averaged over 10 runs, where we sampled 40 outputs independently from the decoder in each run. The baseline we compare to is chain-of-thought prompting with greedy decoding (Wei et al., 2022), referred to as CoT-prompting , which has been previously used for decoding in large language models (Chowdhery et al., 2022).

Arithmetic Reasoning The results are shown in Table 2. 7 Self-consistency improves the arithmetic reasoning performance over all four language models significantly over chain-of-thought prompting. More surprisingly, the gains become more significant when the language model's scale increases, e.g., we see +3%-6% absolute accuracy improvement over UL2-20B but +9%-23% for LaMDA137B and GPT-3. For larger models that already achieve high accuracy on most tasks (e.g., GPT-3 and PaLM-540B), self-consistency still contributes significant additional gains with +12%-18% absolute accuracy on tasks like AQuA and GSM8K, and +7%-11% on SVAMP and ASDiv. With self-consistency, we achieve new state-of-the-art results on almost all tasks: despite the fact that selfconsistency is unsupervised and task-agnostic, these results compare favorably to existing approaches that require task-specific training, or fine-tuning with thousands of examples (e.g., on GSM8K).

Table 2: Arithmetic reasoning accuracy by self-consistency compared to chain-of-thought prompting (Wei et al., 2022). The previous SoTA baselines are obtained from: a : Relevance and LCA operation classifier (Roy &amp; Roth, 2015), b : Lan et al. (2021), c : Amini et al. (2019), d : Pi et al. (2022), e : GPT-3 175B finetuned with 7.5k examples (Cobbe et al., 2021), g : GPT-3 175B finetuned plus an additional 175B verifier (Cobbe et al., 2021). The best performance for each task is shown in bold.

|                        | Method                         | AddSub            | MultiArith        | ASDiv            | AQuA              | SVAMP             | GSM8K             |
|------------------------|--------------------------------|-------------------|-------------------|------------------|-------------------|-------------------|-------------------|
|                        | Previous SoTA                  | 94.9 a            | 60.5 a            | 75.3 b           | 37.9 c            | 57.4 d            | 35 e / 55 g       |
| UL2-20B                | CoT-prompting Self-consistency | 18.2 24.8 (+6.6)  | 10.7 15.0 (+4.3)  | 16.9 21.5 (+4.6) | 23.6 26.9 (+3.3)  | 12.6 19.4 (+6.8)  | 4.1 7.3 (+3.2)    |
| LaMDA-137B             | CoT-prompting Self-consistency | 52.9 63.5 (+10.6) | 51.8 75.7 (+23.9) | 49.0 58.2 (+9.2) | 17.7 26.8 (+9.1)  | 38.9 53.3 (+14.4) | 17.1 27.7 (+10.6) |
| PaLM-540B              | CoT-prompting Self-consistency | 91.9 93.7 (+1.8)  | 94.7 99.3 (+4.6)  | 74.0 81.9 (+7.9) | 35.8 48.3 (+12.5) | 79.0 86.6 (+7.6)  | 56.5 74.4 (+17.9) |
| GPT-3 Code-davinci-001 | CoT-prompting Self-consistency | 57.2 67.8 (+10.6) | 59.5 82.7 (+23.2) | 52.7 61.9 (+9.2) | 18.9 25.6 (+6.7)  | 39.8 54.5 (+14.7) | 14.6 23.4 (+8.8)  |
| GPT-3 Code-davinci-002 | CoT-prompting Self-consistency | 89.4 91.6 (+2.2)  | 96.2 100.0 (+3.8) | 80.1 87.8 (+7.6) | 39.8 52.0 (+12.2) | 75.8 86.8 (+11.0) | 60.1 78.0 (+17.9) |

Table 3: Commonsense and symbolic reasoning accuracy by self-consistency compared to chainof-thought prompting (Wei et al., 2022). The previous SoTA baselines are obtained from: a : DeBERTaV3-large + KEAR (Xu et al., 2021b), b : Chowdhery et al. (2022), c : UnifiedQA-FT (Khashabi et al., 2020). The best performance for each task is shown in bold.

|                        | Method                         | CSQA             | StrategyQA       | ARC-e            | ARC-c             | Letter (4)       | Coinflip (4)     |
|------------------------|--------------------------------|------------------|------------------|------------------|-------------------|------------------|------------------|
|                        | Previous SoTA                  | 91.2 a           | 73.9 b           | 86.4 c           | 75.0 c            | N/A              | N/A              |
| UL2-20B                | CoT-prompting Self-consistency | 51.4 55.7 (+4.3) | 53.3 54.9 (+1.6) | 61.6 69.8 (+8.2) | 42.9 49.5 (+6.8)  | 0.0 0.0 (+0.0)   | 50.4 50.5 (+0.1) |
| LaMDA-137B             | CoT-prompting Self-consistency | 57.9 63.1 (+5.2) | 65.4 67.8 (+2.4) | 75.3 79.3 (+4.0) | 55.1 59.8 (+4.7)  | 8.2 8.2 (+0.0)   | 72.4 73.5 (+1.1) |
| PaLM-540B              | CoT-prompting Self-consistency | 79.0 80.7 (+1.7) | 75.3 81.6 (+6.3) | 95.3 96.4 (+1.1) | 85.2 88.7 (+3.5)  | 65.8 70.8 (+5.0) | 88.2 91.2 (+3.0) |
| GPT-3 Code-davinci-001 | CoT-prompting Self-consistency | 46.6 54.9 (+8.3) | 56.7 61.7 (+5.0) | 63.1 72.1 (+9.0) | 43.1 53.7 (+10.6) | 7.8 10.0 (+2.2)  | 71.4 75.9 (+4.5) |
| GPT-3                  | CoT-prompting Self-consistency | 79.0 81.5 (+2.5) | 73.4 (+6.4)      | 94.0 96.0 (+2.0) | 87.5 (+3.9)       | 73.4 (+3.0)      | 99.0 99.5 (+0.5) |
| Code-davinci-002       |                                |                  | 79.8             |                  | 83.6              | 70.4             |                  |

7 The standard deviation of self-consistency is â‰¤ 0 . 5 for all tasks and is thus omitted in the table. Please refer to Figure 2, Figure 7 and 8 for the standard deviations under varying numbers of sampled paths.

Commonsense and Symbolic Reasoning Table 3 shows the results on commonsense and symbolic reasoning tasks. Similarly, self-consistency yields large gains across all four language models, and obtained SoTA results on 5 out of 6 tasks. For symbolic reasoning, we test the out-of-distribution (OOD) setting where the input prompt contains examples of 2-letters or 2-flips but we test examples of 4-letters and 4-flips (this setting is more challenging as PaLM-540B or GPT-3 can already achieve perfect in-distribution accuracy). In this challenging OOD setting, the gain of self-consistency is still quite significant compared to CoT-prompting with sufficient model sizes.

To show the effect of the number of sampled reasoning paths, we plot the accuracy (mean and standard deviation over 10 runs) with respect to varying numbers of sampled paths (1, 5, 10, 20, 40) in Figure 2. The results show that sampling a higher number (e.g., 40) of reasoning paths leads to a consistently better performance, further emphasizing the importance of introducing diversity in the reasoning paths. In Table 4, we show self-consistency yields a richer set of reasoning paths compared to greedy decoding with a few example questions from two tasks.

Figure 2: Self-consistency (blue) significantly improves accuracy over CoT-prompting with greedy decoding (orange) across arithmetic and commonsense reasoning tasks, over LaMDA-137B. Sampling a higher number of diverse reasoning paths consistently improves reasoning accuracy.

<!-- image -->

Table 4: Examples where self-consistency helps repair the errors over greedy decode, on PaLM-540B. Two sampled reasoning paths that are consistent with the ground truth are shown.

|                | GSM8K                                                                                                                                                                                                                                                                                                                           | StrategyQA                                                                                                                                                                          |
|----------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Question       | Henry made two stops during his 60-mile bike trip. He first stopped after 20 miles. His second stop was 15 miles before the end of the trip. How many miles did he travel between his first and second stops?                                                                                                                   | Yes or no: Is Albany, Georgia the most populous US Albany?                                                                                                                          |
| Greedy Decode  | He traveled 60 miles in total. He stopped after 20 miles, so he traveled 60 - 20 = 40 miles between the first and second stops. The answer is 40.                                                                                                                                                                               | Albany, Georgia is the most populous US Al- bany. Thus, the answer is yes.                                                                                                          |
| Sampled Path 1 | Henry travelled a total of 60 miles. His first stop was 20 miles in, and his second stop was 15 miles before the end. So between his first and second stops he travelled 60 - 20 -15 = 25 miles. The answer is 25.                                                                                                              | The most populous US Albany is Albany, New York. Thus, Albany, Georgia is not the most populous US Albany. So the answer is no.                                                     |
| Sampled Path 2 | He made two stops during a 60-mile trip. The first was 20 miles into the trip. The second was 15 miles before the end of the trip. This means the second stop was 60 - 15 = 45 miles into the trip. Since he made the stops in order, the second stop must have been 45 - 20 = 25 miles after the first stop. The answer is 25. | Albany, Georgia has a population of about 88,000. Albany, New York has a population of about 95,000. Thus, Albany, Georgia is not the most populous US Albany. So the answer is no. |
