## Abstract

Newly-developed large language models (LLM)-because of how they are trained and designed-are implicit computational models of humans-a homo silicus . LLMs can be used like economists use homo economicus : they can be given endowments, information, preferences, and so on, and then their behavior can be explored in scenarios via simulation. Experiments using this approach, derived from Charness and Rabin (2002), Kahneman, Knetsch and Thaler (1986), and Samuelson and Zeckhauser (1988) show qualitatively similar results to the original, but it is also easy to try variations for fresh insights. LLMs could allow researchers to pilot studies via simulation first, searching for novel social science insights to test in the real world.

âˆ— Thanks to the MIT Center for Collective Intelligence for generous offer of funding, though all the experiments here cost only about $ 50 to run. Thanks to Daniel Rock, Elliot Lipnowski, Hong-Yi TuYe, Daron Acemoglu, Shakked Noy, Jimbo Brand, David Autor, and Mohammed Alsobay for their helpful conversations and comments. Special thanks to Yo Shavit, who has been extremely generous with his time and thinking. Thanks to GPT-3 for all this work and helping me describe the technology. Author contact information, code, and data are currently or will be available at http://www.john-joseph-horton.com/ .
