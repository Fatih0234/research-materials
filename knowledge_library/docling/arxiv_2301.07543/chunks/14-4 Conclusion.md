## 4 Conclusion

This paper reports the results of several experiments using GPT3 AIs as experimental subjects. The main conclusion is that this approach seems promising: it can qualitatively recover findings from experiments with actual humans. Furthermore, it can do this remarkably cheaply: Because of this low cost, it is feasible to try numerous variations of wording, prompts,

answer order, and so on. Sample sizes can be arbitrarily large. There are no human subjects related ethical concerns with running these experiments (Kessler, Low and Sullivan, 2019).

In traditional experimental work, there is a concern about researchers data-mining on experimental results to find 'significant' findings. A partial solution is pre-registration. This is not likely to work for AI experiments. The fixed cost of doing an experiment makes a registry work, incentive-wise, but when it costs $ 1 and 30 seconds to run an experiment, it is hard to see what the benefit would be. The more realistic option would be a norm of these experiments being 'push button' reproducible where one can fork a repository, replace API keys, and re-run. This will allow people to verify if results are sensitive to slight differences in framing. In terms of reproducible research, the data from these experiments can always be released. One issue is that OpenAI-or any other LLM provider-is under no obligation to continue offering access to any particular model. However, these experiments could be redone with new AIs as they become available. Consider that no lab experiment comes with the guarantee that the same humans will later be available for your replication.
