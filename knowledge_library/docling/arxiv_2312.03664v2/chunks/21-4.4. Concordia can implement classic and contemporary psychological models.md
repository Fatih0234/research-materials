## 4.4. Concordia can implement classic and contemporary psychological models

Many influential psychological models have distinguished between more associative and more deliberative processes for decision-making (e.g. Dayan (2009); Kahneman et al. (2002); Schneider and Shiffrin (1977)). Whereas implicitassociative processes learn the regularity of the world slowly for intuitive judgment, the explicitdeliberative processes are thought to be more linguistically mediated and allow for symbolic inference and faster learning in novel situations (Greenwald and Banaji (1995); Wilson et al. (2000)). Because the implicit-associative models are conceptually easy to model within connectionist or neural network frameworks (Smith (2009)), many ABMs have been more closely aligned with models of individual decision making that focus on its associative processes or the associative parts of complex models, and have neglected their more symbolic and deliberative aspects. Many of these more symbolic psychological models take an 'arrow and box' approach to theorizing which describe high level processes and transformations of information, and often posit sequential steps of information flow. Now using generative agents like Concordia such symbolic and deliberative aspects of cognition are also easy to capture in computational models.

Take for instance the ways that attitudes-preexisting beliefs and feelings about an object, person, or situation-guide behaviour. Whereas implicit attitudes are thought to quickly guide actions through the direct biasing of perception and behaviour, explicit attitudes are thought to guide behaviour through deliberation and con-

sideration of additional situational factors (Fazio (1990); Gawronski and Bodenhausen (2011); Olson and Fazio (2008)). One example model in which deliberative processes can guide behaviour is Ajzen (1991)'s theory of planned behavior. This model holds that the tendency to emit a particular behavior is determined by an individual's attitude toward the behavior, norms related to the behavior, and perceived control over the behavior. This approach to decision-making is qualitatively different from an RL approach which slowly builds a policy that directly generates behavioral responses from states and contexts. In such a model, different questions regarding the agent's current state are queried as in Concordia components, and then integrated into a behavioural intent which serves like a plan. These operations can easily be described as Concordia components, with the appropriate inputs, transformations, and outputs described verbally. Such a scheme would be much harder or impossible to implement in a traditional neural network model of decision making.

To realize Ajzen (1991)'s theory using Concordia the following components could be built. The first component would generate a set of possible behaviours given the agent's current state. Then, this set of possible behaviours would be queried through a set of components that would evaluate each behavioral option. Specifically, one component would determine the agents attitudes towards the behavior ("do I have a positive or negative evaluation or feeling about [behavior]"), one component can determine the social or situational norms about the behavior "do I believe that most people approve or disapprove of [behavior]?," and finally a component would determine the agents perceived behavioral control to perform the behavior "how easy or difficult would it be for me to perform [behavior] right now and how likely would it be to succeed?". The outputs of these components would then be concatenated into the plan, serving as the behavioral intention for action. Thus, a sequence of modular processes can be organized to build a computational model of higher level cognition. Critically , an agent's decisions can be quickly shifted as it learns new information or considers new information in any of these components, leading to rapid and contex- tually appropriate changes in behavioral profiles.

Generative agents are not useful just for decision making models. As another example, psychological constructivist models assume that people have a set of psychological primitives that underlie cognition (akin to Concordia's components), but that people learn to conceptualize their experiences and mental states to build useful categories for behavior. In the emotion domain, this perspective suggests that emotions like "fear" and "anger" are not psychological primitives, but rather come about though people's constructed categorization of their body and mental states (Barrett (2006)). Indeed, several of these models suggest that conceptualization is a necessary component for the generation of discrete emotion representations for understanding oneself or others (Barrett (2014)). To the extent that conceptualization is linguistically mediated, a Concordia agent can relatively easily generate emotional categories that would be nearly impossible in a standard RL agent.

The modular nature of Concordia's component system offers a robust platform for empirically testing psychological hypotheses. This is accomplished by constructing agents whose psychological processes are intricately modeled after diverse cognitive frameworks. The agents may then be subjected to rigorously controlled experimental conditions, orchestrated by the game master. Such an approach allows for the systematic evaluation of models against empirical human data, serving as a benchmark for their algorithmic fidelity and psychological realism. Moreover, this system facilitates hypothesis generation through the simulation of different cognitive models in simulated experimental designs that can be validated on human participants.

Here we have mostly discussed the case of using an LLM as the generative engine for the agents. This could lead one to think these ideas are restricted to the language space, which would be a limitation if true. However, we could use any foundation model as the generative engine. In particular, multimodal foundation models capable of operating over images, sounds, or motor actuation could be used. Current multi-modal foundation models such as Li et al. (2023a) are

developing rapidly and promise the ability to both comprehend and generate data across domains. In the future Concordia models will be able to sample over an abstract token space, which can then be cast in any modality.
