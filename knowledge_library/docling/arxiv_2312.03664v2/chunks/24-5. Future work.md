## 5. Future work

Since there is no consensus at present concerning how to interpret results of LLM-based simulations of human populations, the future work will address the critical epistemic question: 'by what standard should we judge whether (and in what ways, and under which conditions) the results of in silico experiments are likely to generalize to the real world?'. These are not questions any one group of researchers can answer by themselves; rather these issues must be negotiated by the community as a whole. This is is why we release Concordia early and with only few examples. It is an invitation to the researchers from various fields that are interested in GABM to come onboard and participate in the creation of validating procedures, best practices, and epistemic norms.

We plan to add the following over the coming months:

1. New example environments
2. Integration with different LLMs to see which are more suitable for constructing GABMs (e.g., they act 'reasonably', are internally consistent, apply common sense, etc).
3. Improving agents-better associative memory, context-driven and dynamic component assemblage, tool use.
4. Visualisation and audit tools.
5. Snapshot-serializing and persisting the simulation at specific episode, to enable to later resumption and performance comparison of different approaches for a specific scenario.
6. Keyframes-conditioning the agent actions to be consistent with future key action or of narrative. This allow steering the simulation more granularly and addresses an inherent issue that is caused by the fact that there is no guarantee that due to the stochastic nature of GABMs, ongoing simulations might diverge from their intended topic.
