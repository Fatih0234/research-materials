## A.1. Agents

The agent class implements three methods:

1. .name() -returns the name of the agent, that is being referred to in the simulation. It is important that all agents have unique names;
2. .observe( observation: str) -a function to take in an observation;
3. .act( action spec) -returns the action (as a string), for example "Alice makes breakfast". The function takes in action spec, which specifies the type of output (free form, categorical, float) and the specific phrasing of the call to action . For example, the call to action could be 'what would Alice do in the next

8 here: https://github.com/google-deepmind/ concordia

hour?', in this case the answer type would be free form. Or it could be 'Would Alice eat steak for dinner?' with answer type of binary choice (yes / no).

The agent class constructor is parameterised by a list of components. The components of agent have to implement the following functions:

1. .state() -returns the state of the component ùëß ùëñ , for example "Alice is vegetarian";
2. .name() -returns the name of the components, for example "dietary preferences";
3. .update() -updates the state of the component by implementing; eq. (2). Optional, can pass for constant constructs;
4. .observe( observation: str) -takes in an observation, for later use during update. Optional. Observations always go into the memory anyway, but some components are easier to implement by directly subscribing to the observation stream.

During an episode , on each timestep, each agent calls .state() on all its components to construct the context of its next decision and implements eq. (1) (the components' states are concatenated in the order supplied to the agents' constructor). .observe() is called on each component whenever it receives observations, and .update() is called at regular intervals (configurable in the constructor). Unlike in RL, we do not assume that the agent will produce an action after every observation. Here the GM might call .observe() several times before it calls .act() .
