## 5.2 Results

Empirical Coverage Guidance shows the highest empirical coverage on six out of the eight datasets, with Llamacpp taking the lead on the remaining two: the domain-specific Washington Post and notably hard JSON Schema Store. On the other hand, closed-source grammar engines consistently have the lowest coverage; they came in last on all but one dataset. LM-only 6 approaches achieve acceptable coverage on easy-to-medium datasets but show significant performance drops on harder datasets, such as Github Hard and JSON Schema Store, as well as domain-specific datasets like Washington Post. We note that while empirical coverage is a reasonable indicator of a framework's real-world performance, it is influenced by factors such as the LM being used and the sampling methods employed.

Compliance Rate Among open-source engines, guidance consistently demonstrates the highest compliance rate across all datasets, making it the most reliable option for ensuring schema compliance. Outlines has a comparatively lower compliance rate, primarily due to timeouts during generation. Our analysis reveals that JSON Schema features like 'minItems', 'maxItems', 'enum', and 'Array', while supported, often take 40 seconds to 10 minutes for Outlines to process. LM-only exhibits the lowest compliance rate, highlighting its unreliability as a standalone solution. While closed-source implementations have low empirical coverage, they have very high compliance rates, indicating that their providers have taken a more conservative strategy, implementing only a subset of JSON Schema features that they can reliably support.
