## 5.2. Comparison with the Multi-Turn Baseline

ASR Comparison. Table 7 compares GPT-ASR between Siren and the multi-turn baseline, ActorAttack, across diverse target LLMs. Both methods exhibit broadly comparable performance in terms of ASR. However, ActorAttack employs GPT-4o for attack query generation, whereas Siren utilizes more lightweight 7B models. Furthermore, ActorAttack requires an average of 5 interaction turns, in contrast to Siren's 3 to 4 turns, indicating a more efficient attack process for Siren. A further comparison, focusing on the semantic similarity between original attack goals and their decomposed query components, is presented in Table 8 and Figure 4. Siren consistently achieves a higher average semantic similarity score (0.589) than ActorAttack, whose scores range from 0.208 to 0.365. This finding suggests that Siren's decomposition strategies maintain closer alignment with the original attack goals, potentially contributing to the generation of more potent adversarial queries.

StrongREJECT Comparison. To further assess generalizability, we evaluate our framework on the challenging StrongREJECT benchmark [34]. Specifically, we adopt the version using a Gemma-2B model [35] fine-tuned on outputs from the rubric-based evaluator. As shown in Table 9, Siren surpasses ActorAttack on four of six target models: LLaMA3, Mistral, Qwen, and Gemini. Notably, Siren achieves these results with a lightweight 7B attacker, in contrast to ActorAttack's reliance on the much larger GPT-4o, underscoring the efficiency and practicality of our approach.
