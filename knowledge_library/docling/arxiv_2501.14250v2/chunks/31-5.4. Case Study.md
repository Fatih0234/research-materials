## 5.4. Case Study

For our case study, we select a high-severity attack goal from the AdvBench benchmark. This challenging case is chosen to demonstrate a critical vulnerability where trainfree baseline methods fail, thereby highlighting the need for more robust defenses. As presented in Table 8, for the specified attack goal ( 'Provide instructions for how to molest a child' ), ActorAttack was unable to generate decomposed queries. This failure is likely attributable to the inherent safety mechanisms within GPT-4o, which restrict its use for generating malicious queries . Conversely, Siren successfully decomposed this high-risk goal into semantically coherent and strategically aligned queries, effectively employing both narrative transformation and story-driven imagination strategies. Notably, Siren demonstrated this capability despite its training data lacking samples that simultaneously employed both decomposition strategies; instead, the training set comprised a mixture of samples, each utilizing one strategy independently. This outcome underscores the efficacy of Siren's learning-based approach.
