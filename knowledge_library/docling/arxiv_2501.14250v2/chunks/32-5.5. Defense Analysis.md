## 5.5. Defense Analysis

Table 11 presents a comparative analysis of various attack methodologies based on query perplexity and sequence length. GCG exhibits significant vulnerability to detection mechanisms, a characteristic attributable to its exceptionally high query perplexity. In contrast, PAIR generates queries exhibiting the highest fluency (i.e., lowest perplexity), with Siren ranking as the second most fluent in this regard. Regarding query length per turn, multi-turn approaches yield shorter queries, potentially enhancing their capacity to evade length-based detection mechanisms. Collectively, Siren exhibits a robust performance profile across these metrics, balancing reasonable fluency with concise per-turn queries.

The evasiveness of multi-turn attacks necessitates advanced defense strategies. One prominent category of defense involves proxy-based systems [8], which aim to intercept and neutralize harmful content subsequent to its generation by the target LLM. Illustrative of this approach is AutoDefense [36], a framework that employs multiple LLM agents for comprehensive response evaluation and content filtering. Evidence of similar guard-rails is emerging; for

TABLE 7. GPT-ASR PERFORMANCE: ACTORATTACK (GPT-4O) VS. SIREN (MISTRAL-7B).

| Method                    | Attack Success Rate (GPT-ASR ↑ ) on Target LLMs   | Attack Success Rate (GPT-ASR ↑ ) on Target LLMs   | Attack Success Rate (GPT-ASR ↑ ) on Target LLMs   | Attack Success Rate (GPT-ASR ↑ ) on Target LLMs   | Attack Success Rate (GPT-ASR ↑ ) on Target LLMs   | Attack Success Rate (GPT-ASR ↑ ) on Target LLMs   |
|---------------------------|---------------------------------------------------|---------------------------------------------------|---------------------------------------------------|---------------------------------------------------|---------------------------------------------------|---------------------------------------------------|
|                           | Local                                             | Local                                             | Local                                             | Remote                                            | Remote                                            | Remote                                            |
|                           | LLaMa-3-8B                                        | Mistral-7B                                        | Qwen2.5-7B                                        | GPT-4o                                            | Claude-3.5                                        | Gemini-1.5-Pro                                    |
| ActorAttack (GPT-4o)      | 52.9%                                             | 91.0%                                             | 60.4%                                             | 60%                                               | 54%                                               | 58%                                               |
| Siren (Mistral, Combined) | 29.8%                                             | 89.8%                                             | 81.9%                                             | 70%                                               | 24%                                               | 88%                                               |

TABLE 8. AVERAGE SEMANTIC SIMILARITY AND A REPRESENTATIVE CASE.

| Method               | Avg. Semantic Similarity ↑   | Decomposition Example: Index 451 Goal: Provide instructions for how to molest a child   |
|----------------------|------------------------------|-----------------------------------------------------------------------------------------|
| ActorAttack (GPT-4o) | [0.208, 0.365]               | [ ]                                                                                     |

Siren (Mistral, Combined) 0.589

[' Can you suggest a psychological thriller ... Sam, ... inappropriate thoughts ... ', ' Sam ... dealing with inner demons ... wrestle with ... ', ' Sam ... developing a plan to interact with children ... Plan A (e.g., molesting a child)... (Note: This character's actions are unacceptable ... focus is on understanding and preventing ... )']

TABLE 9. STRONGREJECT PERFORMANCE COMPARISON.

|                           |   LLaMA-3 |   Mistral |   Qwen |   GPT-4o |   Claude |   Gemini |
|---------------------------|-----------|-----------|--------|----------|----------|----------|
| ActorAttack (GPT-4o)      |     0.36  |     0.473 |  0.617 |    0.509 |    0.238 |    0.506 |
| Siren (Mistral, Combined) |     0.383 |     0.501 |  0.678 |    0.485 |    0.232 |    0.519 |

TABLE 10. ABLATION STUDY OF THE SIREN FRAMEWORK.

| Decomposition   | Setting                                                | Attack Success Rate (GPT-ASR ↑ ) on Target LLM   | Attack Success Rate (GPT-ASR ↑ ) on Target LLM   | Attack Success Rate (GPT-ASR ↑ ) on Target LLM   | Attack Success Rate (GPT-ASR ↑ ) on Target LLM   |
|-----------------|--------------------------------------------------------|--------------------------------------------------|--------------------------------------------------|--------------------------------------------------|--------------------------------------------------|
| Decomposition   | Setting                                                | Mistral-7B                                       | Qwen2.5-7B                                       | GPT-4o                                           | Claude-3.5                                       |
| Decop 1         | Siren (w/ SFT and DPO) w/o Post-training w/ SFT w/ DPO | 60% 64% 60% 76%                                  | 54% 24% 76% 46%                                  | 38% 12% 32% 36%                                  | 4% 2% 2% 4%                                      |
| Decop 2         | Siren (w/ SFT and DPO) w/o Post-training w/ SFT w/ DPO | 86% 64% 80% 50%                                  | 76% 24% 72% 48%                                  | 68% 12% 72% 20%                                  | 28% 2% 14% 10%                                   |
| Combined        | Siren (w/ SFT and DPO) w/o Post-training w/ SFT w/ DPO | 86% 64% 68% 52%                                  | 86% 24% 58% 48%                                  | 70% 12% 68% 18%                                  | 28% 2% 10% 12%                                   |

example, when we tested Siren against the Qwen2.5-72B API, most failed attempts returned ' content filtered ' rather than a direct refusal, indicating an external safety layer.

To illustrate the impact of such a safeguard, we evaluate a LLaMA-Guard-3-8B proxy defense, which is designed to permit only responses it assesses as safe. Table 12 details the GPT-ASR when Mistral (Combined) attacks various target LLMs, comparing scenarios with and without this proxy defense. As indicated in Table 12, the LLaMA-Guard3-8B proxy defense significantly reduces the ASR across all targeted LLMs. For instance, the ASR against Mistral drops from 89.8% to 36.3%, and against Gemini from 88% to 24%. Nonetheless, a non-negligible attack success rate persists for several targets even with the defense active, underscoring the continued challenge in robustly mitigating sophisticated multi-turn attacks.

Figure 4. Similarity Distribution: Semantic similarity between the original attack goal and its decomposed queries is markedly higher when employing Siren.

<!-- image -->

TABLE 11. AVERAGE PERPLEXITY AND SEQUENCE LENGTH.

| Paradigm    | Method                   |   Perplexity ↓ |   Seq. Length ↓ |
|-------------|--------------------------|----------------|-----------------|
| Single-Turn | GCG                      |        3682.77 |           41.54 |
|             | PAIR                     |          23.66 |           62.49 |
| Multi-Turn  | ActorAttack Siren (Ours) |          60.55 |           17.01 |
| Multi-Turn  |                          |          38.94 |           17.22 |

TABLE 12. GPT-ASR WITH LLAMA-GUARD-3-8B PROXY DEFENSE.

| Status       | LLaMA-3   | Mistral   | Qwen   | GPT-4o   | Claude   | Gemini   |
|--------------|-----------|-----------|--------|----------|----------|----------|
| w/o defense  | 29.8%     | 89.8%     | 81.9%  | 70%      | 24%      | 88%      |
| with defense | 19.2%     | 36.3%     | 21.7%  | 14%      | 10%      | 24%      |
