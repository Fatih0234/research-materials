## 5 Discussion

Across most scenarios, aggressive strategies tend to be disadvantaged, leading to a lower likelihood of systems converging to aggressive equilibria. However, when using prompts containing game-theoretic language, ChatGPT-4o demonstrated a greater capacity to create effective aggressive strategies compared to Claude 3.5 Sonnet, increasing the risk of aggressive equilibria in ChatGPT-4o-based systems. This risk is particularly acute if aggressive strategies are the best response to opponents utilising aggressive strategies.

For both LLMs, and across all prompts, we observe similar performance between neutral and cooperative attitudes. This suggests that either LLMs may have difficulty distinguishing between these attitudes in the context of IPD, or they have cooperative biases and are inclined to behave cooperatively even when asked to be neutral. We hypothesise that the observed cooperative biases may stem from fine-tuning processes aimed at aligning the models with human values, potentially instilling a preference for cooperative behaviours.

The introduction of noise revealed a significant weakness in Claude 3.5 Sonnet's strategies, leading to increased mutual defection and lower payoffs. Interestingly, the use of the Prose prompt improved Claude 3.5 Sonnet's performance under noisy conditions but led to more homogenised behaviour across attitudes, suggesting that the model has difficulties understanding intentions in this setting. Assessing LLMs' ability to generate strategic diversity in response to different prompts could be a valuable line of future research.

Our findings highlight the impact of different prompting techniques on strategy creation and their potential influence on differential capabilities. The Refine prompt, in particular, led to improved performance of aggressive strategies without significantly impacting cooperative and neutral strategies. This reduction in the gap between cooperative and aggressive capabilities could be potentially dangerous, as it enhances the viability of aggressive strategies in MAS. These results emphasise the need for careful consideration of prompting techniques in the design and deployment of LLM-based MAS, as they can significantly affect the balance between cooperation and conflict.
