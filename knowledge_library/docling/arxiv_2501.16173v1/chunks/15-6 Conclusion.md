## 6 Conclusion

We introduced a novel approach to LLM game-play, namely creating strategies, rather than prompting LLMs to output individual actions. This methodology allows us to verify that the strategies demonstrate with their requested behaviours. By enabling users to inspect and test the generated strategies in advance of deployment, they are able to potentially reject the strategy, enhancing transparency and control.

We simulated MAS of LLM agents tasked with displaying aggressive, cooperative or neutral behaviours, and investigated their relative performance (Section 3.2). We modelled the evolution of the systems under competitive pressures by employing a Moran process (Section 3.4), wherein entrants into the system are predisposed to use strategies that have demonstrated greater success.

Our investigation into the strategic behaviour of LLM agents in the Iterated Prisoner's Dilemma reveals a nuanced landscape of cooperative tendencies and potential emergent dynamics. While we observed a general trend towards cooperative behaviours, our findings also highlight scenarios where aggressive strategies can persist or even dominate. This underscores the importance of careful model development, system design and the initial conditions when deploying autonomous agents.

A key finding of our study is the impact of prompting techniques on differential capabilities. In particular, prompting LLMs to critique and refine their strategies [Madaan et al. , 2023] led to improved performance of aggressive strategies without significantly impacting cooperative and neutral strategies. This reduction in the performance gap between cooperative and aggressive capabilities could be dangerous, as it increases the viability of aggressive strategies. Notably, ChatGPT-4o prompted using game-theoretic language with self-refinement demonstrated a significant risk of converging to aggressive equilibria, particularly when starting from a population with an initial majority of aggressive agents.

The choice of iterated Prisoner's Dilemma as the foundational game-theoretic framework offers several advantages: it provides a language for discussing and analysing LLM agent behaviour, and the body of existing research allows us to contextualise our results by benchmarking against classical human-written algorithms. This allows us to gain insights into the tendencies of LLM agents towards prosocial or antisocial behaviours in more complex, real-world scenarios.

Werelease our benchmark to equip the AI community with a practical tool for model testing. As new generative models are released, we can repeat the analysis to determine whether the balance between aggressive, cooperative or neutral strategies is shifting. We hope our work will initiate discussions and encourage developers to assess their models' differential abilities, and to consider their emergent collective behaviour before deployment in real-world applications. Future work should investigate the factors influencing LLMs' cooperative biases, including training methodologies, fine-tuning processes, prompt engineering techniques, and the system dynamics they are deployed in.

In conclusion, our study provides a novel framework for evaluating the emergent behaviour of LLM agents and highlights the complex interplay between cooperation and aggression in MAS. As AI systems become increasingly prevalent in society, understanding and shaping their cooperative tendencies will be crucial for ensuring beneficial outcomes for humanity.
