## 1 Introduction

The recent appearance of large language models (LLMs) has resulted in numerous attempts to substitute humans with generative agents in various settings (see, for example, Park et al. (2023)). The motivation is simple: in many economic activities, especially those involving codifiable, highvolume, or knowledge-intensive tasks, LLMs are increasingly cost-competitive and productivityenhancing compared to human labor (Korinek, 2023, Merali, 2024, Kanazawa et al., 2025), and such automation can reduce employment (Acemoglu &amp; Restrepo, 2018). Still, at this point, it is not clear to what extent LLM can simulate human behavior. The revelation of differences between the decisions of the participants of economic experiments and LLMs' decisions in similar circumstances becomes an important challenge. Horton (2023) replicates several classic experiments with LLM players and advocates the use of LLMs as models for ordinary economic agents. Akata et al. (2023) reveal that LLMs underperform in the iterated games that require coordination such as the iterated Battle of Sexes. Brookins &amp; DeBacker (2023) show that LLMs prefer fair decisions in a Dictator game, even more than human players do. Goli &amp; Singh (2024) study the intertemporal preferences of LLMs and figure out that artificial players are less patient than humans. In general, different LLMs have different peculiarities: some are very sensitive to game structure, others have issues with context framing (Lor` e &amp; Heydari, 2024).

Our paper contributes to this strand of literature by studying the behavior of LLMs in the classic Guess the number game which belongs to a wider class of ùëù -beauty contest games. These ùëù -beauty contest games are of particular importance because they arise in various industries where the profit of a firm or the payoff of an individual player depend on the median preferences of all economic agents. The behavior of short-term traders and the resulting asset pricing is regarded as a variant of a beauty contest game (Allen et al., 2006, Cespa &amp; Vives, 2015). On the prediction markets, the desire to guess the most popular opinion is often considered as a behavioral driving force in addition to guessing the fundamental probabilities of an outcome (Marinovic et al., 2011). The beauty contest auction is an important alternative to price-only mechanisms of allocating goods to the bidders (Yoganarasimhan, 2016). Whereas algorithmic trading and betting strategies

written by humans have long been used on the markets, the appearance of strategies generated by LLMs is a rather recent phenomenon. Investigation of the LLMs' performance in a ùëù -beauty contest game (both absolute and relative to humans) would help to predict their performance in the above-mentioned markets.

The Guess the Number game tests the ability of a player to make a sequence of conclusions, and the outcome depends on their level of sophistication. The literature provides several important observations about the performance of heterogeneous players in various strategic settings. First, and most obvious, more advanced players reach better outcomes. The latter observation is especially notable in antagonistic pure games of skill. Charness (1981) revealed that the objective quality of moves selected by chess players increases with the player's skill. Levitt et al. (2011) considered a sequential game Race to 100 which is a pure game of skill. They conclude that the ability to perform backward induction leads to better results in the Race to 100 game. Second (and this is less obvious), the players pay attention to the opponents' quality. In the Eichberger et al. (2008) experimental study, most of the participants (72%) who play the simultaneous games of strategic complements or strategic substitutes feel that they can predict the actions of a game theorist better than the actions of a granny. The same large majority (72%) prefer to play against a game theorist rather than against a granny. In the Prisoner's Dilemma game, the high-ability players who learn that their partner is a low-ability one, decrease the level of cooperation (Lambrecht et al., 2024). In antagonistic games, more advanced human players demonstrate greater adaptability to competing environment. For example, in the centipede game, stronger chess players exploit the non-equilibrium play of weaker players (Palacios-Huerta &amp; Volij, 2009). However, Levitt et al. (2011) show that the ability to perform backward induction is not related to ability to stop early in the centipede game and assert that, instead of a centipede game, the pure games of skill should be used to test the role of the level of sophistication. We conclude that in many strategic environments, the skill of the players affects the outcome by allowing them to choose better strategies and/or to show greater adaptability to the opponents. To what extent do LLMs behave like a human? To answer this question, we replicate a series of well-known experiments with human participants playing the Guess the Number game by asking LLMs to play against the

same groups of competitors.

The rules of the Guess the number game are as follows. A group of ùëõ players simultaneously and independently choose a number between 0 and 100 . Denote by ùëö the mean of all strategies played. A player whose number is the closest to ùëùùëö , where ùëù &gt; 0 is the predetermined constant known to all players before the game, wins. In case of a tie, all tied players get the corresponding share of the prize. When all real numbers from [0 , 100] are allowed, for ùëù ‚àà (0 , 1) there is a unique Nash equilibrium in the model where all players choose 0 . In a particular case of ùëõ = 2 , choosing 0 is a weakly dominant strategy. If only integer numbers are allowed, there do exist additional Nash equilibria where the players play higher numbers. For example, if ùëù = 0 . 5 , all strategy profiles where most of the players play 1 and other players play 0 , are additional Nash equilibria. If ùëù = 2 / 3 , the profile (1 , . . . , 1) is the only additional Nash equilibrium.

Multiple experiments show that in the Guess the number game people, in general, do not play Nash equilibrium. In the pioneering experimental paper, Nagel (1995) demonstrated that in sessions with ùëù = 1 / 2 and ùëù = 2 / 3 no subject chose 0 and only 6 percent chose numbers below 10 . However, in the iterated game the strategies converged to Nash equilibrium from period to period, after the participants learned statistics from the previous rounds (Nagel, 1995). If one uses the median of the chosen numbers instead of the mean, results do not change much in a one-shot game but in the iterated game convergence to 0 is faster in the median variant compared to the mean variant (Duffy &amp; Nagel, 1997). Switching to the maximum instead of the mean or the median increases the chosen strategies (Duffy &amp; Nagel, 1997).

In a particular case of ùëõ = 2 , one could possibly anticipate a significant share of players choosing 0 , a weakly dominant strategy. However, this is not the case. Only 10% of undergraduate students and 37% of the audience of economics or psychology decision-making conferences chose 0 (Grosskopf &amp; Nagel, 2008). Also, the mean of the numbers chosen by the professionals (22) is lower than the mean of the numbers chosen by the students (36). A higher number of participants ùëõ = 18 leads to a lower mean both for professionals (19) and students (29). However, in the case of professionals, this difference is not statistically significant (Grosskopf &amp; Nagel, 2008). Rydval et al. (2009) strengthen this finding by identifying that only nearly 1/3 of all participants think

in terms of dominant strategies in 2- or 3-person Guess the number -like games with dominant strategies, while 2/3 of all participants fail to identify the strategic properties of the game. In our study, we ask whether LLMs are able to identify the strategic nature of the game.

Several theoretical models explaining the non-equilibrium behavior were proposed in the literature. Most of these models deal with the notion of bounded rationality when players are rational only to some extent; the degree of rationality is associated with the sophistication of a player. A dynamical model where the players choose one of the stepùëò behavioral rules, learn the results of the experiment, and choose more successful rules in the next iterations, was presented and estimated in Stahl (1996). A further extension of the set of possible behavioral strategies is discussed in Stahl (1998). Ho et al. (1998) builds the bounded rationality models based on the iterative deletion of dominated strategies and iterated best replies to previously played actions. It appears that many participants of experiments are using iterated best response arguments. Namely, Bosch et al. (2002) describes an experiment organized by The Financial Times where 64% of players indeed explained that they exploited the best responses to the revealed statistics. Note that playing iterative best response to the previous iteration of the game does not lead to the best response to other players' strategies in the new iteration (Breitmoser, 2012). Weber (2003) demonstrated that the feedback from organizers plays a key role in the speed of convergence to Nash equilibrium: in the absence of the feedback, the numbers also decreased but at a lower rate. Advice from a peer participant has an even stronger effect on the performance than pure statistics provided by the organizers (Kocher et al., 2014). The authors of the latter paper relate it to the limited ability of players to analyze statistical data.

Cognitive ability is also an important determinant of the outcome of the Guess the number game. Higher cognitive ability may manifest itself through better inductive reasoning, iterative dominance, and levelùëò thinking (Carpenter et al., 2013). Brocas &amp; Carrillo (2020) designed a variant of the Guess the number game and demonstrated that the equilibrium behavior increases significantly between 5 and 10 years of age (from 17.9% to 61.4%) and stabilizes afterward. Back to the classic variant of the game, players with higher scores in a cognitive ability test choose lower numbers (Burnham et al., 2009) and show faster convergence to equilibrium in iterated experiments

(Gill &amp; Prowse, 2016). Mixed evidence was reported in BraÀú nas-Garza et al. (2012): the better performance in the CRT test that measures cognitive reflectiveness is associated with lower numbers in the Guess the number game, whereas the outcome of the Raven test measuring visual reasoning and analytic intelligence surprisingly was not associated with the successful performance in the Guess the number game. Interestingly, high cognitive ability test scorers better respond to the cognitive ability of their opponents (Gill &amp; Prowse, 2016), whereas players whose abilities are below a certain threshold do not adapt strategically to the opponents' level of sophistication at all Fehr &amp; Huck (2016). The recent Gill et al. (2025) study distinguishes between cognitive ability and judgment. The authors show that whereas high cognitive ability shifts the strategy towards 0, high judgment subjects are less inclined to choose 0, even though their choices on average are lower than low judgment subjects. Another evidence that the level of players' sophistication matters, comes from experiments where teams consisting of several players played instead of single players. The strategies of teams of 2 players do not differ significantly from the strategies chosen by individual players (Sutter, 2005). At the same time, teams consisting of 3 and 4 players outperform individual players (Kocher &amp; Sutter, 2005, Sutter, 2005). One should also distinguish between cognitive abilities and cognitive effort. Al¬¥ os-Ferrer &amp; Buckenmaier (2021) propose an experiment where the deliberation time in the Guess the number game serves as a proxy for cognitive effort. The authors find evidence that longer deliberation time is related to playing strategies associated with higher numbers of reasoning steps. After running experiments with two families of games, Georganas et al. (2015) warn us that strategic sophistication varies across different families of games which prevents us from making too strong conclusions and expanding them from the Guess the number game to more general environments.

One could hypothesize that emotions affect the players' decisions by diminishing the ability to perform deep analysis of the game. However, the evidence differs for various conditions. Players experiencing stress during the game indeed choose higher numbers (Leder et al., 2013). Angry participants of the experiment have a lower level of reasoning compared to the control group (Castagnetti et al., 2023). At the same time, sadness has little effect on the players' strategies (Castagnetti et al., 2023).

It appears that framing of the problem also matters. Hanaki et al. (2019) considered two variants of the Guess the number game. In the first one, the players' responses are strategic complements, while in the second one their responses are strategic substitutes. Theoretical Nash equilibrium is the same in both variants. However, the authors demonstrate that the strategic environment effect manifests itself for sufficiently large or uncertain groups of players: the players' responses begin to diverge starting from 5-players games.

There are two principal dimensions of the problem in consideration.

1. For a wide range of parameters of a one-shot game, one can compare the strategies of humans and LLMs in a one-shot Guess the number game.
2. For a specific set of parameters, one can compare the strategies of humans and LLMs in the iterated version of the Guess the number game.

While the first approach focuses on the role of changing conditions of the game, the second approach studies learning effects. Our paper follows the former one. In order to make a fair comparison, we took only the first iterations of the game from the previous literature. Similarly, we never asked LLMs to play the Guess the number game several times in a row during one iteration of an experiment, and we never provided any feedback to LLMs. In contrast, the working paper Lu (2024) follows the second approach.

For more experimental and theoretical results on Guess the number games, we refer the reader to one of the surveys (Nagel, 2008, Nagel et al., 2017). Fan et al. (2024) presents a detailed overview of LLMs research published by 2023.

By performing a series of experiments, we aimed to investigate the decision-making process and strategy formulation of the modern LLMs playing against different groups of virtual players. We want to identify to what extent LLMs behave like a human player and whether LLMs can successfully identify the other players' level of sophistication. To move forward on this path, we break our task down into several questions.
