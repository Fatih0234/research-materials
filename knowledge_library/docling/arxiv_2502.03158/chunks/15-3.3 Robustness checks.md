## 3.3 Robustness checks

To ensure the stability of our findings, three robustness checks were performed by systematically modifying the experimental prompts.

First, the original prompt was paraphrased using synonyms, resulting in the following alternative formulation:

'Picture yourself in a contest with ğ‘› participants (you included). Everyone simultaneously picks an integer from 0 to 100, inclusive. Once all numbers are in, a ğ‘“ğ‘¢ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘› is applied to the full set; its value at ğ‘ is computed. The victor is the player whose chosen number lies nearest to that computed value. Your rivals are: ğ‘‚ğ‘ğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡ğ‘  . Assume you and they share identical ability, knowledge, intelligence, and education. Task: Which integer will you choose, and why? Return your reply in JSON with exactly two keys: 'answer\_text' (which contains the full text of the answer including the reasoning and ending with your unambiguously chosen number) and 'answer\_number' (which contains only your unambiguously chosen number.'

Table 8: Robustness checks for paraphrased prompt using synonyms.

| Paper                      |   Scenario |   Claude Sonnet |   Gemini Flash |   GPT-4o |   GPT-4o mini |   Llama |
|----------------------------|------------|-----------------|----------------|----------|---------------|---------|
| Nagel (1995)               |          1 |           11.72 |           5.68 |    20.3  |         24.8  |    9.84 |
| Nagel (1995)               |          2 |           16.96 |           7.46 |    18.72 |         33.52 |    6.6  |
| Duffy & Nagel (1997)       |          3 |           10.62 |           3.76 |    20.64 |         25.08 |   17.78 |
| Duffy & Nagel (1997)       |          4 |            8.42 |           1.16 |    24.98 |         26.44 |   17.76 |
| Duffy & Nagel (1997)       |          5 |           27.5  |          12.9  |    40.08 |         48.98 |   34.46 |
| Grosskopf & Nagel (2008)   |          6 |           18.88 |          19.74 |    23.32 |         32.04 |    8.38 |
| Grosskopf & Nagel (2008)   |          7 |           13.74 |           1.04 |    16.3  |         30.26 |    2.24 |
| Grosskopf & Nagel (2008)   |          8 |           16.8  |          22.56 |    22.58 |         32.4  |   13.24 |
| Grosskopf & Nagel (2008)   |          9 |           13.16 |           2.48 |    20.62 |         28.54 |    3.98 |
| Branas-Garza et al. (2012) |         10 |            2.7  |           0    |    10.88 |         25.18 |    3.5  |
| Branas-Garza et al. (2012) |         11 |           14.92 |          19.38 |    23.06 |         25.72 |   21.28 |
| Branas-Garza et al. (2012) |         12 |            2.8  |           0.1  |    15.38 |         31.76 |    6.88 |
| Branas-Garza et al. (2012) |         13 |           21.3  |          22.32 |    28.32 |         30.74 |   23.92 |
| Castagnetti et al. (2023)  |         14 |           19.86 |          15.8  |    31.36 |         40.4  |   21.24 |
| Castagnetti et al. (2023)  |         15 |           13.42 |           1.5  |    30.18 |         32.28 |   15.72 |
| Castagnetti et al. (2023)  |         16 |           15.1  |           0.76 |    23.26 |         35.16 |   13.06 |

A comparison of the results generated under the original and synonym-based prompts (Table 8) indicates that the overall behavioral patterns are preserved.

The results from Nagel (1995) and Grosskopf &amp; Nagel (2008) were compared in terms of AI agents' behavior relative to human outcomes under varying prompts. In the experimental setting of Nagel (1995), AI agents produced similar outcomes across both prompts. In the setting of Grosskopf &amp; Nagel (2008), however, an exception emerged for GPT-4o mini, which produced different outcomes in Scenarios 7 and 8, with predicted means exceeding those of human participants. In the case of Duffy &amp; Nagel (1997), the outcomes showed that AI agents consistently produced the highest values under both prompts in the setting of maximum function.

The divergent behavior of GPT-4o mini was also observed in the context of BraËœ nas-Garza et al. (2012). In this case, results of AI agents were compared between the original and synonym-based prompts across conditions defined by participants' CRT scores and the value of the ğ‘ parameter. The only discrepancy occurred in Scenarios 12 and 13, where GPT-4o mini generated a slightly higher mean predictions for participants with high CRT scores compared to those with low CRT scores.

Finally, for Castagnetti et al. (2023), model predictions were compared across conditions with emotions (anger and sadness) versus the control group. For anger, the results were consistent: AI agents exposed to anger produced higher average values under both prompts. For sadness, four out of five models (all except GPT-4o mini) produced higher values than the control group under the original prompt. Under the synonym-based prompt, however, an additional model (Claude Sonnet) also produced lower values under sadness compared to the control.

Second, to avoid direct associations with the well-known beauty contest framing, the task was reformulated in the context of a game show scenario:

'You are a participant in a TV show, and it's time for the next challenge. There are ğ‘› contestants, including you. Only one will advance to the next stage of the show. The organizers have given each participant a set of 100 stones. Simultaneously, each participant chooses how many stones (between 0 and 100) to put into the pot. The participant whose number of stones is closest to ğ‘ times a ğ‘“ğ‘¢ğ‘›ğ‘ğ‘¡ğ‘–ğ‘œğ‘› of all the submitted numbers of stones is declared the winner and advances to the next round. Your opponents are: ğ‘‚ğ‘ğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡ğ‘  You are in the same group as the ğ‘‚ğ‘ğ‘ğ‘œğ‘›ğ‘’ğ‘›ğ‘¡ğ‘  , you

possess the same skills, knowledge, level of intelligence, education, etc. How many stones will you put, and why? Provide your answer in a JSON format with two keys: 'answer\_text' (which contains the full text of the answer including the reasoning and concluded by your unambiguously chosen number of stones) and 'answer\_number' (which contains only your unambiguously chosen number of stones).'

Table 9: Robustness checks for paraphrasing using a different context.

| Paper                      |   Scenario |   Claude Sonnet |   Gemini Flash |   GPT-4o |   GPT-4o mini |   Llama |
|----------------------------|------------|-----------------|----------------|----------|---------------|---------|
| Nagel (1995)               |          1 |           10.48 |           6.1  |    21.68 |         23.24 |    0    |
| Nagel (1995)               |          2 |           17    |          13.6  |    22.62 |         28.98 |    0    |
| Duffy & Nagel (1997)       |          3 |           11.76 |           3.44 |    20.3  |         23.42 |    0    |
| Duffy & Nagel (1997)       |          4 |           13.04 |           5.68 |    24.92 |         25.32 |    0    |
| Duffy & Nagel (1997)       |          5 |           27.92 |          41.22 |    30.9  |         26.94 |    0.96 |
| Grosskopf & Nagel (2008)   |          6 |           22.3  |          19.5  |    28.9  |         29.72 |    0.88 |
| Grosskopf & Nagel (2008)   |          7 |           15.54 |           1.22 |    19.88 |         27.56 |    0    |
| Grosskopf & Nagel (2008)   |          8 |           21.82 |          21.08 |    26.44 |         29.48 |    4.02 |
| Grosskopf & Nagel (2008)   |          9 |            5.96 |           0.02 |     7.64 |         25.5  |    0    |
| Branas-Garza et al. (2012) |         10 |            3.94 |           0    |    13.64 |         23.18 |    0.44 |
| Branas-Garza et al. (2012) |         11 |           17.94 |          16.48 |    24.12 |         23.54 |    8.1  |
| Branas-Garza et al. (2012) |         12 |            5.12 |           0.2  |     7.78 |         26.62 |    0    |
| Branas-Garza et al. (2012) |         13 |           28.42 |          26.68 |    30.02 |         32    |   19.46 |
| Castagnetti et al. (2023)  |         14 |           39.4  |          18.72 |    36.44 |         36.66 |    0    |
| Castagnetti et al. (2023)  |         15 |           18.88 |           7.52 |    32.28 |         28.82 |    0    |
| Castagnetti et al. (2023)  |         16 |           15.08 |           1.42 |    34.84 |         34.5  |    0    |

The results obtained under the TV show framing broadly confirm the robustness of the initial findings, with models preserving their relative positioning in terms of strategic sophistication, although some quantitative differences arise (Table 9). For the settings examined by Nagel (1995), Duffy &amp; Nagel (1997), and BraËœ nas-Garza et al. (2012), no differences were observed in model behavior between the original and paraphrased prompts.

In the setting of Grosskopf &amp; Nagel (2008), GPT-4o mini again demonstrated sensitivity to prompt paraphrasing. Under the original prompt, this model produced higher predicted values than human participants only in Scenario 9. Under the TV show prompt, however, it also produced higher values in Scenarios 7 and 8. Another instance of deviation under the paraphrased prompt was observed in Scenarios 14 and 15 of Castagnetti et al. (2023). A notable change in behavior occurred with the Llama model, which produced zero predictions in 10 out of 16 scenarios, although

it had also demonstrated lower predictions compared to other models under the original prompt. All other results from the robustness check with the paraphrased prompt remained consistent with those obtained under the original formulation.

Third, to examine the sensitivity of responses to additional contextual features, the original prompt was extended by explicitly assigning the LLM player psychological and cognitive characteristics. Specifically, the agent was described as experiencing either anger or sadness, or alternatively, as possessing either a low or high cognitive reflection test (CRT) score. We therefore added an explicit clause to the prompts, for both CRT scores and emotions during robustness checks. For example:

You are playing the game. In this game, 3 players, including you, simultaneously choose an integer between 0 and 100, inclusive. The winner is the player whose number is closest to 0.7 times the average of all numbers chosen. You are playing against the following opponents: individuals experiencing anger. You are in the same group as the individuals experiencing anger; you possess the same skills, knowledge, intelligence, and education. You are also experiencing anger. Provide your answer in a JSON format with two keys: 'answer\_text' (which contains the full text of the answer including the reasoning and concluded by your unambiguously chosen number of stones) and 'answer\_number' (which contains only your unambiguously chosen number of stones).

Thus, we explicitly assigned the relevant trait (CRT score or emotional state) to the model's persona.

When emotional states and cognitive reflection traits were incorporated clearer into the prompts, model predictions remained broadly stable (Table 10). The inclusion of CRT level or emotional state had little influence on the mean values, as the variance of mean predictions was nearly identical between the extended prompt (0-37.42) and the original prompt (0.02-35.64).

With respect to CRT score (BraËœ nas-Garza et al., 2012), the finding that participants with higher CRT levels tend to play closer to 0 holds for both prompts, across conditions where the ğ‘ parameter equals 1/2 and 2/3. Regarding emotional states (Castagnetti et al., 2023), the behavior of AI agents with explicitly assigned emotions also indicates that participants experiencing anger

or sadness provide higher values compared to the control group. On average, those in the anger condition produce higher guesses than those in the sadness condition for both prompts.

Table 10: Robustness checks for CRT level and emotions

| Paper                      |   Scenario |   Claude Sonnet |   Gemini Flash |   GPT-4o |   GPT-4o mini |   Llama |
|----------------------------|------------|-----------------|----------------|----------|---------------|---------|
| Branas-Garza et al. (2012) |         10 |            5.54 |           0.04 |     9.1  |         17.16 |    0.06 |
| Branas-Garza et al. (2012) |         11 |           23.3  |          23.82 |    23.94 |         21.36 |   24.84 |
| Branas-Garza et al. (2012) |         12 |            7.4  |           0.12 |     6.38 |         20.68 |    0.04 |
| Branas-Garza et al. (2012) |         13 |           32.5  |          29.5  |    31.98 |         26.22 |   33.4  |
| Castagnetti et al. (2023)  |         14 |           25.46 |           8.68 |    31.46 |         37.42 |   23.52 |
| Castagnetti et al. (2023)  |         15 |           20.66 |          13.88 |    31.82 |         26.84 |    3.24 |
| Castagnetti et al. (2023)  |         16 |            8.78 |           0.24 |    27.49 |         36.88 |    0    |

Taken together, the three robustness checks demonstrate that although numerical outcomes may vary under paraphrasing, alternative framings, or the introduction of psychological attributes, the relative ordering and qualitative interpretation of model performance remain consistent, underscoring the reliability of the main results. The highest sensitivity to prompt formulation is observed for GPT-4o mini and Llama. It should also be noted that human participants likewise might be sensitive to the framing of the game, and the models exhibit a comparable responsiveness.
