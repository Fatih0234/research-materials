## 4.1 Multi-Stakeholder Competition and Cooperation in LLM Era

The development and deployment of LLMs involve various stakeholders, ranging from data providers and annotators to model trainers, platform deployers, and end users. Strategic behavior is ubiquitous in this landscape, whether manipulation of preference reporting during model fine-tuning or intense competition among vendors for user attention and market share. Game-theoretic modeling offers a structured approach to exploring these behaviors, uncovering equilibrium structures, incentive misalignments, and design trade-offs.

4.1.1 Strategic Preference Reporting in LLM Alignment. Several studies examine strategic preference reporting in LLM alignment. Buening et al. [191] model RLHF as a principal-agent game, where the LLM developer (principal) relies on annotators (agents) to provide pairwise preference data for fine-tuning. Since annotators also derive utility from the resulting model, they may manipulate preferences to influence outcomes. Their analysis proves that no RLHF objective can simultaneously ensure strategyproofness and social welfare optimality. Adopting a mechanism design perspective, Sun et al. [192] similarly identify misreporting incentives under standard objectives and derive payment rules that enforce truthful reporting while maximizing welfare. In a simpler setting, Wu et al. [154] formalize the Battling Influencers Game (BIG), showing it is a potential game where rational annotators exaggerate preferences in equilibrium to maximize influence. Together, these works reveal inherent incentive misalignment, necessitating carefully designed reward structures in alignment pipelines. Liu et al. [193, 194] modeled scenarios where a principal cannot directly observe effort. They design and analyze contracts, such as bonus schemes using 'golden questions' or linear/binary payment structures, to reward high-quality work. Both studies emphasize that without proper monitoring, even well-intentioned annotators may provide low-effort data, undermining alignment.

4.1.2 Data Sharing and Model Release Strategies. Game-theoretic approaches have emerged as powerful tools for analyzing strategic interactions in AI data-sharing, model development, and release strategies. In the domain of data sharing, Taitler et al. [195] modeled the interaction between a content creation firm and a Generative AI (GenAI) platform as a Stackelberg game. The firm, acting as the leader, strategically controls information disclosure, while the AI platform, as the follower, determines how much data to acquire from external experts. Their equilibrium analysis shows that firms may be willing to pay GenAI platforms to use their data and identifies the conditions under which such agreements become Pareto-improving. Focusing on model development, Laufer et al. [24] framed fine-tuning as a two-stage game between a generalist developer and a domain-specific specialist. This game involves sequential investment decisions followed by bargaining over revenue-sharing terms. Their findings demonstrate that a specialist's strategic decision to contribute, free-ride, or abstain hinges on the interplay of marginal returns and cost asymmetries. To analyze competition among machine learning providers, Xu et al. [196] introduced the Heterogeneous Data Game. This framework models providers that handle diverse data sources characterized by covariate and concept shifts. By identifying pure Nash equilibria, their work delineates the conditions that lead to distinct market structures: the nonexistence of an equilibrium, convergence toward homogeneity, or specialization in heterogeneous niches. Wu et al. [197] explored the strategic choice between open- and closed-source model releases, modeling it as a multi-agent game between open-source and proprietary developers. Their analysis reveals an 'innovation paradox': while open-sourcing accelerates ecosystem-wide innovation, it can erode the competitive advantages of individual firms. The equilibrium outcome ultimately depends on factors like user demand elasticity and asymmetries in development costs.

4.1.3 Pricing Strategies on Models and Outputs. Economic modeling also extends to pricing strategies on models and outputs, frequently adopting a Stackelberg pricing framework. Here, LLM platforms play the role of leaders Manuscript submitted to ACM

who pre-commit to pricing menus, while users, acting as followers, select options based on individual utility and task requirements. Bergemann et al. [198] studied the optimal pricing and product design for LLMs. Their economic framework considers variable operational costs for processing input and output tokens, the ability to fine-tune models, and diverse user needs and error sensitivities. They found that optimal pricing structures, often implemented through two-part tariffs, lead to higher markups for more intensive users, rationalizing observed industry practices like tiered pricing based on customization and usage levels. Li et al. [200] and Saig et al. [201] studied the pricing strategy for LLM users. The current pricing scheme, pay-per-token, is challenged by Saig et al. [201], who found that companies may use a cheaper model rather than the model they claimed to use, which causes a moral hazard. To address such a problem, they introduce a pay-for-performance, contract-based framework that incentivizes quality. Li et al. [200] modeled prompt pricing as a Stackelberg game between a platform and users with different prompt engineering skills. By incorporating 'prompt ambiguity,' they derive an optimal pricing algorithm that adapts to user proficiency, improving platform payoff. Mahmood [199] studied sequential price competition between two LLM-developing firms, setting prices for different tasks of model usage. The equilibrium analysis shows that the second mover can always achieve cost-effectiveness. Moreover, if the tasks are similar, the first mover may become cost-ineffective regardless of its pricing strategy.

4.1.4 Advertising and Monetization within LLM. Advertising and monetization within LLM interfaces represent a rapidly evolving area of research. Early explorations by Feizi et al. [202] outline several potential advertising ecosystems, sparking further work on specific mechanisms. Duetting et al. [25] introduced a token-level auction where advertisers can bid to influence text generation, highlighting resultant challenges like the exposure problem. Building on this, Soumalias et al. [203] proposed MOSAIC, a truthful mechanism that aggregates advertiser preferences over entire outputs using Rochet payments and importance sampling. Auction theory is also being adapted for Retrieval-Augmented Generation (RAG) [204, 205]. In these models, advertisers hold text content and bid to have it integrated into the LLM's output. Recent studies are also exploring more complex dynamics; Banchio et al. [206] modeled dynamic auctions, revealing a temporal trade-off where delaying responses can create 'auction thickness' to increase revenue. Meanwhile, Mordo et al. [207] investigated auctions that jointly compose sponsored and organic content to maximize social welfare rather than revenue alone. For a broader perspective, recent surveys [208] and position papers [209] map the entire design space for these novel systems.
