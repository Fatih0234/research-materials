## 5.2 Solving Intractable Game Problems with LLMs

In addition to expanding how games are modeled, LLMs offer powerful tools for addressing computational bottlenecks that have long hindered the practical application of game theory. Their ability to generate, interpret, and formalize complex structures allows them to tackle problems traditionally deemed intractable. This subsection explores how LLMs contribute to four crucial areas: interpretable mechanism design, reducing cognitive load in allocation tasks, automated game modeling, and simulation-based reasoning for information disclosure. These contributions not only improve solution efficiency but also broaden the real-world applicability of game-theoretic analysis.

5.2.1 Interpretable Mechanism Design. Traditional mechanism design often produces opaque, black-box solutions. Liu et al. [29] proposed a framework that casts mechanism design as a code generation task, using LLMs to produce human-readable pseudocode for heuristic mechanisms. This approach achieves competitive performance in complex design spaces, rediscovers classic mechanisms, and enhances interpretability, offering potential for discovering optimal mechanisms in intricate scenarios.

5.2.2 Reducing Cognitive Burdens in Allocation Tasks. High-dimensional preference reporting in allocation tasks, such as combinatorial auctions or course assignments, often overwhelms users, reducing efficiency. Soumalias et al. [28] Manuscript submitted to ACM

developed LLM-powered proxies that interpret one-shot natural language inputs to generate preference comparisons, lowering error rates and improving allocative efficiency. Similarly, Huang et al. [224] showed that LLM-based proxies in combinatorial auctions, integrated with incremental revelation mechanisms, reduce query demands and achieve faster convergence compared to traditional learning-theoretic methods, streamlining complex allocation processes.

5.2.3 Automated Game Modeling and Simulation. Real-world strategic interactions described in natural language are challenging to formalize. Mensfelt et al. [225] introduced a framework for autoformalizing simultaneous-move games from textual descriptions, using one-shot prompting and syntactic feedback to create formal logic representations for analysis. Deng et al. [226] extended this to imperfect-information games, employing a two-stage pipeline to identify information sets and construct extensive-form games, with a self-debugging module ensuring validity. Mensfelt et al. [227] further enabled tournament-style simulations of strategies derived from natural language scenarios, completing a pipeline from informal input to executable strategic evaluation. These frameworks enhance game theory's adaptability to real-world scenarios like policy negotiations.

5.2.4 Strategic Simulation and Information Disclosure. LLMs enable novel simulation-based approaches to complex game-theoretic problems. Yin et al. [228] proposed InfoBid, a framework using LLM agents to evaluate how information disclosure policies affect auction outcomes. Their simulations reveal that classical assumptions, such as 'more information improves efficiency,' may not hold with LLM bidders, as selective information sharing can lead to over- or underbidding. The limited ability of LLM bidders to model competitors' strategies highlights a gap between simulated and bounded rationality, underscoring the need to redesign strategies for LLM-mediated environments.
