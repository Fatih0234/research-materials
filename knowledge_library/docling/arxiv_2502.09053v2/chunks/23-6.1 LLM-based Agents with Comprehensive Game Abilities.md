## 6.1 LLM-based Agents with Comprehensive Game Abilities

Current Landscape: Recent research has focused on evaluating and enhancing LLM agents' performance in specific, isolated game scenarios. For instance, studies have demonstrated significant improvements in strategic reasoning in matrix games [63], Avalon [13], bargaining [19], and Werewolf [65]. Although some of the methods, such as strategic reflection or tool usage, are general in principle, their validation remains highly scenario-specific. Consequently, the Manuscript submitted to ACM

performance improvement often fails to transfer effectively between different game genres or rule systems, limiting the development of truly generalist game-playing agents.

Future Directions: Based on this observation, a future direction is to develop LLM agents proficient in fundamental game-theoretic reasoning, capable of applying core principles across diverse game settings without requiring explicit customization for each new environment. Achieving this ambitious goal requires simultaneous advancements across multiple research fronts: (1) improved rule comprehension through better formal language understanding and symbolic reasoning integration, (2) more robust external environment modeling that can handle partial observability and stochastic transitions, and (3) sophisticated multi-agent reasoning frameworks that scale to varying numbers of participants with different behavioral patterns. As the goal is to build a generalist game-playing LLm, the validation data should be comprehensive, ranging from simple matrix games to complex imperfect-information games.
