## 6.3 Understanding LLMs' Strategic Behavior

Current Landscape: Despite the improvement and evaluation of LLM agents in games, another valuable task is to provide a theoretical framework to characterize LLMs' behavior. For instance, Park et al. [229] provided insight into how LLM fails to act as a no-regret algorithm with the current supervised pre-training procedure. However, extending such theoretical characterizations to more complex strategic environments remains a significant open challenge. The vastness of strategy spaces and the combinatorial intricacies of game rules in realistic settings severely limit the feasibility of formal analysis.

Future Directions: A robust theoretical understanding of LLMs in strategic contexts is critical for defining performance boundaries and guiding architectural design. A promising approach is to use abstraction and simplification to model essential game dynamics without their full analytical complexity, for instance, by analyzing critical subroutines or decision points in isolation. Moreover, tools from complexity theory, especially those related to the circuit complexity

of Transformers, can be leveraged to establish formal limits on the strategic capabilities of these models. Ultimately, this line of inquiry could lead to more principled training methodologies that instill desired strategic behaviors.
