## 6.5 Modeling Cooperation Between Multi-LLMs and Humans

Current Landscape: As reviewed in Section 4, prior research has predominantly focused on competitive or adversarial dynamics between LLMs and humans. These studies have shed light on important societal concerns, including persuasion, manipulation, and safety. Yet, cooperative interactions-particularly those involving formal game-theoretic modeling-remain significantly underexplored.

Future Directions: A promising and necessary research direction lies in understanding and designing cooperative frameworks involving multiple LLMs and human participants. Central challenges include constructing incentivecompatible mechanisms that encourage LLMs to coordinate effectively on human-assigned tasks while also accounting for their own modeled objectives. Developing a formal understanding of LLM agents' goals and behaviors is critical for bridging the gap between abstract theory and practical deployment. Progress in this area could lead to the design of AI systems that more robustly align with human values and intentions.
