## REFERENCES

- [1] John Von Neumann and Oskar Morgenstern. Theory of games and economic behavior: 60th anniversary commemorative edition. In Theory of games and economic behavior . Princeton university press, 2007.
- [2] John F Nash Jr. Equilibrium points in n-person games. Proceedings of the national academy of sciences , 1950.
- [3] William Vickrey. Counterspeculation, auctions, and competitive sealed tenders. The Journal of finance , 1961.
- [4] Dirk Bergemann and Stephen Morris. Information design: A unified perspective. Journal of Economic Literature , 57(1):44-95, 2019.
- [5] Amartya Sen. Social choice theory. Handbook of mathematical economics , 3:1073-1181, 1986.
- [6] Mu Zhu, Ahmed H Anwar, Zelin Wan, Jin-Hee Cho, Charles A Kamhoua, and Munindar P Singh. A survey of defensive deception: Approaches using game theory and machine learning. IEEE Communications Surveys &amp; Tutorials , 23(4):2460-2493, 2021.
- [7] Tanmoy Hazra and Kushal Anjaria. Applications of game theory in deep learning: a survey. Multimedia Tools and Applications , 81(6):8963-8994, 2022.
- [8] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Open and efficient foundation language models. arXiv preprint arXiv:2302.13971 , 2023.
- [9] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 , 2023.
- [10] Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, Katie Millican, et al. Gemini: a family of highly capable multimodal models. arXiv preprint arXiv:2312.11805 , 2023.
- [11] Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. arXiv preprint arXiv:2412.19437 , 2024.
- [12] Elif Akata, Lion Schulz, Julian Coda-Forno, Seong Joon Oh, Matthias Bethge, and Eric Schulz. Playing repeated games with large language models. Nature Human Behaviour , pages 1-11, 2025.
- [13] Shenzhi Wang, Chang Liu, Zilong Zheng, Siyuan Qi, Shuo Chen, Qisen Yang, Andrew Zhao, Chaofei Wang, Shiji Song, and Gao Huang. Avalon's game of thoughts: Battle against deception through recursive contemplation. arXiv preprint arXiv:2310.01320 , 2023.
- [14] Yuan Deng, Vahab Mirrokni, Renato Paes Leme, Hanrui Zhang, and Song Zuo. Llms at the bargaining table. In Agentic Markets @ ICML 2024 , volume 2024, 2024.
- [15] Jiangjie Chen, Siyu Yuan, Rong Ye, Bodhisattwa Prasad Majumder, and Kyle Richardson. Put your money where your mouth is: Evaluating strategic planning and execution of LLM agents in an auction arena. In Open-World Agents @ NeurIPS 2024 , 2024. URL https://openreview.net/forum?id= hKEzHiYJXc.
- [16] Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Yan Xia, Man Lan, and Furu Wei. K-level reasoning: Establishing higher order beliefs in large language models for strategic reasoning. In Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers) , pages 7212-7234, 2025. doi: 10.18653/v1/2025.naacl-long.370. URL https://aclanthology.org/2025.naacl-long.370/.
- [17] Chenghao Huang, Yanbo Cao, Yinlong Wen, Tao Zhou, and Yanru Zhang. Pokergpt: An end-to-end lightweight solver for multi-player texas hold'em via large language model, 2024. URL https://arxiv.org/abs/2401.06781.
- [18] Yao Fu, Hao Peng, Tushar Khot, and Mirella Lapata. Improving language model negotiation with self-play and in-context learning from ai feedback, 2023. URL https://arxiv.org/abs/2305.10142.
- [19] Tian Xia, Zhiwei He, Tong Ren, Yibo Miao, Zhuosheng Zhang, Yang Yang, and Rui Wang. Measuring bargaining abilities of LLMs: A benchmark and a buyer-enhancement method. In Findings of the Association for Computational Linguistics: ACL 2024 , pages 3579-3602, 2024. doi: 10.18653/v1/ 2024.findings-acl.213. URL https://aclanthology.org/2024.findings-acl.213/.
- [20] Dekun Wu, Haochen Shi, Zhiyuan Sun, and Bang Liu. Deciphering digital detectives: Understanding llm behaviors and capabilities in multi-agent mystery games. In Findings of the Association for Computational Linguistics: ACL 2024 , pages 8225-8291, 2024.

- [21] James Enouen, Hootan Nakhost, Sayna Ebrahimi, Sercan Arik, Yan Liu, and Tomas Pfister. Textgenshap: Scalable post-hoc explanations in text generation with long documents. In Findings of the Association for Computational Linguistics: ACL 2024 , pages 13984-14011, 2024.
- [22] Luise Ge, Daniel Halpern, Evi Micha, Ariel D. Procaccia, Itai Shapira, Yevgeniy Vorobeychik, and Junlin Wu. Axioms for ai alignment from human feedback. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , pages 80439-80465, 2024. URL https://proceedings.neurips.cc/paper\_files/paper/2024/file/9328208f88ec69420031647e6ff97727-Paper-Conference.pdf.
- [23] Remi Munos, Michal Valko, Daniele Calandriello, Mohammad Gheshlaghi Azar, Mark Rowland, Zhaohan Daniel Guo, Yunhao Tang, Matthieu Geist, Thomas Mesnard, Côme Fiegel, et al. Nash learning from human feedback. In Proceedings of the International Conference on Machine Learning 41 (ICML 2024) , 2024.
- [24] Benjamin Laufer, Jon Kleinberg, and Hoda Heidari. Fine-tuning games: Bargaining and adaptation for general-purpose models. In Proceedings of the ACM on Web Conference 2024 , pages 66-76, 2024.
- [25] Paul Duetting, Vahab Mirrokni, Renato Paes Leme, Haifeng Xu, and Song Zuo. Mechanism design for large language models. In Proceedings of the ACM on Web Conference 2024 , pages 144-155, 2024.
- [26] Fan Yao, Chuanhao Li, Denis Nekipelov, Hongning Wang, and Haifeng Xu. Human vs. generative ai in content creation competition: Symbiosis or conflict? In Proceedings of the International Conference on Machine Learning 41 (ICML 2024) , 2024.
- [27] Boaz Taitler and Omer Ben-Porat. Braess's paradox of generative ai. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 39, pages 14139-14147, 2025. doi: 10.1609/aaai.v39i13.33548. URL https://ojs.aaai.org/index.php/AAAI/article/view/33548.
- [28] Ermis Soumalias, Yanchen Jiang, Kehang Zhu, Michael Curry, Sven Seuken, and David C Parkes. Llm-powered preference elicitation in combinatorial assignment. arXiv preprint arXiv:2502.10308 , 2025.
- [29] Jiayuan Liu, Mingyu Guo, and Vincent Conitzer. An interpretable automated mechanism design framework with large language models. arXiv preprint arXiv:2502.12203 , 2025.
- [30] Sara Fish, Paul Gölz, David C Parkes, Ariel D Procaccia, Gili Rusak, Itai Shapira, and Manuel Wüthrich. Generative social choice. In Proceedings of the 25th ACM Conference on Economics and Computation , pages 985-985, 2024.
- [31] Yuxuan Lu, Shengwei Xu, Yichi Zhang, Yuqing Kong, and Grant Schoenebeck. Eliciting informative text evaluations with large language models. In Proceedings of the 25th ACM Conference on Economics and Computation , pages 582-612, 2024.
- [32] Yadong Zhang, Shaoguang Mao, Tao Ge, Xun Wang, Yan Xia, Wenshan Wu, Ting Song, Man Lan, and Furu Wei. LLM as a mastermind: A survey of strategic reasoning with large language models. In First Conference on Language Modeling , 2024. URL https://openreview.net/forum?id=iMqJsQ4evS.
- [33] Xiachong Feng, Longxu Dou, Ella Li, Qinghao Wang, Haochuan Wang, Yu Guo, Chang Ma, and Lingpeng Kong. A survey on large language model-based social agents in game-theoretic scenarios. Transactions on Machine Learning Research , 2025.
- [34] Sihao Hu, Tiansheng Huang, Fatih Ilhan, Selim Tekin, Gaowen Liu, Ramana Kompella, and Ling Liu. A survey on large language model-based game agents. arXiv preprint arXiv:2404.02039 , 2024.
- [35] Fulin Guo. Gpt in game theory experiments, 2023. URL https://arxiv.org/abs/2305.05516.
- [36] John J Horton. Large language models as simulated economic agents: What can we learn from homo silicus? Technical report, National Bureau of Economic Research, 2023.
- [37] Kehan Zheng, Jinfeng Zhou, and Hongning Wang. Beyond nash equilibrium: Bounded rationality of llms and humans in strategic decision-making, 2025. URL https://arxiv.org/abs/2506.09390.
- [38] Alicia Vidler and Toby Walsh. Playing games with large language models: Randomness and strategy, 2025. URL https://arxiv.org/abs/2503.02582.
- [39] Silin Du and Xiaowei Zhang. Helmsman of the masses? evaluate the opinion leadership of large language models in the werewolf game. In First Conference on Language Modeling , 2024. URL https://openreview.net/forum?id=xMt9kCv5YR.
- [40] Jonathan Light, Min Cai, Sheng Shen, and Ziniu Hu. From text to tactic: Evaluating LLMs playing the game of avalon. In Foundation Models for Decision Making @ NeurIPS 2023 , 2023. URL https://openreview.net/forum?id=ltUrSryS0K.
- [41] Haolan Zhan, Yufei Wang, Zhuang Li, Tao Feng, Yuncheng Hua, Suraj Sharma, Lizhen Qu, Zhaleh Semnani-Azad, Ingrid Zukerman, and Reza Haffari. Let's negotiate! a survey of negotiation dialogue systems. In EACL (Findings) , 2024.
- [42] Yauwai Yim, Chunkit Chan, Tianyu Shi, Zheye Deng, Wei Fan, Tianshi Zheng, and Yangqiu Song. Evaluating and enhancing llms agent based on theory of mind in guandan: A multi-player cooperative game under imperfect information, 2024. URL https://arxiv.org/abs/2408.02559.
- [43] Giorgio Piatti, Zhijing Jin, Max Kleiman-Weiner, Bernhard Schölkopf, Mrinmaya Sachan, and Rada Mihalcea. Cooperate or collapse: Emergence of sustainable cooperation in a society of LLM agents. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , 2024. URL https://openreview.net/forum?id=0zWzJj6lO3.
- [44] Tim Ruben Davidson, Veniamin Veselovsky, Michal Kosinski, and Robert West. Evaluating language model agency through negotiations. In Proceedings of the International Conference on Learning Representations 12 (ICLR 2024) , 2024. URL https://openreview.net/forum?id=3ZqKxMHcAg.
- [45] Sara Fish, Yannai A Gonczarowski, and Ran I Shorrer. Algorithmic collusion by large language models. arXiv preprint arXiv:2404.00806 , 2024.
- [46] Shangmin Guo, Haochuan Wang, Haoran Bu, Yi Ren, Dianbo Sui, Yu-Ming Shang, and Siting Estee Lu. Economics arena for large language models. In Language Gamification @ NeurIPS 2024 , 2024. URL https://openreview.net/forum?id=n6Y5b1MCBV.
- [47] Nicole Immorlica, Brendan Lucier, and Aleksandrs Slivkins. Generative ai as economic agents. ACM SIGecom Exchanges , 22(1):93-109, 2024.
- [48] Xidong Feng, Yicheng Luo, Ziyan Wang, Hongrui Tang, Mengyue Yang, Kun Shao, David Henry Mguni, Yali Du, and Jun Wang. ChessGPT: Bridging policy learning and language modeling. In Proceedings of the Advances in Neural Information Processing Systems 36 (NeurIPS 2023) , 2023. URL https://openreview.net/forum?id=pvdm4B6JMK.

- [49] Richard Zhuang, Akshat Gupta, Richard Yang, Aniket Rahane, Zhengyu Li, and Gopala Anumanchipalli. Pokerbench: Training large language models to become professional poker players. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 39, pages 26175-26182, 2025.
- [50] Sihao Hu, Tiansheng Huang, and Ling Liu. Pokellmon: A human-parity agent for pokemon battles with large language models, 2024. URL https://arxiv.org/abs/2402.01118.
- [51] Junzhe Chen, Xuming Hu, Shuodi Liu, Shiyu Huang, Wei-Wei Tu, Zhaofeng He, and Lijie Wen. LLMArena: Assessing capabilities of large language models in dynamic multi-agent environments. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors, Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 13055-13077, 2024. doi: 10.18653/v1/2024.acl-long.705. URL https://aclanthology.org/2024.acl-long.705/.
- [52] Philip Brookins and Jason DeBacker. Playing games with gpt: What can we learn about a large language model from canonical strategic games? Economics Bulletin , 44(1):25 - 37, 2024. URL https://EconPapers.repec.org/RePEc:ebl:ecbull:eb-23-00457.
- [53] Nicolò Fontana, Francesco Pierri, and Luca Maria Aiello. Nicer than humans: How do large language models behave in the prisoner's dilemma? In Proceedings of the International AAAI Conference on Web and Social Media , volume 19, pages 522-535, 2025. doi: 10.1609/icwsm.v19i1.35829. URL https://ojs.aaai.org/index.php/ICWSM/article/view/35829.
- [54] Richard Willis, Yali Du, Joel Z Leibo, and Michael Luck. Will systems of llm agents cooperate: An investigation into a social dilemma. arXiv preprint arXiv:2501.16173 , 2025.
- [55] Jillian Ross, Yoon Kim, and Andrew Lo. LLM economicus? mapping the behavioral biases of LLMs via utility theory. In First Conference on Language Modeling , 2024. URL https://openreview.net/forum?id=Rx3wC8sCTJ.
- [56] Qiaozhu Mei, Yutong Xie, Walter Yuan, and Matthew O. Jackson. A turing test of whether ai chatbots are behaviorally similar to humans. Proceedings of the National Academy of Sciences , 121(9):e2313925121, 2024. doi: 10.1073/pnas.2313925121. URL https://www.pnas.org/doi/abs/10. 1073/pnas.2313925121.
- [57] Jingru Jia, Zehua Yuan, Junhao Pan, Paul E. McNamara, and Deming Chen. Large language model strategic reasoning evaluation through behavioral game theory, 2025. URL https://arxiv.org/abs/2502.20432.
- [58] Yue Wu, Xuan Tang, Tom Mitchell, and Yuanzhi Li. Smartplay : A benchmark for LLMs as intelligent agents. In Proceedings of the International Conference on Learning Representations 12 (ICLR 2024) , 2024. URL https://openreview.net/forum?id=S2oTVrlcp3.
- [59] Alonso Silva. Large language models playing mixed strategy nash equilibrium games. In Network Games, Artificial Intelligence, Control and Optimization: 11th International Conference, NETGCOOP 2024, Lille, France, October 9-11, 2024, Proceedings , page 142-152, Berlin, Heidelberg, 2024. Springer-Verlag. ISBN 978-3-031-78599-3. doi: 10.1007/978-3-031-78600-6\_13. URL https://doi.org/10.1007/978-3-031-78600-6\_13.
- [60] Jinhao Duan, Shiqi Wang, James Diffenderfer, Lichao Sun, Tianlong Chen, Bhavya Kailkhura, and Kaidi Xu. Reta: Recursively thinking ahead to improve the strategic reasoning of large language models. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers) , pages 2232-2246, 2024.
- [61] Caoyun Fan, Jindou Chen, Yaohui Jin, and Hao He. Can large language models serve as rational players in game theory? a systematic analysis. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 38, pages 17960-17967, 2024.
- [62] Nunzio Lorè and Babak Heydari. Strategic behavior of large language models and the role of game structure versus contextual framing. Scientific Reports , 14(1):18490, 2024.
- [63] Kanishk Gandhi, Dorsa Sadigh, and Noah Goodman. Strategic reasoning with language models. In Foundation Models for Decision Making @ NeurIPS 2023 , 2023.
- [64] Alessio Buscemi, Daniele Proverbio, Alessandro Di Stefano, The Anh Han, German Castignani, and Pietro Liò. Fairgame: a framework for ai agents bias recognition using game theory, 2025. URL https://arxiv.org/abs/2504.14325.
- [65] Neo Watanabe and Yoshinobu Kano. Werewolf game agent by generative AI incorporating logical information between players. In Yoshinobu Kano, editor, Proceedings of the 2nd International AIWolfDial @ ACL 2024 , pages 21-29, Tokyo, Japan, September 2024. Association for Computational Linguistics. doi: 10.18653/v1/2024.aiwolfdial-1.3. URL https://aclanthology.org/2024.aiwolfdial-1.3/.
- [66] Suma Bailis, Jane Friedhoff, and Feiyang Chen. Werewolf arena: A case study in llm evaluation via social deduction, 2024. URL https://arxiv.org/ abs/2407.13943.
- [67] Ziyi Liu, Abhishek Anand, Pei Zhou, Jen-tse Huang, and Jieyu Zhao. InterIntent: Investigating social intelligence of LLMs via intention understanding in an interactive game context. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , pages 6718-6746, 2024. doi: 10.18653/v1/2024.emnlp-main.383. URL https://aclanthology.org/2024.emnlp-main.383/.
- [68] Saaket Agashe, Yue Fan, Anthony Reyna, and Xin Eric Wang. LLM-coordination: Evaluating and analyzing multi-agent coordination abilities in large language models. In Luis Chiruzzo, Alan Ritter, and Lu Wang, editors, Findings of the Association for Computational Linguistics: NAACL 2025 , pages 8038-8057, 2025. doi: 10.18653/v1/2025.findings-naacl.448. URL https://aclanthology.org/2025.findings-naacl.448/.
- [69] Sahar Abdelnabi, Amr Gomaa, Sarath Sivaprasad, Lea Schönherr, and Mario Fritz. LLM-deliberation: Evaluating LLMs with interactive multi-agent negotiation game. In Large Language Model (LLM) Agents @ ICLR 2024 , 2024. URL https://openreview.net/forum?id=eE1WHn6qlk.
- [70] Dan Qiao, Chenfei Wu, Yaobo Liang, Juntao Li, and Nan Duan. Gameeval: Evaluating llms on conversational games. arXiv preprint arXiv:2308.10032 , 2023.
- [71] Yunhao Yang, Leonard Berthellemy, and Ufuk Topcu. Reasoning, memorization, and fine-tuning language models for non-cooperative games. arXiv preprint arXiv:2410.14890 , 2024.

- [72] Gabriel Mukobi, Hannah Erlebach, Niklas Lauffer, Lewis Hammond, Alan Chan, and Jesse Clifton. Welfare diplomacy: Benchmarking language model cooperation. In Socially Responsible Language Modelling Research , 2023. URL https://openreview.net/forum?id=WnR5BCX8GS.
- [73] Zhenyu Guan, Xiangyu Kong, Fangwei Zhong, and Yizhou Wang. Richelieu: self-evolving llm-based agents for ai diplomacy. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , 2024.
- [74] Maayan Orner, Oleg Maksimov, Akiva Kleinerman, Charles Ortiz, and Sarit Kraus. Explaining decisions of agents in mixed-motive games. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 39, pages 23267-23275, 2025.
- [75] Karthik Sreedhar and Lydia Chilton. Simulating human strategic behavior: Comparing single and multi-agent llms, 2024. URL https://arxiv.org/ abs/2402.08189.
- [76] Lin Xu, Zhiyuan Hu, Daquan Zhou, Hongyu Ren, Zhen Dong, Kurt Keutzer, See-Kiong Ng, and Jiashi Feng. MAgIC: Investigation of large language model powered multi-agent in cognition, adaptability, rationality and collaboration. In Yaser Al-Onaizan, Mohit Bansal, and YunNung Chen, editors, Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , pages 7315-7332, 2024. doi: 10.18653/v1/2024.emnlp-main.416. URL https://aclanthology.org/2024.emnlp-main.416/.
- [77] Steve Phelps and Yvan I. Russell. The machine psychology of cooperation: Can gpt models operationalise prompts for altruism, cooperation, competitiveness and selfishness in economic games?, 2024. URL https://arxiv.org/abs/2305.07970.
- [78] Haolin Wang, Xueyan Li, Yazhe Niu, Shuai Hu, and Hongsheng Li. Empowering LLMs in decision games through algorithmic data synthesis. In Will Synthetic Data Finally Solve the Data Access Problem? , 2025. URL https://openreview.net/forum?id=1RIHEJWN1L.
- [79] Jinhao Duan, Renming Zhang, James Diffenderfer, Bhavya Kailkhura, Lichao Sun, Elias Stengel-Eskin, Mohit Bansal, Tianlong Chen, and Kaidi Xu. GTBench: Uncovering the strategic reasoning capabilities of LLMs via game-theoretic evaluations. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , 2024. URL https://openreview.net/forum?id=ypggxVWIv2.
- [80] Jen-tse Huang, Eric John Li, Man Ho Lam, Tian Liang, Wenxuan Wang, Youliang Yuan, Wenxiang Jiao, Xing Wang, Zhaopeng Tu, and Michael R Lyu. How far are we on the decision-making of llms? evaluating llms' gaming ability in multi-agent environments. arXiv preprint arXiv:2403.11807 , 2024.
- [81] WenyueHua,Ollie Liu, Lingyao Li, Alfonso Amayuelas, Julie Chen, Lucas Jiang, Mingyu Jin, Lizhou Fan, Fei Sun, William Wang, et al. Game-theoretic llm: Agent workflow for negotiation games. arXiv preprint arXiv:2411.05990 , 2024.
- [82] Oguzhan Topsakal, Colby Jacob Edell, and Jackson Bailey Harper. Evaluating large language models with grid-based game competitions: An extensible llm benchmark and leaderboard, 2024. URL https://arxiv.org/abs/2407.07796.
- [83] Yihuai Lan, Zhiqiang Hu, Lei Wang, Yang Wang, Deheng Ye, Peilin Zhao, Ee-Peng Lim, Hui Xiong, and Hao Wang. LLM-based agent society investigation: Collaboration and confrontation in avalon gameplay. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing , pages 128-145, 2024. doi: 10.18653/v1/2024.emnlp-main.7. URL https://aclanthology.org/2024.emnlp-main.7/.
- [84] Federico Bianchi, Patrick John Chia, Mert Yuksekgonul, Jacopo Tagliabue, Dan Jurafsky, and James Zou. How well can LLMs negotiate? NegotiationArena platform and analysis. In Ruslan Salakhutdinov, Zico Kolter, Katherine Heller, Adrian Weller, Nuria Oliver, Jonathan Scarlett, and Felix Berkenkamp, editors, Proceedings of the International Conference on Machine Learning 41 (ICML 2024) , volume 235 of Proceedings of Machine Learning Research , pages 3935-3951. PMLR, 21-27 Jul 2024. URL https://proceedings.mlr.press/v235/bianchi24a.html.
- [85] Eilam Shapira, Omer Madmon, et al. Glee: A unified framework and benchmark for language-based economic environments. arXiv preprint , 2024.
- [86] Haochuan Wang, Xiachong Feng, Lei Li, Zhanyue Qin, Dianbo Sui, and Lingpeng Kong. Tmgbench: A systematic game benchmark for evaluating strategic reasoning abilities of llms. arXiv preprint arXiv:2410.10479 , 2024.
- [87] Shaoguang Mao, Yuzhe Cai, Yan Xia, Wenshan Wu, Xun Wang, Fengyi Wang, Qiang Guan, Tao Ge, and Furu Wei. ALYMPICS: LLM agents meet game theory. In Owen Rambow, Leo Wanner, Marianna Apidianaki, Hend Al-Khalifa, Barbara Di Eugenio, and Steven Schockaert, editors, Proceedings of the 31st International Conference on Computational Linguistics , pages 2845-2866, 2025. URL https://aclanthology.org/2025.coling-main.193/.
- [88] Lanxiang Hu, Mingjia Huo, Yuxuan Zhang, Haoyang Yu, Eric P. Xing, Ion Stoica, Tajana Rosing, Haojian Jin, and Hao Zhang. lmgame-bench: How good are llms at playing games?, 2025. URL https://arxiv.org/abs/2505.15146.
- [89] Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large language models are zero-shot reasoners. In Proceedings of the Advances in Neural Information Processing Systems 35 (NeurIPS 2022) , pages 22199-22213, 2022.
- [90] Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, and Denny Zhou. Self-consistency improves chain of thought reasoning in language models. In Proceedings of the International Conference on Learning Representations 11 (ICLR 2023) , 2023. URL https://openreview.net/forum?id=1PL1NIMMrw.
- [91] Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. Tree of thoughts: Deliberate problem solving with large language models. In Proceedings of the Advances in Neural Information Processing Systems 36 (NeurIPS 2023) , pages 11809-11822, 2023.
- [92] Benjamin Kempinski, Ian Gemp, Kate Larson, Marc Lanctot, Yoram Bachrach, and Tal Kachman. Game of thoughts: Iterative reasoning in game-theoretic domains with large language models. In AAMAS , 2025.
- [93] Jiaxian Guo, Bo Yang, Paul Yoo, Bill Yuchen Lin, Yusuke Iwasawa, and Yutaka Matsuo. Suspicion agent: Playing imperfect information games with theory of mind aware GPT-4. In First Conference on Language Modeling , 2024. URL https://openreview.net/forum?id=F2yGbwXJAi.
- [94] Hongyi Guo, Zhihan Liu, Yufeng Zhang, and Zhaoran Wang. Can large language models play games? a case study of a self-play approach, 2024. URL https://arxiv.org/abs/2403.05632.
- [95] Minae Kwon, Sang Michael Xie, Kalesha Bullard, and Dorsa Sadigh. Reward design with language models. In Proceedings of the International Conference on Learning Representations 11 (ICLR 2023) , 2023. URL https://openreview.net/forum?id=10uNUgI5Kl.

Manuscript submitted to ACM

- [96] Wenqi Zhang, Ke Tang, Hai Wu, Mengna Wang, Yongliang Shen, Guiyang Hou, Zeqi Tan, Peng Li, Yueting Zhuang, and Weiming Lu. Agent-pro: Learning to evolve via policy-level reflection and optimization. In Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages 5348-5375, 2024. doi: 10.18653/v1/2024.acl-long.292. URL https://aclanthology.org/2024.acl-long.292/.
- [97] Dixiao Wei, Peng Yi, Jinlong Lei, Yiguang Hong, and Yuchuan Du. An automated reinforcement learning reward design framework with large language model for cooperative platoon coordination, 2025. URL https://arxiv.org/abs/2504.19480.
- [98] Reiji Suzuki and Takaya Arita. An evolutionary model of personality traits related to cooperative behavior using a large language model. Scientific Reports , 14(1):5989, 2024.
- [99] Austen Liao, Nicholas Tomlin, and Dan Klein. Efficacy of language model self-play in non-zero-sum games. In Language Gamification @ NeurIPS 2024 , 2024. URL https://openreview.net/forum?id=lK93maUXif.
- [100] Xuanfa Jin, Ziyan Wang, Yali Du, Meng Fang, Haifeng Zhang, and Jun Wang. Learning to discuss strategically: a case study on one night ultimate werewolf. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , 2024.
- [101] Timo Schick, Jane Dwivedi-Yu, Roberto Dessì, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools. In Proceedings of the Advances in Neural Information Processing Systems 36 (NeurIPS 2023) , pages 68539-68551, 2023.
- [102] Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, dahai li, Zhiyuan Liu, and Maosong Sun. ToolLLM: Facilitating large language models to master 16000+ real-world APIs. In Proceedings of the International Conference on Learning Representations 12 (ICLR 2024) , 2024. URL https: //openreview.net/forum?id=dHng2O0Jjr.
- [103] Chuanhao Li, Runhan Yang, Tiankai Li, Milad Bafarassat, Kourosh Sharifi, Dirk Bergemann, and Zhuoran Yang. STRIDE: A tool-assisted LLM agent framework for strategic and interactive decision-making. In Agentic Markets @ ICML 2024 , 2024. URL https://openreview.net/forum?id=pqlkg1ABhr.
- [104] Lloyd S Shapley. A value for n-person games. Contribution to the Theory of Games , 2, 1953.
- [105] Miriam Horovicz and Roni Goldshmidt. TokenSHAP: Interpreting large language models with Monte Carlo shapley value estimation. In Lotem Peled-Cohen, Nitay Calderon, Shir Lissak, and Roi Reichart, editors, Proceedings of the 1st Workshop on NLP for Science (NLP4Science) @ ACL 2024 , pages 1-8, 2024. doi: 10.18653/v1/2024.nlp4science-1.1. URL https://aclanthology.org/2024.nlp4science-1.1/.
- [106] Amirata Ghorbani and James Zou. Data shapley: Equitable valuation of data for machine learning. In Proceedings of the International Conference on Machine Learning 36 (ICML 2019) , pages 2242-2251. PMLR, 2019.
- [107] Chuan Sun, Han Yu, and Lizhen Cui. Efficient shapley value-based non-uniform pruning of large language models. arXiv preprint arXiv:2505.01731 , 2025.
- [108] Gokul Swamy, Christoph Dann, Rahul Kidambi, Steven Wu, and Alekh Agarwal. A minimaximalist approach to reinforcement learning from human feedback. In Proceedings of the International Conference on Machine Learning 41 (ICML 2024) , 2024.
- [109] Corby Rosset, Ching-An Cheng, Arindam Mitra, Michael Santacroce, Ahmed Awadallah, and Tengyang Xie. Direct nash optimization: Teaching language models to self-improve with general preferences. arXiv preprint arXiv:2404.03715 , 2024.
- [110] Mingzhi Wang, Chengdong Ma, Qizhi Chen, Linjian Meng, Yang Han, Jiancong Xiao, Zhaowei Zhang, Jing Huo, Weijie J Su, and Yaodong Yang. Magnetic preference optimization: Achieving last-iterate convergence for language model alignment. arXiv preprint arXiv:2410.16714 , 2024.
- [111] Souradip Chakraborty, Jiahao Qiu, Hui Yuan, Alec Koppel, Furong Huang, Dinesh Manocha, Amrit Singh Bedi, and Mengdi Wang. Maxmin-rlhf: Towards equitable alignment of large language models with diverse human preferences. In Proceedings of the International Conference on Machine Learning 41 (ICML 2024) , 2024.
- [112] Rashid Mushkani, Hugo Berard, and Shin Koseki. Negotiative alignment: Embracing disagreement to achieve fairer outcomes-insights from urban studies. arXiv preprint arXiv:2503.12613 , 2025.
- [113] Zixiang Chen, Yihe Deng, Huizhuo Yuan, Kaixuan Ji, and Quanquan Gu. Self-play fine-tuning converts weak language models to strong language models. In Proceedings of the International Conference on Machine Learning 41 (ICML 2024) , 2024.
- [114] Jacob Makar-Limanov, Arjun Prakash, Denizalp Goktas, Nora Ayanian, and Amy Greenwald. Sta-rlhf: Stackelberg aligned reinforcement learning with human feedback. In Coordination and Cooperation for Multi-Agent Reinforcement Learning Methods Workshop , 2024.
- [115] Sijin Chen, Omar Hagrass, and Jason M Klusowski. Decoding game: On minimax optimality of heuristic text generation strategies. In Proceedings of the International Conference on Learning Representations 13 (ICLR 2025) , 2025.
- [116] Supriyo Chakraborty, Richard Tomsett, Ramya Raghavendra, Daniel Harborne, Moustafa Alzantot, Federico Cerutti, Mani Srivastava, Alun Preece, Simon Julier, Raghuveer M Rao, et al. Interpretability of deep learning models: A survey of results. In 2017 IEEE smartworld, ubiquitous intelligence &amp; computing, advanced &amp; trusted computed, scalable computing &amp; communications, cloud &amp; big data computing, Internet of people and smart city innovation (smartworld/SCALCOM/UIC/ATC/CBDcom/IOP/SCI) , pages 1-6. IEEE, 2017.
- [117] Quan-shi Zhang and Song-Chun Zhu. Visual interpretability for deep learning: a survey. Frontiers of Information Technology &amp; Electronic Engineering , 19(1):27-39, 2018.
- [118] Forough Poursabzi-Sangdeh, Daniel G Goldstein, Jake M Hofman, Jennifer Wortman Wortman Vaughan, and Hanna Wallach. Manipulating and measuring model interpretability. In Proceedings of the 2021 CHI conference on human factors in computing systems , pages 1-52, 2021.
- [119] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model predictions. In Proceedings of the Advances in Neural Information Processing Systems 30 (NeurIPS 2017) , 2017.
- [120] Hanxi Liu, Xiaokai Mao, Haocheng Xia, Jian Lou, and Jinfei Liu. Prompt valuation based on shapley values. arXiv preprint arXiv:2312.15395 , 2023.

Manuscript submitted to ACM

- [121] Behnam Mohammadi. Explaining large language models decisions using shapley values.
2. arXiv preprint arXiv:2404.01332 , 2024.
- [122] Zikun Ye and Hema Yoganarasimhan. Document valuation in llm summaries: A cluster shapley approach. arXiv preprint arXiv:2505.23842 , 2025.
- [123] Yexiao He, Ziyao Wang, Zheyu Shen, Guoheng Sun, Yucong Dai, Yongkai Wu, Hongyi Wang, and Ang Li. Shed: Shapley-based automated dataset refinement for instruction fine-tuning. arXiv preprint arXiv:2405.00705 , 2024.
- [124] Meng Cao, Shuyuan Zhang, Xiao-Wen Chang, and Doina Precup. Scar: Shapley credit assignment for more efficient rlhf. arXiv preprint arXiv:2505.20417 , 2025.
- [125] Yang Zhang, Yanfei Dong, and Kenji Kawaguchi. Investigating layer importance in large language models. In Proceedings of the 7th BlackboxNLP Workshop: Analyzing and Interpreting Neural Networks for NLP , pages 469-479, 2024. doi: 10.18653/v1/2024.blackboxnlp-1.29. URL https: //aclanthology.org/2024.blackboxnlp-1.29/.
- [126] William Held and Diyi Yang. Shapley head pruning: Identifying and removing interference in multilingual transformers. In Andreas Vlachos and Isabelle Augenstein, editors, Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics , pages 2416-2427, 2023. doi: 10.18653/v1/2023.eacl-main.177. URL https://aclanthology.org/2023.eacl-main.177/.
- [127] Chenghao Yang, Fan Yin, He He, Kai-Wei Chang, Xiaofei Ma, and Bing Xiang. Efficient shapley values estimation by amortization for text classification. arXiv preprint arXiv:2305.19998 , 2023.
- [128] Marcell Fekete and Johannes Bjerva. Linguistically grounded analysis of language models using shapley head values. In Luis Chiruzzo, Alan Ritter, and Lu Wang, editors, Findings of the Association for Computational Linguistics: NAACL 2025 , pages 850-865, 2025. doi: 10.18653/v1/2025.findingsnaacl.49. URL https://aclanthology.org/2025.findings-naacl.49/.
- [129] Yingxuan Yang, Bo Huang, Siyuan Qi, Chao Feng, Haoyi Hu, Yuxuan Zhu, Jinbo Hu, Haoran Zhao, Ziyi He, Xiao Liu, Zongyu Wang, Lin Qiu, Xuezhi Cao, Xunliang Cai, Yong Yu, and Weinan Zhang. Who's the mvp? a game-theoretic evaluation benchmark for modular attribution in llm agents, 2025. URL https://arxiv.org/abs/2502.00510.
- [130] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Gray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. Training language models to follow instructions with human feedback. In Proceedings of the Advances in Neural Information Processing Systems 35 (NeurIPS 2022) , 2022. URL https://openreview.net/forum?id=TG8KACxEON.
- [131] Timo Kaufmann, Paul Weng, Viktor Bengs, and Eyke Hüllermeier. A survey of reinforcement learning from human feedback. arXiv preprint arXiv:2312.14925 , 2024. URL https://arxiv.org/abs/2312.14925.
- [132] Yue Wu, Zhiqing Sun, Huizhuo Yuan, Kaixuan Ji, Yiming Yang, and Quanquan Gu. Self-play preference optimization for language model alignment. In Proceedings of the International Conference on Learning Representations 13 (ICLR 2025) , 2025.
- [133] Yuheng Zhang, Dian Yu, Baolin Peng, Linfeng Song, Ye Tian, Mingyue Huo, Nan Jiang, Haitao Mi, and Dong Yu. Iterative nash policy optimization: Aligning llms with general preferences via no-regret learning. In Proceedings of the International Conference on Learning Representations 13 (ICLR 2025) , 2025.
- [134] Chenlu Ye, Wei Xiong, Yuheng Zhang, Hanze Dong, Nan Jiang, and Tong Zhang. Online iterative reinforcement learning from human feedback with general preference model. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , pages 81773-81807, 2024.
- [135] Chenlu Ye, Wei Xiong, Yuheng Zhang, Nan Jiang, and Tong Zhang. A theoretical analysis of nash learning from human feedback under general kl-regularized preference. arXiv e-prints , pages arXiv-2402, 2024.
- [136] Daniil Tiapkin, Daniele Calandriello, Denis Belomestny, Eric Moulines, Alexey Naumov, Kashif Rasul, Michal Valko, and Pierre Menard. Accelerating nash learning from human feedback via mirror prox. arXiv preprint arXiv:2505.19731 , 2025.
- [137] Runlong Zhou, Maryam Fazel, and Simon S Du. Extragradient preference optimization (egpo): Beyond last-iterate convergence for nash learning from human feedback. arXiv preprint arXiv:2503.08942 , 2025.
- [138] Yibo Wang, Zikun Zhang, Zhihan Liu, Shenao Zhang, and Zhaoran Wang. Provably efficient and practical self-play for better llm alignment. arXiv preprint arXiv:2405.00705 , 2024.
- [139] Xiaohang Tang, Sangwoong Yoon, Seongho Son, Huizhuo Yuan, Quanquan Gu, and Ilija Bogunovic. Game-theoretic regularized self-play alignment of large language models. arXiv preprint arXiv:2503.00030 , 2025.
- [140] Reda Alami, Abdalgader Abubaker, Mastane Achab, Mohamed El Amine Seddik, and Salem Lahlou. Investigating regularization of self-play language models. arXiv preprint arXiv:2404.04291 , 2024.
- [141] Hao Sun, Yunyi Shen, and Jean-Francois Ton. Rethinking bradley-terry models in preference-based reward modeling: Foundations, theory, and alternatives. arXiv preprint arXiv:2411.04991 , 2024.
- [142] Zhekun Shi, Kaizhao Liu, Qi Long, Weijie J Su, and Jiancong Xiao. Fundamental limits of game-theoretic llm alignment: Smith consistency and preference matching. arXiv preprint arXiv:2505.20627 , 2025.
- [143] Tan Zhi-Xuan, Micah Carroll, Matija Franklin, and Hal Ashton. Beyond preferences in ai alignment. Philosophical Studies , pages 1-51, 2024.
- [144] Eve Fleisig, Rediet Abebe, and Dan Klein. When the majority is wrong: Modeling annotator disagreement for subjective tasks. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing , pages 6715-6726, 2023.
- [145] Abhilash Mishra. Ai alignment and social choice: Fundamental limitations and policy implications. arXiv preprint arXiv:2310.16048 , 2023.
- [146] Jessica Dai and Eve Fleisig. Mapping social choice theory to rlhf. arXiv preprint arXiv:2404.13038 , 2024.
- [147] Ali Shirali, Arash Nasr-Esfahany, Abdullah Alomar, Parsa Mirtaheri, Rediet Abebe, and Ariel Procaccia. Direct alignment with heterogeneous preferences. arXiv preprint arXiv:2502.16320 , 2025.

Manuscript submitted to ACM

- [148] Hadi Hosseini and Samarth Khanna. Distributive fairness in large language models: Evaluating alignment with human values. arXiv preprint arXiv:2502.00313 , 2025.
- [149] Ariel D Procaccia, Benjamin Schiffer, and Shirley Zhang. Clone-robust ai alignment. arXiv preprint arXiv:2501.09254 , 2025.
- [150] Paul Gölz, Nika Haghtalab, and Kunhe Yang. Distortion of ai alignment: Does preference optimization optimize for preferences? arXiv preprint arXiv:2505.23749 , 2025.
- [151] Jiancong Xiao, Zhekun Shi, Kaizhao Liu, Qi Long, and Weijie J Su. Theoretical tensions in rlhf: Reconciling empirical success with inconsistencies in social choice theory. arXiv preprint arXiv:2506.12350 , 2025.
- [152] Vincent Conitzer, Rachel Freedman, Jobst Heitzig, Wesley H Holliday, Bob M Jacobs, Nathan Lambert, Milan Mossé, Eric Pacuit, Stuart Russell, Hailey Schoelkopf, et al. Position: Social choice should guide ai alignment in dealing with diverse human feedback. In Proceedings of the International Conference on Machine Learning 41 (ICML 2024) , 2024.
- [153] Zhaowei Zhang, Fengshuo Bai, Mingzhi Wang, Haoyang Ye, Chengdong Ma, and Yaodong Yang. Incentive compatibility for ai alignment in sociotechnical systems: Positions and prospects. arXiv preprint arXiv:2402.12907 , 2024.
- [154] Young Wu, Yancheng Zhu, Jin-Yi Cai, and Xiaojin Zhu. The battling influencers game: Nash equilibria structure of a potential game and implications to value alignment. arXiv preprint arXiv:2502.01127 , 2025.
- [155] Oliver Klingefjord, Ryan Lowe, and Joe Edelman. What are human values, and how do we align ai to them? arXiv preprint arXiv:2404.10636 , 2024.
- [156] Kihyun Kim, Jiawei Zhang, Asuman Ozdaglar, and Pablo A Parrilo. Population-proportional preference learning from human feedback: An axiomatic approach. arXiv preprint arXiv:2506.05619 , 2025.
- [157] Dominik Peters. Proportional representation for artificial intelligence. In ECAI 2024 , pages 27-31. IOS Press, 2024.
- [158] Tianyi Qiu. Representative social choice: From learning theory to ai alignment. In Pluralistic Alignment @ NeurIPS 2024 , 2024.
- [159] Pengyu Cheng, Yong Dai, Tianhao Hu, Han Xu, Zhisong Zhang, Lei Han, Nan Du, and Xiaolong Li. Self-playing adversarial language game enhances llm reasoning. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , pages 126515-126543, 2024. URL https://proceedings.neurips.cc/paper\_files/paper/2024/file/e4be7e9867ef163563f4a5e90cec478f-Paper-Conference.pdf.
- [160] Kaizhao Liu, Qi Long, Zhekun Shi, Weijie J Su, and Jiancong Xiao. Statistical impossibility and possibility of aligning llms with human preferences: From condorcet paradox to nash equilibrium. arXiv preprint arXiv:2503.10990 , 2025.
- [161] Daiwei Chen, Yi Chen, Aniket Rege, and Ramya Korlakai Vinayak. Pal: Pluralistic alignment framework for learning from heterogeneous preferences. Adaptive Foundation Models @ NeurIPS 2024 , 2024.
- [162] Chanwoo Park, Mingyang Liu, Dingwen Kong, Kaiqing Zhang, and Asuman E Ozdaglar. Rlhf from heterogeneous feedback via personalization and preference aggregation. In Aligning Reinforcement Learning Experimentalists and Theorists @ ICML 2024 , 2024.
- [163] Huiying Zhong, Zhun Deng, Weijie J Su, Zhiwei Steven Wu, and Linjun Zhang. Provable multi-party reinforcement learning with diverse human feedback. arXiv preprint arXiv:2403.05006 , 2024.
- [164] Parand A. Alamdari, Soroush Ebadian, and Ariel D. Procaccia. Policy aggregation. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , pages 68308-68329, 2024. URL https://proceedings.neurips.cc/paper\_files/paper/2024/file/ 7e670825a578392891ad40e93931b1e3-Paper-Conference.pdf.
- [165] Joshua C Yang, Damian Dalisan, Marcin Korecki, Carina I Hausladen, and Dirk Helbing. Llm voting: Human choices and ai collective decision-making. In Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society 7 (AIES 2024) , pages 1696-1708, 2024.
- [166] Daniel Halpern, Evi Micha, Ariel D Procaccia, and Itai Shapira. Pairwise calibrated rewards for pluralistic alignment. arXiv preprint arXiv:2505.19731 , 2025.
- [167] Zhen Wang, Ruiqi Song, Chen Shen, Shiya Yin, Zhao Song, Balaraju Battu, Lei Shi, Danyang Jia, Talal Rahwan, and Shuyue Hu. Large language models overcome the machine penalty when acting fairly but not when acting selfishly or altruistically. arXiv preprint arXiv:2410.03724 , 2024.
- [168] Joar Skalse, Nikolaus Howe, Dmitrii Krasheninnikov, and David Krueger. Defining and characterizing reward gaming. In Proceedings of the Advances in Neural Information Processing Systems 35 (NeurIPS 2022) , pages 9460-9471, 2022.
- [169] Ari Azarafrooz and Farshid Faal. Language alignment via nash-learning and adaptive feedback. In Models of Human Feedback for AI Alignment @ ICML 2024 , 2024.
- [170] Xu Chu, Zhixin Zhang, Tianyu Jia, and Yujie Jin. Stackelberg game preference optimization for data-efficient alignment of language models. arXiv preprint arXiv:2502.18099 , 2025.
- [171] Rui Zheng, Hongyi Guo, Zhihan Liu, Xiaoying Zhang, Yuanshun Yao, Xiaojun Xu, Zhaoran Wang, Zhiheng Xi, Tao Gui, Qi Zhang, et al. Toward optimal llm alignments using two-player games. arXiv preprint arXiv:2406.10977 , 2024.
- [172] Ziyu Ye, Rishabh Agarwal, Tianqi Liu, Rishabh Joshi, Sarmishta Velury, Quoc V Le, Qijun Tan, and Yuan Liu. Reward-guided prompt evolving in reinforcement learning for llms. In Proceedings of the International Conference on Machine Learning 42 (ICML 2025) , 2025.
- [173] Mickel Liu, Liwei Jiang, Yancheng Liang, Simon Shaolei Du, Yejin Choi, Tim Althoff, and Natasha Jaques. Chasing moving targets with online self-play reinforcement learning for safer language models. arXiv preprint arXiv:2506.07468 , 2025.
- [174] Jiaqi Chen, Bang Zhang, Ruotian Ma, Peisong Wang, Xiaodan Liang, Zhaopeng Tu, Xiaolong Li, and Kwan-Yee K Wong. Spc: Evolving self-play critic via adversarial games for llm reasoning. arXiv preprint arXiv:2504.19162 , 2025.
- [175] Runlong Zhou, Simon S Du, and Beibin Li. Reflect-rl: Two-player online rl fine-tuning for lms. arXiv preprint arXiv:2402.12621 , 2024.
- [176] Xinhong Xie, Tao Li, and Quanyan Zhu. Learning from response not preference: A stackelberg approach for llm detoxification using non-parallel data. arXiv preprint arXiv:2410.20298 , 2024.

- [177] Pengyu Cheng, Yifan Yang, Jian Li, Yong Dai, Tianhao Hu, Peixin Cao, Nan Du, and Xiaolong Li. Adversarial preference optimization: Enhancing your alignment via rm-llm game. In Findings of the Association for Computational Linguistics: ACL 2024 , pages 3705-3716, 2024.
- [178] Han Shen, Zhuoran Yang, and Tianyi Chen. Principled penalty-based methods for bilevel reinforcement learning and rlhf. arXiv preprint arXiv:2402.06886 , 2024.
- [179] Souradip Chakraborty, Amrit Bedi, Alec Koppel, Huazheng Wang, Dinesh Manocha, Mengdi Wang, and Furong Huang. Parl: A unified framework for policy alignment in reinforcement learning from human feedback. In Proceedings of the International Conference on Learning Representations 12 (ICLR 2024) , 2024.
- [180] Vinzenz Thoma, Barna Pásztor, Andreas Krause, Giorgia Ramponi, and Yifan Hu. Contextual bilevel reinforcement learning for incentive alignment. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , pages 127369-127435, 2024.
- [181] Hao Ma, Tianyi Hu, Zhiqiang Pu, Liu Boyin, Xiaolin Ai, Yanyan Liang, and Min Chen. Coevolving with the other you: Fine-tuning llm with sequential cooperative multi-agent reinforcement learning. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , pages 15497-15525, 2024.
- [182] Ian Gemp, Yoram Bachrach, Marc Lanctot, Roma Patel, Vibhavari Dasagi, Luke Marris, Georgios Piliouras, Siqi Liu, and Karl Tuyls. States as strings as strategies: Steering language models with game-theoretic solvers. Agentic Markets @ ICML 2024 , 2024.
- [183] Athul Paul Jacob, Yikang Shen, Gabriele Farina, and Jacob Andreas. The consensus game: Language model generation via equilibrium search. In Proceedings of the International Conference on Learning Representations 12 (ICLR 2024) , 2024.
- [184] Baiting Chen, Tong Zhu, Jiale Han, Lexin Li, Gang Li, and Xiaowu Dai. Incentivizing truthful language models via peer elicitation games. arXiv preprint arXiv:2505.13636 , 2025.
- [185] Bangguo Yu, Yuzhen Liu, Lei Han, Hamidreza Kasaei, Tingguang Li, and Ming Cao. Vln-game: Vision-language equilibrium search for zero-shot semantic navigation. arXiv preprint arXiv:2411.11609 , 2024.
- [186] Weitong Zhang, Chengqi Zang, and Bernhard Kainz. Strategic llm decoding through bayesian games. In Reasoning and Planning for Large Language Models @ ICLR 2025 , 2025.
- [187] Ian Gemp, Roma Patel, Yoram Bachrach, Marc Lanctot, Vibhavari Dasagi, Luke Marris, Georgios Piliouras, Siqi Liu, and Karl Tuyls. Steering language models with game-theoretic solvers. In Agentic Markets @ ICML 2024 , 2024.
- [188] Daniel Sefeni, Michael Johnson, and Joshua Lee. Game-theoretic approaches for stepwise controllable text generation in large language models. Authorea Preprints , 2024.
- [189] Guoxi Zhang and Jiuding Duan. Vickreyfeedback: Cost-efficient data construction for reinforcement learning from human feedback. In International Conference on Principles and Practice of Multi-Agent Systems , pages 351-366. Springer, 2024.
- [190] Xie Yi, Zhanke Zhou, Chentao Cao, Qiyu Niu, Tongliang Liu, and Bo Han. From debate to equilibrium: Belief-driven multi-agent LLM reasoning via bayesian nash equilibrium. In Proceedings of the International Conference on Machine Learning 42 (ICML 2025) , 2025. URL https://openreview. net/forum?id=RQwexjUCxm.
- [191] Thomas Kleine Buening, Jiarui Gan, Debmalya Mandal, and Marta Kwiatkowska. Strategyproof reinforcement learning from human feedback. arXiv preprint arXiv:2503.09561 , 2025.
- [192] Haoran Sun, Yurong Chen, Siwei Wang, Wei Chen, and Xiaotie Deng. Mechanism design for llm fine-tuning with multiple reward models. Pluralistic Alignment @ NeurIPS 2024 , 2024.
- [193] Shang Liu, Hanzhao Wang, Zhongyao Ma, and Xiaocheng Li. How humans help llms: Assessing and incentivizing human preference annotators. arXiv preprint arXiv:2502.06387 , 2025.
- [194] Shang Liu, Zhongze Cai, Hanzhao Wang, Zhongyao Ma, and Xiaocheng Li. Incentivizing high-quality human annotations with golden questions. arXiv preprint arXiv:2505.19134 , 2025.
- [195] Boaz Taitler, Omer Madmon, Moshe Tennenholtz, and Omer Ben-Porat. Data sharing with a generative ai competitor. arXiv preprint arXiv:2505.12386 , 2025.
- [196] Renzhe Xu, Kang Wang, and Bo Li. Heterogeneous data game: Characterizing the model competition across multiple data sources. In Proceedings of the International Conference on Machine Learning 42 (ICML 2025) , 2025.
- [197] Yanxuan Wu, Haihan Duan, Xitong Li, and Xiping Hu. Navigating the deployment dilemma and innovation paradox: Open-source versus closed-source models. In Proceedings of the ACM on Web Conference 2025 , WWW'25, page 1488-1501, New York, NY, USA, 2025. Association for Computing Machinery. ISBN 9798400712746. doi: 10.1145/3696410.3714783. URL https://doi.org/10.1145/3696410.3714783.
- [198] Dirk Bergemann, Alessandro Bonatti, and Alex Smolin. The Economics of Large Language Models: Token Allocation, Fine-Tuning, and Optimal Pricing. arXiv preprint arXiv:2502.07736 , 2025.
- [199] Rafid Mahmood. Pricing and competition for generative ai. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , 2024.
- [200] Xiang Li, Bing Luo, Jianwei Huang, and Yuan Luo. Strategic prompt pricing for aigc services: A user-centric approach. arXiv preprint arXiv:2503.18168 , 2025.
- [201] Eden Saig, Ohad Einav, and Inbal Talgam-Cohen. Incentivizing quality text generation via statistical contracts. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , 2024.
- [202] Soheil Feizi, MohammadTaghi Hajiaghayi, Keivan Rezaei, and Suho Shin. Online advertisements with llms: Opportunities and challenges. ACM SIGecom Exchanges , 22(2):66--81, March 2025.

Manuscript submitted to ACM

- [203] Ermis Soumalias, Michael J Curry, and Sven Seuken. Truthful aggregation of llms with an application to online advertising. Agentic Markets @ ICML 2024 , 2024.
- [204] MohammadTaghi Hajiaghayi, Sebastien Lahaie, Keivan Rezaei, and Suho Shin. Ad auctions for llms via retrieval augmented generation. In Proceedings of the Advances in Neural Information Processing Systems 37 (NeurIPS 2024) , 2024.
- [205] Avinava Dubey, Zhe Feng, Rahul Kidambi, Aranyak Mehta, and Di Wang. Auctions with llm summaries. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining , pages 713-722, 2024.
- [206] Martino Banchio, Aranyak Mehta, and Andres Perlroth. Ads in conversations. In Proceedings of the 26th ACM Conference on Economics and Computation , page 350. Association for Computing Machinery, 2025. ISBN 9798400719431. doi: 10.1145/3736252.3742545. URL https: //doi.org/10.1145/3736252.3742545.
- [207] Tommy Mordo, Moshe Tennenholtz, and Oren Kurland. Sponsored question answering. In Proceedings of the 2024 ACM SIGIR International Conference on Theory of Information Retrieval , pages 167-173, 2024.
- [208] Ziwei Wu and Junwu Zhu. A review on large model-oriented advertising auction. In 2024 IEEE International Conference on Cognitive Computing and Complex Data (ICCD) , pages 7-12. IEEE, 2024.
- [209] Menghua Wu and Yujia Bao. Advertising in ai systems: Society must be vigilant. arXiv preprint arXiv:2505.18425 , 2025.
- [210] Boaz Taitler and Omer Ben-Porat. Selective Response Strategies for GenAI. In Proceedings of the International Conference on Machine Learning 42 (ICML 2025) , 2025.
- [211] Sahand Sabour, June M Liu, Siyang Liu, Chris Z Yao, Shiyao Cui, Xuanming Zhang, Wen Zhang, Yaru Cao, Advait Bhat, Jian Guan, et al. Human decision-making is susceptible to ai-driven manipulation. arXiv preprint arXiv:2502.07663 , 2025.
- [212] Gur Keinan and Omer Ben-Porat. Strategic content creation in the age of genai: To share or not to share? arXiv preprint arXiv:2505.16358 , 2025.
- [213] Yi Gao, Zhe Wang, and Yan Huang. Pandora box or golden fleece: Economic analysis of generative ai adoption on creation platforms. In Michelle Carter 0001, Kelly J. Fadel, Thomas O. Meservy, Deborah J. Armstrong, Amit Deokar 0001, and Matthew L. Jensen, editors, 30th Americas Conference on Information Systems: Elevating Life through Digital Social Entrepreneurship, AMCIS 2024, Salt Lake City, UT, USA, August 15-17, 2024 . Association for Information Systems, 2024. URL https://aisel.aisnet.org/amcis2024/ai\_aa/ai\_aa/11.
- [214] Seyed A Esmaeili, Kshipra Bhawalkar, Zhe Feng, Di Wang, and Haifeng Xu. How to strategize human content creation in the era of genai? arXiv preprint arXiv:2406.05187 , 2024.
- [215] Boaz Taitler and Omer Ben-Porat. Braess's paradox of generative ai. In Proceedings of the AAAI Conference on Artificial Intelligence , volume 39, pages 14139-14147, 2025.
- [216] Benjamin Laufer, Jon Kleinberg, and Hoda Heidari. The Backfiring Effect of Weak AI Safety Regulation. arXiv preprint arXiv:2503.20848 , 2025.
- [217] S Nageeb Ali, Nicole Immorlica, Meena Jagadeesan, and Brendan Lucier. Flattening supply chains: When do technology improvements lead to disintermediation? arXiv preprint arXiv:2502.20783 , 2025.
- [218] Tian Xie, Xuwei Tan, and Xueru Zhang. Algorithmic decision-making under agents with persistent improvement. In Proceedings of AAAI/ACM Conference on AI, Ethics, and Society 7 (AIES 2024) , page 1672-1683, 2025.
- [219] Wenhao Li, Yue Lin, Xiangfeng Wang, Bo Jin, Hongyuan Zha, and Baoxiang Wang. Verbalized bayesian persuasion. arXiv preprint arXiv:2502.01587 , 2025.
- [220] Niclas Boehmer, Sara Fish, and Ariel D Procaccia. Generative social choice: The next generation. In Proceedings of the International Conference on Machine Learning 42 (ICML 2025) , 2025.
- [221] Jie Sun, Tianyu Zhang, Houcheng Jiang, Kexin Huang, Chi Luo, Junkang Wu, Jiancan Wu, An Zhang, and Xiang Wang. Large language models empower personalized valuation in auction. arXiv preprint arXiv:2410.15817 , 2024.
- [222] Nicolas Della Penna. Natural language mechanisms via self-resolution with foundation models. arXiv preprint arXiv:2407.07845 , 2024.
- [223] Ismail Lotfi, Nouf Alabbasi, and Omar Alhussein. Rethinking strategic mechanism design in the age of large language models: New directions for communication systems. IEEE Internet of Things Magazine , pages 1-9, 2025. doi: 10.1109/MIOT.2025.3576260.
- [224] David Huang, Francisco Marmolejo-Cossío, Edwin Lock, and David Parkes. Accelerated preference elicitation with llm-based proxies. arXiv preprint arXiv:2501.14625 , 2025.
- [225] Agnieszka Mensfelt, Kostas Stathis, and Vince Trencsenyi. Autoformalizing and simulating game-theoretic scenarios using llm-augmented agents. arXiv preprint arXiv:2412.08805 , 2024.
- [226] Shilong Deng, Yongzhao Wang, and Rahul Savani. From natural language to extensive-form game representations. arXiv preprint , 2025.
- [227] Agnieszka Mensfelt, Kostas Stathis, and Vince Trencsenyi. Autoformalization of game descriptions using large language models. arXiv preprint arXiv:2409.12300 , 2024.
- [228] Yue Yin. Too much information? investigating information disclosure in auction systems with llm simulations. In Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems , CHI EA '25, New York, NY, USA, 2025. Association for Computing Machinery. ISBN 9798400713958. doi: 10.1145/3706599.3720022. URL https://doi.org/10.1145/3706599.3720022.
- [229] Chanwoo Park, Xiangyu Liu, Asuman E Ozdaglar, and Kaiqing Zhang. Do llm agents have regret? a case study in online learning and games. In Proceedings of the International Conference on Learning Representations 13 (ICLR 2025) , 2025.
