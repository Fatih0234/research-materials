## 1 Introduction

Human prosocial cooperation is essential for our collective health, education, and welfare, but cooperation is also difficult to maintain. When everyone pays taxes, societies can collectively benefit from public goods like roads, safety nets, and schools. However, individuals who do not contribute get to keep their wealth and still benefit from public goods. This "freeloading" behavior can eventually erode public trust and lead to a tragedy of the commons. Psychologists study this behavior in the lab using games like the public goods game (PPG) where a group of 3 or more people all decide how much to donate to a public fund. Public funds are multiplied then redistributed equally. If everyone donates, everyone is better off. However, if someone decides not to donate, they benefit more than others - they receive the public funds and get to keep their initial wealth. Eventually, this freeloading behavior discourages everyone else from donating, and public funds are emptied. Encouraging cooperation is thus important and psychologists have discovered many factors that affect prosocial behavior such as priming (positive framing), transparency (social pressure), and varying endowments (inequality).

However, human behavior in the lab is different than in the wild. In the lab, people's choices and actions are bounded: they only get to choose from a small set of options, such as a choice from a menu of how much to donate. But in the wild, choices are unbounded. Humans exhibit more complex behaviors including lying, cheating, persuasion, and gaming the system. These are often the behaviors that cause programs and policies to fail. They're also very difficult to foresee. Studying human behavior in the wild using experiments is very challenging. It requires large numbers of people interacting,

creating a control group or a matched sample to compare to, and numerous runs a to achieve statistical significance. This is almost never done, and thus policies affecting human cooperative behavior are rarely informed by experimental evidence.

Multi-agent LLM systems have the potential to simulate complex human behavior and interactions. They exhibit human-like behavior [26], including doing actions they were not explicitly told to do (emergent behavior), thus displaying the potential for unbounded actions. Beyond human-like behavior, LLMs and multi-agent LLM systems have also shown a capacity to replicate actual human behavior seen in lab studies. This includes 70 psychology experiments [2, 15], and multi-player economic games with strategic thinking about what other players will do, such as the multi-turn Ultimatum Game [31] and auctions [21]. For a simulation to be useful, it does not necessarily have to replicate human behavior exactly, but it does have to exhibit a rich enough set of actions consistent with behaviors that are observed, and provide evidence that the results can generalize to previously unseen situations. To lay the groundwork for a future where policy makers can ask LLM-agents to simulate human behavior in response to policy changes, we address the following questions:

- (1) Do multi-agent LLM systems understand human cooperative behavior well enough to simulate it, even in a lab setting?
- (2) Are multi-agent LLM systems simply echoing the results from previous papers, or can effects transfer across papers and apply more broadly?
- (3) To what extent are multi-agent LLMs complex enough to simulate the rich set of unbounded options, actions, and interactions people do in the real world, outside of the lab?
- (4) To see the complex interactions observed in the real world, what simulation mechanisms do we have to add to the set up of the system?

Our experiments show that multi-agent LLM systems replicate findings of three lab studies of human cooperative prosocial behavior, showing that LLM-agents are consistent with humans in their responses to priming, transparency and varying endowments. The simulation accurately replicated the direction of the effect (positive or negative), but often exaggerated the effect size. In addition to replicating the findings of previous studies, we show that multiagent LLM systems can apply insights from other games to the PGG. Specifically, we demonstrate that two priming effects previously studied in other games - but not tested in the PGG - also have a similar impact on behavior in the PGG. This indicates that multi-agent LLM systems are not simply echoing existing research but have a broader ability to simulate psychological mechanisms across different games, situations, and simulations.

We also show that for two real world situations, we do see complex, unbounded behavior consistent with anecdotal evidence. For a classroom scenario with a teacher testing various late policies, we find that when late policies are strict and assignments are hard, we can enable the behavior of cheating to emerge. For a shopping center parking lot scenario, we find that LLM-agents can be affected by external conditions like humans in returning or not returning their shopping cart. For both scenarios, simple mechanisms had to be added to the simulation to see these effects. For cheating, the simulation had to include communication channels like a private student room to initiate the communication needed for a behavior like cheating. For agents to not return their cart, their provided information had to allude to what was at stake as a result of their external condition.

Altogether, we conclude that multi-agent LLM systems show remarkable promise towards simulating human prosocial behavior. For broader real-world scenarios, we find that there remain additional mechanisms to identify in order for multi-agent LLM systems to simulate cooperative behavior, including (1) creating communication mechanisms that allow agents to coordinate behavior privately and (2) make sure the stakes (or incentives) driving behavior are clear. These are far from the only mechanisms needed, and there is much future work to discover more mechanisms, but there is reason to believe that these mechanisms will be broadly applicable across domains. Our simulations show that in the future, there is a potential for multi-agent LLM simulations to be useful in informing policy makers. Currently, LLM-agents can simulate the general direction of human behavioral effects, although they struggle to accurately capture the magnitude. While fine-tuning may improve this, it likely never perfectly replicates human behavior. Nevertheless, the ability to simulate directional trends can still help policymakers anticipate potential policy outcomes. Given the complexity and high social stakes of such decisions, even preliminary simulations could provide a valuable framework for exploring possible scenarios and guiding decision-making.
