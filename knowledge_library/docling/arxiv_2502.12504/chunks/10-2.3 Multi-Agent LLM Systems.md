## 2.3 Multi-Agent LLM Systems

Previously introduced multi-agent systems have varying capacities for allowing unbounded human behavior. Prior research has presented systems for simulating scenarios such as negotiations, bail hearings, job interviews, and auctions. In such systems, the action space is somewhat limited, with the system having rigid turn-taking guidelines and detailed information on how the simulation should proceed [21]. Similarly, ChatArena is a system which allows users to simulate turn-taking games: setups for tic-tac-toe, rock-paper-scissors, and chameleon are provided by default, while users can modify input information to simulate games such as the PGG. However, the system is again rigid in the actions agents can take and when agents can take such actions [33].

There are also multi-agent LLM systems in which LLM-agents are allowed more complexity and freedom in the ways they can "think" and act: these are referred to as "generative agents" [27]. MetaAgents is a framework in which agents have four modules: perception, memory, reasoning, and execution. Using a simulated environment of a job fair, the research studies agents' abilities to create teams and workflows for collaborative tasks, finding that agents show promising results in simulation [20]. Architectures have also been presented to simulate the inhabitants of a town. Agents have modules for observation, memory, reflection, planning, and reacting. Multiple locations can also be defined for agents to move between. In simulation, agents are found to demonstrate emergent behaviors, but not compared to observations of human actions explicitly [26].

Past work has also explored coupling large language models with simulation models to better represent human behavior and decision-making [11], as well as using LLMs to mediate between end-users and simulations [12]. However, there remains further room for exploration in identifying mechanisms within multi-agent systems themselves to achieve similar goals.

Whereas previous research shows that multi-agent LLM systems can simulate realistic human behavior, our work goes further showing that multi-agent LLM systems can simulate real observed human behavior in the lab. Additionally, we show that LLMs can simulate observed human behavior outside the lab, where there is an unbounded action space. For example, people can cheat.
