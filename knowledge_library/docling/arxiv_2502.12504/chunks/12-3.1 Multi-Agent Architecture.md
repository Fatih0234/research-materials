## 3.1 Multi-Agent Architecture

For all studies, we adapted a previously introduced and open-source multi-agent system for simulating social emergent behavior [1]. The system is implemented in Python and uses gpt-4o-mini. The input to the system is a JSON file describing the locations and agents in the simulation. The output is a series of logs for events (things done by agents and witnessed by other agents). The input files and system we use for the simulations in our studies are publicly available [32].

The system architecture consists of a class structure defined as follows. At the highest level, the simulation is represented by a world class consisting of 3 sub-classes: locations , events , and agents .

Locations represent places that agents can go within the world. Locations are specified by a name, description, and agents allowed within them. Agents can only talk to other agents or witness events in the same location as them. Events are created when agents take action, whether that be moving or speaking. Events are specified by a timestamp, the agent that acted, the location it occurred, a description, and witnesses.

Agents are separate LLM instances that are used to represent "people" in the environment. Agents are specified by a name, a private biography, a public biography and an initial plan. The private biography is information about the agent only known to the agent. The public biography is information about the agent that other agents also are aware of. The initial plan instructs the agent on what to do when the simulation starts. It is specified by a location (i.e., where it occurs), a description of what the agent should do, and a stop condition that specifies when the agent should stop executing on the plan. The initial plan is private - it is only known to the agent.

Agents have subclasses plans - specified by a description, location, and stop condition - and memories - specified by a description, creation time, and importance score. Plans are created by agents as they witness events in simulation. All plans are specified in the same format as the initial plan. Memories are created each time an agent witnesses an event. When a memory is created, an importance score is also created simply by asking an LLM to generate one. When agents act, they first identify memories that are relevant and use them to maintain or adjust their current plan before executing on their action.

Simulations can be run once the user specifies the locations and agents in the input file. The system executes simulation via agent loops , which involve (1) agents observing the events in their current location, (2) agents adding events to memory, (3) agents creating plans , (4) agents reacting as to whether or not to continue the current plan, (5) and agents acting , carrying out plans. Agents speak to communicate with one another. The agent loop is what enables emergent behavior - agents are able to "reason" about their surroundings and events and then decide on new courses of actions. This type of architecture has been shown to be more accurate in replicating human behavior in social science/economics games than just prompting a single LLM [31].

When implementing the PGG in this environment, we create 4-5 agents: 3-4 players, and one moderator. The private biography is used to provide agents with their unique priming or endowment that other agents should not know. There are typically two locations; a game room where players are by default, and a contribution room where players make their contribution. Players are aware of the existence of these locations and can move between them. In every agent loop, the agent waits for the player before them to come back from the contribution room, then goes to the contribution room, tells the moderator their contribution, the moderator records it to his memory, and the player agent leaves. When all the players are done, the moderator comes out and announces the game outcome.
