## 6.2.1 Setup.

Shopping-Cart Return Simulation Setup. There are three main necessary components for simulating the shopping-cart return setting: (1) people, (2) locations, and (3) instructions on what to act on. The simulation involves one person, a shopper, who is preparing to leave the parking lot and represented by a LLM-agent. The simulation requires two locations: (1) the area where the shopper has parked, and (2) the receptacle, where carts should be returned. The shopper agent knows these locations exist, and can decide whether or not to move between them. The shopper agent can be affected by conditions that affect their ability to return their cart (being far from the receptacle or having a child with them) [7]. The shopper is told to prepare to leave the parking lot and instructed that they cannot leave with their shopping cart - the shopper hence must decide something to do with their shopping cart.

Multi-Agent LLM Architecture Implementation. We implement the simulation by adapting the same architecture as in the previous studies. When implementing the shopping-cart return setting in the

% of Simulations with Cheating by Classroom Conditions and With or Without Rooms

70

60â€¢

Cheating

% of Simulations with

40

20

10

0

Without Rooms

With Rooms

Figure 6: Percentage of simulations in which cheating was observed under the 9 late policy and perturbation conditions, for simulations with and without multiple locations. Without multiple locations, cheating is never observed. With multiple locations, cheating first begins to be observed under the medium late policy under the one perturbation condition. The number of simulations in which cheating occurs is the same for the medium late policy in the two perturbation condition, as well as for the harsh late policy under the no perturbation and one perturbation conditions. The number of simulations in which cheating occurs is greatest with the harsh late policy under the two perturbation condition.

<!-- image -->

multi-agent framework, we initialize it accordingly. The shopper agent is given the name "Shopper." The shopper agent has a blank public biography. The shopper agent's private biography states that they have a cart, and conditions that affect their ability to return their cart. The shopper agent has an initial plan to prepare to leave the parking lot, then instructions to act on the outcomes of their initial plan. We create two locations: (1) which represents the area where the shopper has parked and (2) the designated shopping-cart return receptacle. This way, we capture that LLM-agents must move in order to return their shopping cart.

However, we find that simply stating the condition affecting the shopper's ability to return their cart ("you are far from the receptacle," and "you have a child") is insufficient to have the desired effect of shoppers returning their carts less frequently; the prompt must allude towards what is at stake ("you are parked across the parking lot from the receptacle," and "you have a five-month old child"). In the condition where shoppers are far from the receptacle, adding that shoppers are " parked across the parking lot " alludes to the fact that going to receptacle will take effort, whereas adding that the child is an infant alludes to the fact that the child cannot be left unattended. We present this as stake-prompting (SP), a mechanism to have prompts allude to what is at stake, using which LLM-agents can be guided towards demonstrating more human-like behavior in simulation.

Data Collection. As the simulation progresses, all of the thoughts and actions of the shopper agent are displayed in an output log. The output log contains a plethora of information, ranging from the events the agent observed (which is minimal in this simulation), their reactions to them (similarly minimal), and the creation of new plans. But we are only interested in recording whether or not the shopper agent returns their cart, based on whether the shopper agent moves to the receptacle location. A human manually recorded this information and formatted it into a table.

6.2.2 Methodology. We run simulations with two different conditions that shoppers can be affected by: (1) being far from the receptacle (FFR) and (2) having a child (HAC). We run five simulations each of either condition under with and without stake-prompting. Given that the condition affecting the shopper should influence them to not return their shopping cart, we track whether or not the shopping cart is returned in each simulation and then compare

Percentage of Simulations Cart Returned

Effect of Stake-Prompting on Cart Return by Condition

Without SP

With SP

the frequency of returns between simulations with and without stake-prompting.

6.2.3 Results. In simulations without stake-prompting, we find that shopper agents still frequently return their carts despite the conditions affecting their ability to do so. However, alluding to what is at stake as a result of the condition causes shopper agents to stop returning their carts as often. The results are summarized in Figure 7. From these results, we conclude that alluding to what is at stake via stake-prompting causes LLM-agents to demonstrate less prosocial behavior when affected by personal conditions, like humans.

Figure 7: Percentage of simulations in which the shopper agent decided to their shopping cart for both external conditions tested and under either prompting condition: with or without stake-prompting. LLM-Agents returned their cart less frequently with stake-prompting than without.

<!-- image -->
