## Introduction

Recent advances in Large Language Models (LLMs) have sparked growing interest in their ability to reproduce social and psychological behaviors, leading to active research on simulating human-like judgment and choice patterns (Park et al. 2024, 2023; Wang et al. 2023; Cheng, Piccardi, and Yang 2023; Huang et al. 2024; Choi et al. 2025). Of particular note is the approach of injecting personas into LLMs to mimic human attitudes, personality traits, value judgments, and choice behaviors. However, most prior studies have focused on evaluating general tendencies without precise behavioral comparisons with actual humans, employing methods such as generating fictional personas to simulate human social phenomena, creating personas using demographic information, or extracting personas from existing QA datasets

(Horton 2023; Hewitt et al. 2024; Leng and Yuan 2023; Ross, Kim, and Lo 2024; Leng 2024a; Xie et al. 2024b).

To our knowledge, Park et al. (2024) is the only study analyzing actual human behavior, achieving 85% accuracy in reproducing General Social Survey responses from interview data. However, this study focused on psychological surveys rather than economic decision-making involving monetary costs. Simple attitudinal survey can elicit idealistic responses without realistic constraints, making it difficult to reflect actual decision making. Economic decision-making requiring willingness to pay involves complex cognitive processes where budget constraints, opportunity costs, and cultural interact, providing a more precise foundation for evaluating LLMs' human-like behavior reproduction.

To bridge this gap, we designed economic decisionmaking experiment using Pay-What-You-Want (Kim, Natter, and Spann (2009); PWYW) pricing, where consumers voluntarily determine payment amounts. This involves complex psychological factors including willingness to pay, income, cultural values, and individual value systems (Kim, Natter, and Spann 2009; Gerpott 2017), providing a valid framework for analyzing individual decision-making and evaluating how sophisticatedly LLMs can simulate actual individual human choices. Unlike previous studies evaluating general tendencies with fictional personas, we apply identical experimental structures to LLMs using detailed persona information from 522 actual participants and their decisionmaking data, analyzing how persona structure affects LLM choices and evaluating both group-level choice tendencies and individual-level prediction consistency. Therefore, this study evaluates how precisely LLMs can predict individual behaviors based on actual human personas within PWYW contexts. We systematically examine LLMs' human-like behavior reproduction using various models and persona injection methods through two key research questions.

- RQ1. Can LLMs predict economic decision of human individual in sequential or human-guided condition?

The first research question examines whether LLMs can reproduce decision-making patterns similar to correspond- ing human participants when injected with individual persona information. We construct individualized personas encompassing each participant's educational background, cultural experiences, value systems, and consumption tendencies, then input these into various LLMs to predict willingness-to-pay amounts and choice behaviors for the same cultural products. Based on prior studies (Lampinen et al. 2022; Wei et al. 2025) showing that errors may accumulate as LLMs construct subsequent judgments based on previous responses, we analyze the impact of response accumulation on prediction performance. We establish two experimental conditions: 1) Sequential Condition, where LLMs maintain their previous responses and answer all items sequentially, and 2) Human-guided Condition, where actual human responses are inserted into the conversation history to inform subsequent questions. Through this design, we directly compare LLMs' predictions with actual human responses and quantitatively evaluate both individual-level accuracy and group-level tendencies.

- RQ2. How do persona formats and prompting methods affect LLMs' ability in simulating human behavior?

The second research question analyzes how LLMs' prediction performance varies depending on persona composition and injection methods. While previous studies show LLMs respond sensitively to contextual changes (Sclar et al. 2023; Zhuo et al. 2024; Razavi et al. 2025), no systematic comparison exists regarding which methods are more effective for predicting human behavior. This study establishes persona injection along two axes: (1) Format: Survey vs. Storytelling (i.e., biographical narratives), and (2) Prompting Methods: base prompt, CoT (Wei et al. 2022), RAG (Lewis et al. 2020), and Few-shot Prompting (Brown et al. 2020). By applying identical conditions across different models, we analyze performance differences between models and evaluate how method variations are reflected in individual-level accuracy and group-level tendencies.

Based on this research design, this study provides two major contributions. First, we systematically validate the extent to which LLMs can precisely mimic individual human decision-making at both group and individual levels, based on sophisticated persona and decision-making data collected from actual human participants. This represents one of the first studies to evaluate LLMs' ability to predict specific humans' actual choice behaviors, advancing the precision of LLM human simulation research to the next level. Second, by comparing how LLMs' behavioral prediction performance varies according to persona composition and injection methods even with identical information, we provide empirical evidence for appropriate LLM utilization methods for future human-like behavior generation and simulation.
