## 4.1 FOUNDATIONAL VALIDATION

Experimental Setup For reproducibility, we reimplemented agents from eight benchmark tasks using our modular components to match their original implementation. For comparability, we conducted cross-task generalization studies, evaluating how these agents, each with a different cognitive architecture (e.g., with or without tools), perform in unseen environments. All detailed experimental settings are provided in Appendices C.2 and C.3.

Reproducibility Our reproducibility results show that Shachi faithfully replicates prior findings. As shown in Table 1, our implementation achieves significantly lower Mean Absolute Error (MAE) compared to baselines across all tasks, confirming that our components accurately capture the behavior of the original, bespoke models. We also qualitatively verify that our framework reproduces fine-grained system dynamics, such as temporal stock price evolution and auction bidding patterns (visualizations are in Appendix C.2).

Table 1: Reproduction Results. We report the mean absolute error (MAE) for the ported tasks. Shachi consistently achieves lower errors when compared with the baselines.

|               | PsychoBench       | CoMPosT    | CognitiveBiases   | EmotionBench   |
|---------------|-------------------|------------|-------------------|----------------|
| Baseline      | 1.96              | 0.23       | 0.24              | 13.82          |
| Shachi (Ours) | 0.80              | 0.06       | 0.04              | 3.37           |
|               | EmergentAnalogies | StockAgent | AuctionArena      | Sotopia        |
| Baseline      | 0.64              | 9.07       | 10.49             | 3.17           |
| Shachi (Ours) | 0.05              | 2.63       | 2.22              | 0.95           |

Comparability The cross-task generalization results in Table 2 highlight the critical role of the cognitive architecture. While simpler tasks can be solved by minimal agents, performance in complex environments is highly dependent on the available components. For instance, an agent equipped with a full suite of components including Tools (e.g., StockAgent) generalizes effectively to other complex tasks. Conversely, agents lacking necessary components, such as Tools and Memory modules, fail when transferred to environments that require them. This demonstrates that Shachi's modularity is crucial for systematically studying and building agents with robust, generalizable capabilities.

Table 2: Cross-Task Agent Generalization. Scores in each column are normalized against the one on the diagonal. Agents with all the components (i.e., StockAgent) maintain stable performance when transferred to other tasks.

|                                |   EmergentAnalogies |   StockAgent |   AuctionArena |   Sotopia |
|--------------------------------|---------------------|--------------|----------------|-----------|
| EmergentAnalogies              |                1    |         1.08 |           0.62 |      1.01 |
| StockAgent (config, mem, tool) |                1.01 |         1    |           0.99 |      1    |
| AuctionArena (config, mem)     |                1    |         0.93 |           1    |      0.99 |
| Sotopia (mem)                  |                1    |         0.93 |           0.92 |      1    |
