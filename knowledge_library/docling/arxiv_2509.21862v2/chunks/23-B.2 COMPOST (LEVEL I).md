## B.2 COMPOST (LEVEL I)

Description CoMPosT (Cheng et al., 2023) investigates how susceptible large language models (LLMs) are to caricature.

Method To quantify this effect, the framework decomposes caricature into four orthogonal dimensionscontext , model , persona , and topic -which specify the simulated scenario, the LLM configuration, the target opinion, and the domain of discourse, respectively. Two metrics are introduced: the individuation score , which tests whether the simulated persona is distinguishable from the default persona, and the exaggeration score , which measures the degree to which the simulation amplifies persona-topic features.

Experimental Settings In our reproduction study (Table 1), we use GPT-3.5-turbo ( gpt-3.5-turbo-0125 ) as the LLM component without a memory component. The task includes neither config nor tool components. We compare the scores produced by our implementation (and a baseline) with those reported in the original paper. Although we replicate the experimental setup as faithfully as possible, minor differences arise owing to updates in the underlying LLMs. Each method outputs a distribution of scores. We assess similarity between two such distributions via one-dimensional optimal transport with the absolute difference as the cost function. In this setting, the transport cost simplifies to MAE between the paired, sorted samples of the distributions, following Bonnotte (2013). The evaluation takes approximately 20 minutes.
