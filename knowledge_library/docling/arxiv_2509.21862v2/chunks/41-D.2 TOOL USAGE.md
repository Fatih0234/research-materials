## D.2 TOOL USAGE

In this framework, the environment provides a tool component that the agent can dynamically call through an LLM. The agent sends observations to the LLM, which may respond with tool call instructions. The agent executes these tools, returns their outputs, and continues the conversation until no more tool calls are needed. The final LLM response thus incorporates results from any tools. Listing 2 shows a minimal implementation of this process.

```
1 async def step(self, observation: kujira.base.Observation) -> str: 2 prompt = observation.format_as_prompt_text() 3 available_tools = observation.tools 4 5 # Convert tool information for LLM 6 tools_for_llm = [ 7 { 8 "type": "function", 9 "function": { 10 "name": tool.name, 11 "description": tool.description, 12 "parameters": tool.parameters_type.model_json_schema(), 13 }, 14 } 15 for tool in available_tools
```

```
16 ] 17 18 # Chat history with proper typing 19 messages: list[dict[str, Any]] = [{"role": "user", "content": prompt }] 20 21 # Allow up to 5 tool calls 22 for _ in range(5): 23 completion = await litellm.acompletion( 24 messages=messages, 25 model=self.model, 26 tools=tools_for_llm, 27 tool_choice="auto", 28 ) 29 assistant_message = completion.choices[0].message 30 31 # Add message to chat history with proper typing 32 message_entry: dict[str, Any] = { 33 "role": "assistant", 34 "content": assistant_message.content 35 if assistant_message.content is not None 36 else "", 37 } 38 if hasattr(assistant_message, "tool_calls") and assistant_message .tool_calls: 39 message_entry["tool_calls"] = assistant_message.tool_calls 40 messages.append(message_entry) 41 42 # If no tool calls, exit 43 if not hasattr(assistant_message, "tool_calls") or not assistant_message.tool_calls: 44 return assistant_message.content if assistant_message.content is not None else "" 45 46 # Process tool calls 47 for tool_call in assistant_message.tool_calls: 48 function_name = tool_call.function.name 49 function_args = tool_call.function.arguments 50 51 # Find corresponding tool 52 matching_tool = None 53 for tool in available_tools: 54 if tool.name == function_name: 55 matching_tool = tool 56 break 57 58 if matching_tool: 59 # Execute tool 60 try: 61 parameters = matching_tool.parameters_type. model_validate_json( 62 function_args 63 ) 64 tool_response = matching_tool.fun(parameters) 65 response_text = tool_response.format_as_prompt_text() 66 67 # Add tool response to chat history with proper typing 68 tool_message: dict[str, Any] = { 69 "role": "tool", 70 "tool_call_id": tool_call.id, 71 "name": function_name, 72 "content": response_text, 73 } 74 messages.append(tool_message)
```

```
75 76 print(f"Tool call: {function_name}") 77 print(f"Arguments: {function_args}") 78 print(f"Response: {response_text}") 79 except Exception as e: 80 print(f"Error occurred during tool execution: {str(e) }") 81 82 # Get final response 83 final_completion = await litellm.acompletion( 84 messages=messages, 85 model=self.model, 86 ) 87 return ( 88 final_completion.choices[0].message.content 89 if final_completion.choices[0].message.content is not None 90 else "" 91 )
```

Listing 2: Example code for the tool usage in our framework.
