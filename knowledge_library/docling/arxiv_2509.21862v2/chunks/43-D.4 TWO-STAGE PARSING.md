## D.4 TWO-STAGE PARSING

Listing 4 presents a minimal example of how agents employ two-stage parsing in Shachi. To generate outputs in the required format without harming LLM performance, we leverage API features such as structured outputs and function calls, together with the two-stage parsing strategy.

```
1 async def call_llm( 2 messages: list[dict[str, str]], 3 model: str, 4 temperature: float, 5 parsing_mode: PARSING_MODE, 6 parsing_model: str | None = "gpt-4.1-mini-2025-04-14", 7 response_type: TResponseType | None = None, 8 ) -> str | TResponseType: 9 10 # First stage: generate in a plain text 11 completion1 = await litellm.acompletion( 12 messages=messages,
```

```
13 model=model, 14 temperature=temperature, 15 max_retries=MAX_RETRIES, 16 ) 17 response_text_1: str = completion1.choices[0].message.content 18 19 # Second stage: parse the plain text into a structured output 20 completion2 = await litellm.acompletion( 21 messages=[ 22 { 23 "role": "user", 24 "content": f""" 25 Based on the text provided below, output JSON. If the input is plain text , 26 extract the necessary information while preserving the original wording 27 as much as possible. If the input is JSON, output it unchanged, except 28 fix any formatting errors you find. 29 ''' 30 {response_text_1} 31 ''' 32 33 The JSON should follow the schema below: 34 ''' 35 {response_type.model_json_schema()} 36 ''' 37 """.strip(), 38 }, 39 ], 40 model=parsing_model, 41 temperature=temperature, 42 response_format=response_type, 43 max_retries=MAX_RETRIES, 44 ) 45 response_text: str = completion2.choices[0].message.content 46 response_obj = response_type.model_validate_json(response_text) 47 return response_obj
```

Listing 4: Example code for the two-stage parsing used in our framework.
