## 2 Related Works

LLM agents are AI systems where pre-trained LLMs are embedded in a decision-making loop to execute multi-step, multi-turn tasks using external tools autonomously (Chowa et al. 2025; Ferrag, Tihanyi, and Debbah 2025; Wang et al. 2025). Context windows have expanded significantly from 2K tokens in GPT-3 to 2M in Grok 4 Fast, enabled by improved position embeddings and attention mechanisms (Su et al. 2021; Dao et al. 2022). However, LLMs often exhibit recency bias and poor recall of distant tokens (Wang et al. 2024b; Shan et al. 2025), with benchmarks like NIAH and LongBench (Bai et al. 2024; Kuratov et al. 2024) showing that expanding context windows improves capacity but not capability (Liu et al. 2025). LLM safety benchmarking covers toxicity, misinformation, and jailbreaks (Shi et al. 2024; Wang et al. 2024a), with LongSafety (Lu et al. 2025) evaluating long-context inputs ( 5K tokens). Agent safety benchmarking covers interactive tasks: AgentSecurity and Agent-

Figure 1: Overview of our AgentHarm evaluation with after context padding (padding inserted immediately after the task description). We also consider a before position, where padding is inserted between the system prompt and the task. Unless noted, we report on the simplest public test subset: tasks with both a hint and detailed instructions that all models solve without padding. This lets us focus on behavior under padding instead of raw capability. Scoring combines two binary judges (refusal and semantic) with a rubric-based Harm Score that checks criteria such as whether all target tools were invoked and in the correct order. For this paper we focus on Harm Score and refusal rate as our main metrics.

<!-- image -->

Dojo evaluate robustness against prompt injection (Zhang et al. 2025; Debenedetti et al. 2024), while RedCode and MobileSafetyBench assess code execution risks (Guo et al. 2024; Lee et al. 2024). Most relevant, AgentHarm (Andriushchenko et al. 2025) evaluates refusal behavior on harmful tasks and ability to execute multi-step agentic workflows.
