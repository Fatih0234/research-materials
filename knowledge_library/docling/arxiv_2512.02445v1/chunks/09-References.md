## References

Andriushchenko, M.; Souly, A.; Dziemian, M.; Duenas, D.; Lin, M.; Wang, J.; Hendrycks, D.; Zou, A.; Kolter, Z.; Fredrikson, M.; Winsor, E.; Wynne, J.; Gal, Y.; and Davies, X. 2025. AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents. arXiv:2410.09024.

Bai, Y.; Lv, X.; Zhang, J.; Lyu, H.; Tang, J.; Huang, Z.; Du, Z.; Liu, X.; Zeng, A.; Hou, L.; Dong, Y.; Tang, J.; and Li, J. 2024. LongBench: A Bilingual, Multitask Benchmark for Long Context Understanding. arXiv:2308.14508.

Burnham, G.; and Adamczewski, T. 2025. LLMs now accept longer inputs, and the best models can use them more effectively. https://epoch.ai/data-insights/context-windows. Accessed: 2025-10-15.

Chowa, S. S.; Alvi, R.; Rahman, S. S.; Rahman, M. A.; Raiaan, M. A. K.; Islam, M. R.; Hussain, M.; and Azam, S. 2025. From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users. arXiv:2508.17281.

Dao, T.; Fu, D. Y.; Ermon, S.; Rudra, A.; and R´ e, C. 2022. FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness. arXiv:2205.14135.

Debenedetti, E.; Zhang, J.; Balunovi´ c, M.; Beurer-Kellner, L.; Fischer, M.; and Tram` er, F. 2024. AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents. arXiv:2406.13352.

Denain, J.-S.; and Ho, A. 2025. The huge potential implications of long-context inference. https://epoch.ai/gradient-updates/the-huge-potentialimplications-of-long-context-inference. Accessed: 2025-10-

15.

Ferrag, M. A.; Tihanyi, N.; and Debbah, M. 2025. From LLM Reasoning to Autonomous AI Agents: A Comprehensive Review. arXiv:2504.19678.

Guo, C.; Liu, X.; Xie, C.; Zhou, A.; Zeng, Y.; Lin, Z.; Song, D.; and Li, B. 2024. RedCode: Risky Code Execution and Generation Benchmark for Code Agents. arXiv:2411.07781.

Kuratov, Y.; Bulatov, A.; Anokhin, P.; Rodkin, I.; Sorokin, D.; Sorokin, A.; and Burtsev, M. 2024. BABILong: Testing the Limits of LLMs with Long Context Reasoning-in-aHaystack. In Advances in Neural Information Processing Systems (NeurIPS) .

Lee, J.; Hahm, D.; Choi, J. S.; Knox, W. B.; and Lee, K. 2024. MobileSafetyBench: Evaluating Safety of Autonomous Agents in Mobile Device Control. arXiv:2410.17520.

Liu, J.; Zhu, D.; Bai, Z.; He, Y.; Liao, H.; Que, H.; Wang, Z.; Zhang, C.; Zhang, G.; Zhang, J.; Zhang, Y.; Chen, Z.;

Guo, H.; Li, S.; Liu, Z.; Shan, Y.; Song, Y.; Tian, J.; Wu, W.; Zhou, Z.; Zhu, R.; Feng, J.; Gao, Y.; He, S.; Li, Z.; Liu, T.; Meng, F.; Su, W.; Tan, Y.; Wang, Z.; Yang, J.; Ye, W.; Zheng, B.; Zhou, W.; Huang, W.; Li, S.; and Zhang, Z. 2025. A Comprehensive Survey on Long Context Language Modeling. arXiv:2503.17407.

Liu, N. F.; Lin, K.; Hewitt, J.; Paranjape, A.; Bevilacqua, M.; Petroni, F.; and Liang, P. 2024. Lost in the Middle: How Language Models Use Long Contexts. Transactions of the Association for Computational Linguistics , 12: 157-173.

Lu, Y.; Cheng, J.; Zhang, Z.; Cui, S.; Wang, C.; Gu, X.; Dong, Y.; Tang, J.; Wang, H.; and Huang, M. 2025. LongSafety: Evaluating Long-Context Safety of Large Language Models. arXiv:2502.16971.

Shan, L.; Luo, S.; Zhu, Z.; Yuan, Y.; and Wu, Y. 2025. Cognitive Memory in Large Language Models. arXiv:2504.02441. Shi, D.; Shen, T.; Huang, Y.; Li, Z.; Leng, Y.; Jin, R.; Liu, C.; Wu, X.; Guo, Z.; Yu, L.; Shi, L.; Jiang, B.; and Xiong, D. 2024. Large Language Model Safety: A Holistic Survey. arXiv:2412.17686.

Su, J.; Lu, Y.; Pan, S.; Murtadha, A.; Wen, B.; and Liu, Y. 2021. RoFormer: Enhanced Transformer with Rotary Position Embedding. arXiv:2104.09864.

Wang, B.; Chen, W.; Pei, H.; Xie, C.; Kang, M.; Zhang, C.; Xu, C.; Xiong, Z.; Dutta, R.; Schaeffer, R.; Truong, S. T.; Arora, S.; Mazeika, M.; Hendrycks, D.; Lin, Z.; Cheng, Y.; Koyejo, S.; Song, D.; and Li, B. 2024a. DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models. arXiv:2306.11698.

Wang, H.; Qian, C.; Li, M.; Qiu, J.; Xue, B.; Wang, M.; Ji, H.; and Wong, K.-F. 2025. Toward a Theory of Agents as Tool-Use Decision-Makers. arXiv:2506.00886.

Wang, M.; Chen, L.; Fu, C.; Liao, S.; Zhang, X.; Wu, B.; Yu, H.; Xu, N.; Zhang, L.; Li, Y.; Yang, M.; Huang, F.; and Li, Y. 2024b. Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA. arXiv:2406.17419.

Xie, T.; Qi, X.; Zeng, Y.; Huang, Y.; Sehwag, U. M.; Huang, K.; He, L.; Wei, B.; Li, D.; Sheng, Y.; Jia, R.; Li, B.; Li, K.; Chen, D.; Henderson, P.; and Mittal, P. 2025. SORRYBench: Systematically Evaluating Large Language Model Safety Refusal. arXiv:2406.14598.

Zhang, Z.; Cui, S.; Lu, Y.; Zhou, J.; Yang, J.; Wang, H.; and Huang, M. 2025. Agent-SafetyBench: Evaluating the Safety of LLM Agents. arXiv:2412.14470.

Zheng, L.; Chiang, W.-L.; Sheng, Y.; Zhuang, S.; Wu, Z.; Zhuang, Y.; Lin, Z.; Li, Z.; Li, D.; Xing, E.; Zhang, H.; Gonzalez, J. E.; and Stoica, I. 2023. Judging LLM-as-aJudge with MT-Bench and Chatbot Arena. In Advances in Neural Information Processing Systems (NeurIPS) .
