## F Creation of Different Paddings

RandomPadding. Wesampled random tokens from o200k base with fixed random seed to create random padding and used the same padding for each tested model. For DeepSeek-V3.1 we used associated tokenizer to adjust number of tokens accordingly, but for other models we either assume similar tokenizer is used or tokenizer is not available (e.g. Grok 4 Fast).

Non-relevant Padding. We adopt the following method for creating non-relevant padding in experiments. We first pick publicly available fiction literature on five different genres: humor, mythology, sci-fi, crime, and romance. Second, preprocess each piece of literature to remove the paratext. After that, we merge texts for each genre in one single text. We ended up with 5 pieces of long texts, each containing around 4 million English words. During our experiments, we randomly pick a genre and select a chunk of text with the specific padding length from the selected text.

Relevant Padding. The main challenge while collecting relevant padding is to avoid collecting content that could influence model performance. If this padding provides hint to solving the task, model performance will increase. If this padding provides relevant information for categories like disinformation, hate speech or fraud this could increase refusal rate. We collect this padding as follows: the Wikipedia page for the task category is used as a starting point. From there we add articles on relevant topics, usually contained as hyper- links in the main article. We also collected relevant padding from academic textbooks of the topics that were related but not directly about the categories. We assume that as AgentHarm focuses on tool calling, this padding will not provide any hints for the model.

Multi-task Padding. To get multi-task padding we use tasks from both harmful and benign validation datasets. We use all combinations of task description, hint, and detailed prompt to maximally increase the size of the final set from which we are sampling. For multi-task padding that larger than the size of this set, we use replacement sampling. When samples are drawn, we convert the multi-task padding into tokens using the same tokenizer as for random padding to keep lengths comparable. To have a clear separation between padded tasks and the main task, we add a specific prompt (see Section G).
