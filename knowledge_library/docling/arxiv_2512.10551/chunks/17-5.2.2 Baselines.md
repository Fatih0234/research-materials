## 5.2.2 Baselines

- Pre-trained LLM : Base LLM without fine-tuning.
- MOSAIC [Soumalias et al., 2025]: A state-of-the-art advertising mechanism for LLMs that optimizes allocation by sampling multiple LLM responses during inference. We re-implement this method using our own reward model, adhering to the original paper's configuration of sampling 20 response candidates per query.
- LLM-Auction (Oracle) : In our simulated environment, we can obtain click feedback directly from the User-LLM for different responses for the same query, which can serve as an approximate ideal pCTR model. We train an

1 Our work primarily focuses on the mechanism's performance and incentive properties. To highlight the ad and facilitate its recognition by the User-LLM, we adopt the insertion format of @ad\_title@[ad\_id] . Currently, we do not incorporate a consistency verification between the original ad information and the ad content within the generated response. To ensure faithfulness, we restrict the Ad-LLM from changing the ad title.

2

5

5

6

Table 1: An example from our LLM-native advertising simulation environment. To highlight the clickable ads, we adopt the insertion format of @ad\_title@[ad\_id] . The relevant ad texts are marked with blue underlines. In practical applications, a more user-friendly display style can be adopted.
