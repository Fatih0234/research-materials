## 5.3 Comparison of Allocation Efficiency

Table 2: Main results on our proposed LLM-native advertising simulation environment.

| Method                          |   Revenue per Query |   Reward per Query |
|---------------------------------|---------------------|--------------------|
| Pretrained LLM                  |               46.88 |            -120.11 |
| MOSAIC [Soumalias et al., 2025] |               73.29 |              24.95 |
| LLM-Auction (pCTR)              |              125.28 |              54.13 |
| LLM-Auction (Oracle)            |              174.64 |             109.64 |

We compare our proposed mechanism with the baseline methods. The results are shown in Table 2, which demonstrate that our proposed LLM-Auction mechanism achieves significant improvements in allocation efficiency.

First, in terms of revenue per query, LLM-Auction achieves approximately 3Ã— higher average revenue compared to the pre-trained LLM baseline, and a remarkable 70.9% relative improvement over the state-of-the-art MOSAIC mechanism. This indicates that LLM-Auction effectively increases ad revenue. Second, in terms of the reward per query, which comprehensively reflects both ad revenue and user experience, LLM-Auction surpasses the best-performing baseline, MOSAIC, by 117.0% , demonstrating its superior capability in delivering personalized ad content while better adhering to the prescribed ad insertion formats. This also highlights the scalability of the LLM-Auction framework in industrial scenarios. By incorporating product-specific constraints into Eq. (5), we can obtain an LLM that generates responses satisfying customized requirements. In addition, when trained with real User-LLM feedback (i.e., LLM-Auction (Oracle)), the mechanism's performance shows further significant improvement. This suggests substantial room for growth as the accuracy of the pCTR model increases, validating the effectiveness of our proposed learning-based generative auction mechanism.
