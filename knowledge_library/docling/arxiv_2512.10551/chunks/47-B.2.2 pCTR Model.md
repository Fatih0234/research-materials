## B.2.2 pCTR Model

Input features and embeddings. The model takes four primary inputs: the user query, the ad-integrated response, the user ID, and the ad ID. Both the user query and the ad-integrated response are encoded into 1024-dimensional text embeddings using the Qwen3-Embedding-0.6B model [Zhang et al., 2025a], with a maximum sequence length of 2048. The user ID and ad ID are mapped into learnable embeddings of 64 and 32 dimensions, respectively.

Network architecture. These embeddings are concatenated and processed by a 3-layer multilayer perceptron (MLP) network. The hidden dimensions of the MLP layers are 128, 64, and 32, sequentially. A final linear layer followed by a sigmoid activation function produces the output logit for the Binary Cross-Entropy (BCE) loss calculation.

Training procedure. The pCTR model is trained with a batch size of 256. The text encoder is frozen throughout the training process. We use the Adam optimizer with a learning rate of 1 Ã— 10 -3 .
