[
  {
    "title": "preamble",
    "level": 1,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/01-preamble.md"
  },
  {
    "title": "LLM Agents Transformed Various Applications",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/02-LLM Agents Transformed Various Applications.md"
  },
  {
    "title": "Agent Safety",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/03-Agent Safety.md"
  },
  {
    "title": "Agent Overview",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/04-Agent Overview.md"
  },
  {
    "title": "Multi-agent Systems",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/05-Multi-agent Systems.md"
  },
  {
    "title": "What are LLM-Powered Agents?",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/06-What are LLM-Powered Agents-.md"
  },
  {
    "title": "Agentic Safety Risks",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/07-Agentic Safety Risks.md"
  },
  {
    "title": "Emergent safety risks in agentic system",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/08-Emergent safety risks in agentic system.md"
  },
  {
    "title": "Agent Safety Evaluation",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/09-Agent Safety Evaluation.md"
  },
  {
    "title": "Embodiment Agent",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/10-Embodiment Agent.md"
  },
  {
    "title": "How to evaluate agent safety?",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/11-How to evaluate agent safety-.md"
  },
  {
    "title": "Tool-Use Agent",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/12-Tool-Use Agent.md"
  },
  {
    "title": "What are Tool-Use Agents?",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/13-What are Tool-Use Agents-.md"
  },
  {
    "title": "A tool is:",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/14-A tool is-.md"
  },
  {
    "title": "Tool-Use Agent",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/15-Tool-Use Agent.md"
  },
  {
    "title": "Example Tools",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/16-Example Tools.md"
  },
  {
    "title": "Tool-Use Agent",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/17-Tool-Use Agent.md"
  },
  {
    "title": "ToolEmu",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/18-ToolEmu.md"
  },
  {
    "title": "Tool-Use Agent",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/19-Tool-Use Agent.md"
  },
  {
    "title": "Erroneous Use Cases",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/20-Erroneous Use Cases.md"
  },
  {
    "title": "Tool-Use Agent",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/21-Tool-Use Agent.md"
  },
  {
    "title": "Erroneous Use Cases",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/22-Erroneous Use Cases.md"
  },
  {
    "title": "Tool-Use Agent",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/23-Tool-Use Agent.md"
  },
  {
    "title": "Erroneous Use Cases",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/24-Erroneous Use Cases.md"
  },
  {
    "title": "Code Agents",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/25-Code Agents.md"
  },
  {
    "title": "RedCode",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/26-RedCode.md"
  },
  {
    "title": "Code Agents",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/27-Code Agents.md"
  },
  {
    "title": "Web Agents",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/28-Web Agents.md"
  },
  {
    "title": "Web Agents",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/29-Web Agents.md"
  },
  {
    "title": "Web Agents",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/30-Web Agents.md"
  },
  {
    "title": "VLM Web Agent",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/31-VLM Web Agent.md"
  },
  {
    "title": "Web Agents",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/32-Web Agents.md"
  },
  {
    "title": "Human-AI Agent Risks",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/33-Human-AI Agent Risks.md"
  },
  {
    "title": "User Agent Interaction",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/34-User Agent Interaction.md"
  },
  {
    "title": "HAICoystem",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/35-HAICoystem.md"
  },
  {
    "title": "Malicious User",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/36-Malicious User.md"
  },
  {
    "title": "Benign User",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/37-Benign User.md"
  },
  {
    "title": "Privacy Leakage",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/38-Privacy Leakage.md"
  },
  {
    "title": "PrivacyLens",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/39-PrivacyLens.md"
  },
  {
    "title": "Data Type: personal traumatic experience",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/40-Data Type- personal traumatic experience.md"
  },
  {
    "title": "User Instruction: Respond to Emily's message on Messenger with insights that could help her with the",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/41-User Instruction- Respond to Emily's message on Messenger with insights that could help her with the.md"
  },
  {
    "title": "Misplaced Trust &amp; Overreliance",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/42-Misplaced Trust &amp; Overreliance.md"
  },
  {
    "title": "Multi-Agent Safety Risks",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/43-Multi-Agent Safety Risks.md"
  },
  {
    "title": "https://arxiv.org/pdf/2503.13657",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/44-https---arxiv.org-pdf-2503.13657.md"
  },
  {
    "title": "Multi-Agent Systems Unlock New Frontiers in AI Safety",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/45-Multi-Agent Systems Unlock New Frontiers in AI Safety.md"
  },
  {
    "title": "Why?",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/46-Why-.md"
  },
  {
    "title": "Potential applications:",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/47-Potential applications-.md"
  },
  {
    "title": "Scalable Oversight",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/48-Scalable Oversight.md"
  },
  {
    "title": "Core challenge:",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/49-Core challenge-.md"
  },
  {
    "title": "Principles:",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/50-Principles-.md"
  },
  {
    "title": "Why Do We Need It?",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/51-Why Do We Need It-.md"
  },
  {
    "title": "Scalable Oversight: AI Debates",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/52-Scalable Oversight- AI Debates.md"
  },
  {
    "title": "Scalable Oversight: AI Debates Aids Assessment of Controversial Claims",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/53-Scalable Oversight- AI Debates Aids Assessment of Controversial Claims.md"
  },
  {
    "title": "COVID 19 Factuality Claims",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/54-COVID 19 Factuality Claims.md"
  },
  {
    "title": "Scalable Oversight: Interactive Debates is Even More Effective",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/55-Scalable Oversight- Interactive Debates is Even More Effective.md"
  },
  {
    "title": "Co-Evolving Red-Teamer and Safety Classifier",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/56-Co-Evolving Red-Teamer and Safety Classifier.md"
  },
  {
    "title": "Online Self-Play Multi-Agent RL Training for Safer LMs",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/57-Online Self-Play Multi-Agent RL Training for Safer LMs.md"
  },
  {
    "title": "Zero-Sum Adversarial Red-Teaming",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/58-Zero-Sum Adversarial Red-Teaming.md"
  },
  {
    "title": "Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/59-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md"
  },
  {
    "title": "Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/60-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md"
  },
  {
    "title": "Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/61-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md"
  },
  {
    "title": "Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/62-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md"
  },
  {
    "title": "Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/63-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md"
  },
  {
    "title": "Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/64-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md"
  },
  {
    "title": "Less Diverse",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/65-Less Diverse.md"
  },
  {
    "title": "Attacker-Only",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/66-Attacker-Only.md"
  },
  {
    "title": "Training Iterations",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/67-Training Iterations.md"
  },
  {
    "title": "More Diverse",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/68-More Diverse.md"
  },
  {
    "title": "Self-Play",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/69-Self-Play.md"
  },
  {
    "title": "Defender-Only",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/70-Defender-Only.md"
  },
  {
    "title": "Collectively Aligning Multiple Language Models through Combat",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/71-Collectively Aligning Multiple Language Models through Combat.md"
  },
  {
    "title": "Collectively Aligning Multiple Language Models through Combat",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/72-Collectively Aligning Multiple Language Models through Combat.md"
  },
  {
    "title": "Collectively Aligning Multiple Language Models through Combat",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/73-Collectively Aligning Multiple Language Models through Combat.md"
  },
  {
    "title": "Collectively Aligning Multiple Language Models through Combat",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/74-Collectively Aligning Multiple Language Models through Combat.md"
  },
  {
    "title": "Collectively Aligning Multiple Language Models through Combat",
    "level": 2,
    "chunk_path": "knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/75-Collectively Aligning Multiple Language Models through Combat.md"
  }
]