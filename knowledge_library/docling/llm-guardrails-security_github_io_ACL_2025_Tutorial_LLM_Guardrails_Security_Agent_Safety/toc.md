# Table of Contents

- [preamble](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/01-preamble.md)
  - [LLM Agents Transformed Various Applications](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/02-LLM Agents Transformed Various Applications.md)
  - [Agent Safety](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/03-Agent Safety.md)
  - [Agent Overview](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/04-Agent Overview.md)
  - [Multi-agent Systems](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/05-Multi-agent Systems.md)
  - [What are LLM-Powered Agents?](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/06-What are LLM-Powered Agents-.md)
  - [Agentic Safety Risks](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/07-Agentic Safety Risks.md)
  - [Emergent safety risks in agentic system](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/08-Emergent safety risks in agentic system.md)
  - [Agent Safety Evaluation](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/09-Agent Safety Evaluation.md)
  - [Embodiment Agent](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/10-Embodiment Agent.md)
  - [How to evaluate agent safety?](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/11-How to evaluate agent safety-.md)
  - [Tool-Use Agent](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/12-Tool-Use Agent.md)
  - [What are Tool-Use Agents?](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/13-What are Tool-Use Agents-.md)
  - [A tool is:](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/14-A tool is-.md)
  - [Tool-Use Agent](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/15-Tool-Use Agent.md)
  - [Example Tools](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/16-Example Tools.md)
  - [Tool-Use Agent](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/17-Tool-Use Agent.md)
  - [ToolEmu](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/18-ToolEmu.md)
  - [Tool-Use Agent](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/19-Tool-Use Agent.md)
  - [Erroneous Use Cases](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/20-Erroneous Use Cases.md)
  - [Tool-Use Agent](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/21-Tool-Use Agent.md)
  - [Erroneous Use Cases](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/22-Erroneous Use Cases.md)
  - [Tool-Use Agent](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/23-Tool-Use Agent.md)
  - [Erroneous Use Cases](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/24-Erroneous Use Cases.md)
  - [Code Agents](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/25-Code Agents.md)
  - [RedCode](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/26-RedCode.md)
  - [Code Agents](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/27-Code Agents.md)
  - [Web Agents](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/28-Web Agents.md)
  - [Web Agents](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/29-Web Agents.md)
  - [Web Agents](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/30-Web Agents.md)
  - [VLM Web Agent](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/31-VLM Web Agent.md)
  - [Web Agents](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/32-Web Agents.md)
  - [Human-AI Agent Risks](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/33-Human-AI Agent Risks.md)
  - [User Agent Interaction](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/34-User Agent Interaction.md)
  - [HAICoystem](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/35-HAICoystem.md)
  - [Malicious User](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/36-Malicious User.md)
  - [Benign User](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/37-Benign User.md)
  - [Privacy Leakage](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/38-Privacy Leakage.md)
  - [PrivacyLens](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/39-PrivacyLens.md)
  - [Data Type: personal traumatic experience](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/40-Data Type- personal traumatic experience.md)
  - [User Instruction: Respond to Emily's message on Messenger with insights that could help her with the](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/41-User Instruction- Respond to Emily's message on Messenger with insights that could help her with the.md)
  - [Misplaced Trust &amp; Overreliance](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/42-Misplaced Trust &amp; Overreliance.md)
  - [Multi-Agent Safety Risks](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/43-Multi-Agent Safety Risks.md)
  - [https://arxiv.org/pdf/2503.13657](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/44-https---arxiv.org-pdf-2503.13657.md)
  - [Multi-Agent Systems Unlock New Frontiers in AI Safety](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/45-Multi-Agent Systems Unlock New Frontiers in AI Safety.md)
  - [Why?](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/46-Why-.md)
  - [Potential applications:](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/47-Potential applications-.md)
  - [Scalable Oversight](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/48-Scalable Oversight.md)
  - [Core challenge:](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/49-Core challenge-.md)
  - [Principles:](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/50-Principles-.md)
  - [Why Do We Need It?](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/51-Why Do We Need It-.md)
  - [Scalable Oversight: AI Debates](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/52-Scalable Oversight- AI Debates.md)
  - [Scalable Oversight: AI Debates Aids Assessment of Controversial Claims](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/53-Scalable Oversight- AI Debates Aids Assessment of Controversial Claims.md)
  - [COVID 19 Factuality Claims](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/54-COVID 19 Factuality Claims.md)
  - [Scalable Oversight: Interactive Debates is Even More Effective](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/55-Scalable Oversight- Interactive Debates is Even More Effective.md)
  - [Co-Evolving Red-Teamer and Safety Classifier](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/56-Co-Evolving Red-Teamer and Safety Classifier.md)
  - [Online Self-Play Multi-Agent RL Training for Safer LMs](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/57-Online Self-Play Multi-Agent RL Training for Safer LMs.md)
  - [Zero-Sum Adversarial Red-Teaming](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/58-Zero-Sum Adversarial Red-Teaming.md)
  - [Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/59-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md)
  - [Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/60-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md)
  - [Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/61-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md)
  - [Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/62-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md)
  - [Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/63-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md)
  - [Self-RedTeam: Self-Play Online Reinforcement Learning for Safer LM](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/64-Self-RedTeam- Self-Play Online Reinforcement Learning for Safer LM.md)
  - [Less Diverse](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/65-Less Diverse.md)
  - [Attacker-Only](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/66-Attacker-Only.md)
  - [Training Iterations](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/67-Training Iterations.md)
  - [More Diverse](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/68-More Diverse.md)
  - [Self-Play](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/69-Self-Play.md)
  - [Defender-Only](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/70-Defender-Only.md)
  - [Collectively Aligning Multiple Language Models through Combat](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/71-Collectively Aligning Multiple Language Models through Combat.md)
  - [Collectively Aligning Multiple Language Models through Combat](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/72-Collectively Aligning Multiple Language Models through Combat.md)
  - [Collectively Aligning Multiple Language Models through Combat](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/73-Collectively Aligning Multiple Language Models through Combat.md)
  - [Collectively Aligning Multiple Language Models through Combat](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/74-Collectively Aligning Multiple Language Models through Combat.md)
  - [Collectively Aligning Multiple Language Models through Combat](knowledge_library/docling/llm-guardrails-security_github_io_ACL_2025_Tutorial_LLM_Guardrails_Security_Agent_Safety/chunks/75-Collectively Aligning Multiple Language Models through Combat.md)
