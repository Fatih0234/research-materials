## 1.1 RELATED WORK

Auctions: There's a vast quantity of theoretical and experimental literature on auctions. While Krishna (2009)'s textbook and Kagel and Roth (2020)'s handbook provided invaluable general resources, we will stay focused only on the citations relevant to the results in this paper.

From classic theory, the benchmark of revenue equivalence in the risk-neutral case is exposited in the seminal Myerson (1981). The experimental evidence for departures due to risk-aversion in the FPSB auction are thoroughly documented in Coppinger et al. (1980) and Cox et al. (1988)'s survey. The experimental evidence for the common error of bidding above one's value in the SPSB auction is documented in Kagel and Levin (1993).

Further, recent work on obvious strategy-proofness began with Li (2017), who demonstrates empirically that human subjects tend to be less truthful in second price sealed bid auctions than ascending clock auctions in the APV setting, even though the two auctions are strategically equivalent. Li also provides a theoretical framework for the results. To better understand our simulations, we also consider the experimental evidence presented by Breitmoser and Schweighofer-Kodritsch (2022), who investigate intermediate auction formats that decompose the behavioral effects in Li (2017).

1 On publication, we will make the code-base public in the hopes it facilitates additional research into the role of LLMs as modeling human bidder behavior.

108

109

110

111

112

113

114

115

116

117

118

119

120

121

122

123

124

125

126

127

128

129

130

131

132

133

134

135

136

137

138

139

140

141

142

143

144

145

146

147

148

149

150

151

152

153

154

155

156

157

158

159

160

161

LLMs as simulated agents: Recent LLMs, having been trained on an enormous corpus of humangenerated data, are able to generate human-like text and reasoning (Achiam et al., 2023; Bubeck et al., 2023). Yet, they are far from perfect - in particular, displaying limited planning abilities and reflecting various cognitive biases endemic to human agents (Wan et al., 2023).

There is a growing literature on using these human-like AI models as simulated agents in economics and social science studies (Aher et al., 2023; Park et al., 2023; Brand et al., 2023). In this literature, Horton (2023) replicates four classical behavioral economics experiments by endowing a single LLM agent with different personas and querying it about its decisions and preferences. Manning et al. (2024) enable multiple GPT-4 agents to interact and simulate various social science scenarios, including bargaining, job interviews, and bail-setting. Finally, Manning and Horton (2025) and Raman et al. (2024) benchmark the ability of LLM agents to conduct play over a broad range of games and tasks.

LLMs in auctions: Some existing work has already begun using LLMs as simulated agents in auction experiments. Fish et al. (2024) study collusive behavior in first-price sealed-bid auctions between two LLM agents, with the LLM as price setter. Chen et al. (2023) study how to produce super-human play in auctions. Finally, Manning et al. (2024) runs a limited study an a variant of an open-ascending clock auction with three bidders, focusing on deviations from rational economic theory in considering bidders' values and the final clearing price.
