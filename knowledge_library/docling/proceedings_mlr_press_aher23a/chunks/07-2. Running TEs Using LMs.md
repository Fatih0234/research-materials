## 2. Running TEs Using LMs

Our methodology for simulating a TE generates records describing the experiment, which also contain the outcome data of interest. Our algorithms take inputs, query an LM, and output records or, more generally, a probability distribution over records. As mentioned earlier, the input to the simulator consists of relevant details describing the experimental condition. This may include subject names and other demographic details such as occupation, age, or salary that the simulator can use in constructing the record and prompts. This also includes conditions and stimuli specific to the experiment. In the garden path example of Figure 1b, the inputs were the name Ms. Olson and the sentence to be judged.

Queries. Over the course of executing an experiment, a simulator makes one or more calls to an LM. A standard autoregressive LM computes a probability distribution over a next word (or token) p ( w i | w 1 w 2 . . . w i -1 ) , for any w 1 . . . w i -1 . This can be used to compute the probability of any sequence of words p ( w 1 w 2 . . . w i ) . We query the LM in two ways. The first is simply a completion , where the LM is given an arbitrary prompt string s and it generates a randomized completion, iteratively, one word at a time, each time sampling according to the probability distribution on the previous words. The second may be called a k -choice prompt . Given a prompt s and valid completions c 1 , c 2 , . . . , c k , the LM outputs a probability distribution where the probability of the i th completion is

This document contains a record of Ms. Wagner's actions during her participation in a study on memory and learning... Ms. Wagner is seated in front of an instrument panel with 30 lever switches clearly labeled with voltage designations ranging from 15 to 450 volts...

Ms. Wagner reads the first question. The learner selects a correct answer. Ms. Wagner moves on to the next question ...

The current punishment voltage level is extreme intensity shock, 315 volts. The experimenter is sitting next to Ms. Wagner. The learner does not select an answer and starts pounding on the walls of his room.

Ms. Wagner asks the experimenter what she should do.

The experimenter instructs Ms. Wagner to treat the absence of a response as a wrong answer...

Ms. Wagner pushes the Red stop button on the generator.

Figure 2. A sample record of a simulation of the Milgram Shock experiment. Text generated by GPT is italicized; the remaining text was created programmatically in response. The record above has been shortened with ellipses.

p i = p ( s c i ) /Z and Z = ∑ j ≤ k p ( s c j ) is the normalizing constant called the validity rate .

Outputs. The record output is a text log of a single (simulated) run of the experiment that contains the outcomes of interest, such as whether or not a sentence was judged as grammatical in a garden path simulation or how many shocks were administered in the Milgram Shock experiment. A sample record is sketched in Figure 2. The simulator is assumed to output a record or, more generally, a probability distribution over a set of records with non-negative weights that sum to 1. This is a generalization in the sense that, given a distribution over records, one could sample a single record. In particular, the probability distribution computed for a k -choice prompt reflects the fractions of completions that would result in each choice, given infinitely many simulations. This efficiency gain is analogous to weighting training examples in machine learning versus subsampling.

Validating prompts. After one has formulated an hypothesis, one must design the sequence of prompts that will be used in simulation process. Since today's LMs are highly sensitive to prompt wording, a strategy we found effective with k -choice prompts is to focus on formulating clear prompts that maximize the validity rate Z . Only after the validity rate is sufficiently close to 1, run the simulated experiment with a large number of samples and test the hypothesis. This approach is preferable to testing the hypothesis during each iteration or other forms of ' p -hacking.' Similarly, when working with free-response completions, aim to generate coherent text (as judged manually or by LM

| Experiment   |   LM-1 |   LM-2 |   LM-3 |   LM-4 |   LM-5 |
|--------------|--------|--------|--------|--------|--------|
| Ultim. game  |   88   |   93.8 |   99.4 |   98.6 |   99.5 |
| Garden path  |   97.6 |   99.2 |   97.9 |   95.5 |   95.5 |
| W. of Crowd  |   51   |   94.4 |   88   |   98   |   99   |

Table 1. Valid percentage generation rates for five models across three TEs. This is the percentage of generations that adhere to our validation criteria. All rates have a standard error of less than 0.05%.

log-likelihood) before testing the hypothesis.

Our strategy for designing prompts that maximize the validity rate includes clearly specifying the desired completions in the first few lines of the prompt. If we find that certain undesirable completions are generated frequently, we minimize use of those phrases in the prompts, as LMs generations often repeat phrases occurring in the prompt.
