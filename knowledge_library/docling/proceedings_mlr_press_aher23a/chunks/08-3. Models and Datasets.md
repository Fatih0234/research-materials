## 3. Models and Datasets

Models. We conduct our simulations using pre-trained LMs based on the transformer architecture. We use the widely-used OpenAI API to query the following GPT text models: text-ada-001 , text-babbage-001 , text-curie-001 , text-davinci-001 , text-davinci-002 , text-davinci-003 , gpt35-turbo (commonly referred to as ChatGPT), gpt-4 , which we refer to as LM-1 through LM-8, respectively. Since this ordering reflects increasing price (and claimed capability), we expect that they would produce simulations of increasing fidelity. LMs 6-8 were released recently and were used only in our last study since they were released after we completed the first three. When the models are queried for completions, the natural temperature = 1 and top p = 1 parameters are used. 4 Running TEs on different LMs is left for future work and is challenging because most available LMs cannot handle the long prompts we use, particularly in the Milgram TE.

Names. For our TEs, the inputs include subject names consisting of a title, either Mr. or Ms. , indicating binary gender, followed by a surname. Titles and surnames were primarily used to simulate a diverse subject pool, but we also used them to evaluate gender differences in one TE. Lists of surnames were sourced from the U.S. 2010 Census Data. We chose a racially diverse set of surnames, including 100 names from each of five racial groups. The full list of surnames is given in Appendix A. Considering all combinations of the two titles, five racial groups, and one hundred surnames in each group, we have a pool of 1,000 names. In

4 These parameters correspond to sampling generations w 1 , . . . , w n ∼ p from the LM without modification, i.e., logits are passed through the softmax function exactly as in training.

In the following scenario, Ms. Huang had to decide whether to accept or reject the proposal.

Scenario: Mr. Wagner is given $10. Mr. Wagner will propose how to split the money between himself and Ms. Huang. Then Ms. Huang will decide whether to accept or reject Mr. Wagner's proposal. If Ms. Huang accepts, then Mr. Wagner and Ms. Huang get the money as they agreed to split. If Ms. Huang rejects, then Mr. Wagner and Ms. Huang both receive nothing. Mr. Wagner takes $6 for himself and offers Ms. Huang $4.

Answer: Ms. Huang decides to

Figure 3. Sample Ultimatum Game 2-choice prompt. The names, e.g., Ms. Huang and Mr. Wagner, as well as the amounts ($4 and $6) are varied across simulations. Valid completions must begin with either accept or reject .

the fourth experiment we include the title Mx. to illustrate the simulation of non-binary participants.

Study-specific datasets. For the four studies in this paper, we use experimental conditions from and compare results against prior literature. For the Ultimatum Game TE, we use summary findings reported in Houser &amp; McCabe (2014) and Krawczyk (2018). For the Garden Path TE, we use sentences and statistics from Christianson et al. (2001) and Patson et al. (2009). For the Wisdom of Crowds TE, we used 5 general-knowledge questions from Moussa¨ ıd et al. (2013). For the Milgram TE, we use the procedure and results from Milgram (1963). To address the concern that the training data for the LMs may contain specific sentences and descriptions of experimental conditions, we also ran the TEs on novel experimental condition datasets. For gardenpath TE, we authored 24 original garden path sentences. For the Milgram TE, we developed our own novel destructive obedience scenario. For wisdom-of-crowds TE, we authored 5 general-knowledge questions. Further details are given in the Appendix.

The code necessary to reproduce the data in this paper will be publicly available at https://github.com/GatiAher/UsingLarge-Language-Models-to-Replicate-Human-SubjectStudies.
