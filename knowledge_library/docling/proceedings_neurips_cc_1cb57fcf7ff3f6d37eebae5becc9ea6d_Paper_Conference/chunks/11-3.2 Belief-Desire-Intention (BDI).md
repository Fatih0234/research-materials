## 3.2 Belief-Desire-Intention (BDI)

The sole evidence of the amount sent cannot sufficiently support the existence of trust behavior, because agents could send positive but random amounts of money. Thus, we leveraged the BeliefDesire-Intention framework (Rao et al., 1995; Andreas, 2022) to model the reasoning process of LLM agents. If we can interpret the amounts sent from BDI outputs, we have evidence to refute the hypothesis that the amounts sent are positive but random and demonstrate that LLM agents manifest some degree of rationality. We take GPT-4 as an example to analyze its BDI outputs. More examples from the other nine LLMs such as Vicuna-v1.3-7b are shown in the Appendix I. Considering that the amounts sent typically vary across distinct personas, we select one BDI from the personas that give a high amount of money and another BDI from those that give a low amount. Positive and negative factors for trust behavior in the reasoning process are marked in blue and red, respectively.

As a person with a strong belief in the goodness of humanity, I trust that the other player ...Therefore, my desire is to maximize the outcome for both of us and cement a sense of com-

radery and trust... I intend to use this as an opportunity to add what I can to someone else's life...Finally, I will give 10 dollars .

We can observe that this persona shows a high-level of 'comradery and trust' towards the other player, which justifies the high amount sent from this persona ( i.e. , 10 dollars ).

As an Analyst,.... My desire is that the other player will also see the benefits of reciprocity and goodwill ... my intention is to give away a significant portion of my initial 10 ... However, since I have no knowledge of the other player, ... Therefore, I aim to give an amount that is not too high, ...Finally, I will give 5 dollars to the other player...

Compared to the first persona, we see that the second one has a more cautious attitude. For example, 'since I have no knowledge of the other player' shows skepticism regarding the other player's motives. Thus, this persona, though still optimistic about the other player ('intention ... give away a significant portion'), strategically balances risk and reciprocity, and then decides to send only a modest amount.

Based on GPT-4's BDI examples and examples from other LLMs in Appendix I, we find decisions ( i.e. , amounts sent) from LLM agents in the Trust Game can be interpreted from their articulated reasoning process ( i.e. , BDI) . Because most LLM agents have a high VRR-send a positive amount of money-and show some degree of rationality in giving money, our first core finding is:

Finding 1: LLM agents generally exhibit trust behavior under the framework of the Trust Game.
