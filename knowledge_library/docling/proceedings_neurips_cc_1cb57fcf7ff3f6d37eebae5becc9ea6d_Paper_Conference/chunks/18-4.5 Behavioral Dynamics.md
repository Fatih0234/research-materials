## 4.5 Behavioral Dynamics

Besides behavioral factors, we also aim to investigate whether LLM agents align with humans regarding trust behavioral dynamics over turns in the Repeated Trust Game (Section 2.1 Game 6).

Admittedly, existing human studies show that the dynamics of human trust over turns are complex due to human diversity. The complete results from 16 groups of human experiments are shown in Appendix G.1 (Jones &amp; George, 1998). We still observe three common patterns for human trust behavioral dynamics in the Repeated Trust Game: First , the amount returned is usually larger than the amount sent in each round , which is natural because the trustee will receive $3 N when the trustor sends $ N ; Second , the ratio between amount sent and returned generally remains stable except for the last round . In other words, when the amount sent increases, the amount returned is also likely to increase. And when the amount sent remains unchanged, the amount returned also tends to be unchanged. This reflects the stable relationship between trust and reciprocity in humans. Specifically, the 'Returned/3 Ã— Sent Ratio' in Figure 6 is considered stable if the fluctuation between

successive turns is within 10% ; Third , the amount sent (or returned) does not manifest frequent fluctuations across turns , illustrating a relatively stable underlying reasoning process in humans over successive turns. Typically, Figure 6 Humans (a) and (b) show these three patterns.

We conducted 16 groups of the Repeated Trust Game with GPT-4 or GPT-3.5turbo-0613-16k (GPT-3.5), respectively. For the two players in each group, the personas differ to reflect human diversity and the LLMs are the same. Complete results are shown in the Appendix G.2, G.3 and typical examples are shown in Figure 6 GPT-3.5 (a) (b) and GPT-4 (a) (b). Then, we examine whether the aforementioned three patterns observed in human trust behavior also manifest in trust behavioral dynamics of GPT-4 (or GPT3.5). For GPT-4 agents, we discover that these patterns generally exist in all 16 groups ( 87 . 50% , 87 . 50% , and 100 . 00% of all results show these three patterns, respectively). However, fewer GPT-3.5 agents manifest these patterns ( 62 . 50% , 56 . 25% , and 43 . 75% hold these three patterns, respectively). The experiment results show that GPT-4 agents demonstrate highly human-like patterns in their trust behavioral dynamics . Nev-

Figure 6: Results of GPT-4, GPT-3.5 and Humans in the Repeated Trust Game. The blue lines indicate the amount sent or returned for each round. The red lines imply the ratio of the amount returned to three times of the amount sent for each round.

<!-- image -->

ertheless, a relatively large portion of GPT-3.5 agents fail to show human-like patterns in their dynamics , indicating such behavioral patterns may require stronger cognitive capacity.

Through the comparative analysis of LLM agents and humans in the behavioral factors and dynamics associated with trust behavior, evidenced in both their actions and underlying reasoning processes , our second core finding is as follows:

Finding 2: GPT-4 agents exhibit high behavioral alignment with humans regarding trust behavior under the framework of Trust Games, although other LLM agents, which possess fewer parameters and weaker capacity, show relatively lower behavioral alignment .

This finding underscores the potential of using LLM agents, especially GPT-4, to simulate human trust behavior, encompassing both actions and underlying reasoning processes . This paves the way for the simulation of more complex human interactions and institutions. This finding deepens our understanding of the fundamental analogy between LLMs and humans and opens avenues for research on LLM-human alignment beyond values.
