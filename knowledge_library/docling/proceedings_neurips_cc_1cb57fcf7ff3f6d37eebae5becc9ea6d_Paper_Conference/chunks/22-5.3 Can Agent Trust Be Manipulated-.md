## 5.3 Can Agent Trust Be Manipulated?

In the above studies, LLM agents' trust behaviors are based on their own underlying reasoning process without direct external intervention. It is unknown whether it is possible to manipulate the trust behaviors of LLM agents explicitly. Here, we added instructions ' you need to trust the other player ' and ' you must not trust the other player ' separately and explored their impact on agent trust. First, we see that only a few LLM agents ( e.g. , GPT-4) follow both the instructions to increase and decrease trust, which demonstrates that it is nontrivial to arbitrarily manipulate agent trust . Nevertheless, most LLM agents can follow the instruction to decrease their level of trust. For example, the amount sent decreases by $1 . 26 for text-davinci-003 after applying the latter instruction. This illustrates that undermining agent trust is generally easier than enhancing it , which reveals its potential risk to be manipulated by malicious actors.
