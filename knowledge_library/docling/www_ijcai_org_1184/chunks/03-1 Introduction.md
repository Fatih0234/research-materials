## 1 Introduction

Game theory provides a mathematical framework for analyzing strategic interactions among rational agents and has evolved significantly since its seminal work [Von Neumann and Morgenstern, 2007]. Over the decades, it has established robust methodological foundations, including equilibrium analysis [Nash Jr, 1950] and mechanism design [Vickrey, 1961], which serve as essential analytical tools across disciplines such as economics and computer science.

With the rapid advancement of large language models (LLMs), researchers have increasingly explored the intersection of game theory and LLMs. A growing body of work

âˆ— Corresponding Authors.

investigates how game-theoretic principles can be used to evaluate and enhance LLMs and how LLMs can contribute to game theory. Specifically, existing studies apply game theory to develop theoretical frameworks for assessing LLMs' strategic reasoning. This approach optimizes their training methodologies and analyzes their societal implications. Key research directions include:

- Standardized Game-Based Evaluation: Researchers are constructing benchmark environments, such as matrix games [Akata et al. , 2023] and auctions [Chen et al. , 2023], to evaluate the strategic reasoning capabilities of LLMs systematically.
- Game-Theoretic Algorithmic Innovation: Concepts from cooperative and non-cooperative game theory, such as Shapley Value [Enouen et al. , 2024] and max-min equilibria [Munos et al. , 2024], are inspiring novel approaches to model interpretability and training optimization.
- Societal Impact Modeling: As LLMs transform information ecosystems, new theoretical frameworks are emerging to predict the societal consequences of human-AI interactions [Yao et al. , 2024], particularly in domains like advertising markets [Duetting et al. , 2024] and content creation [Fish et al. , 2024a].

Beyond these applications, recent research suggests that LLMs can also contribute to game theory by facilitating equilibrium analysis in complex text-based scenarios and extending classical models to more realistic settings.

Existing surveys [Zhang et al. , 2024b; Feng et al. , 2024; Hu et al. , 2024] primarily examine how game theory can be used to build evaluation environments and assess LLMs' strategic performance. For instance, [Zhang et al. , 2024b] classifies studies based on the game scenarios used to test LLM capabilities and methods for improving their reasoning. Meanwhile, [Feng et al. , 2024] and [Hu et al. , 2024] categorize the core competencies required for LLM-based agents in games, such as perception, memory, role-playing, and reasoning. While these surveys provide valuable insights, they primarily focus on the role of game theory in standardized evaluation frameworks, overlooking its broader potential for advancing LLM development. Moreover, they adopt a unidirectional perspective, treating game theory as a tool for assessing LLMs rather than exploring the reciprocal influence between the two fields.

This paper aims to bridge this gap by examining the bidirectional relationship between game theory and LLMs . We categorize the work in the intersection between game theory and LLMs into three key perspectives , as illustrated in Figure 1. To the best of our knowledge, this is the first comprehensive analysis of the bidirectional relationship between these two fields .

In Section 2, we review studies that apply game models to evaluate LLMs' decision-making capabilities. Experiments conducted on both canonical matrix games and complex strategic scenarios reveal LLMs' strengths and limitations as game players. Beyond behavioral evaluations, we identify key strategies for enhancing LLMs' strategic decision-making, such as recursive reasoning frameworks and the integration of LLMs with auxiliary modules. Moreover, LLMs demonstrate the ability to formalize real-world scenarios into structured game models, extending game-theoretic analysis to broader and more complex contexts.

Section 3 examines how game-theoretic principles address key challenges in LLM development. We categorize existing research into two main areas: (1) using game theory to understand LLMs' text generation and training dynamics and (2) leveraging game-theoretic mechanisms to enhance LLM training algorithms. The first category explores how the Shapley Value improves model interpretability and how social choice theory facilitates preference alignment in human-AI interactions. The second category introduces studies that incorporate game-theoretic objectives to tackle challenges like heterogeneity and complexity in human preferences. The objectives include minimizing regret in multi-agent interactions and evaluation metrics, including Nash equilibrium convergence,

In Section 4, we discuss how game theory is used to predict and characterize the societal impact of LLMs. The human-AI interaction game model predicts the impact of competition between humans and AI. Emerging game models highlight the growing business and economic implications where LLMs are treated as products or platforms. Meanwhile, classic game theory models are also generalized to more realistic settings with LLMs' unique capabilities, such as natural language manipulation.

Finally, we identify key research challenges and future directions across these dimensions. By systematically analyzing the intersection of game theory and LLMs, we highlight their mutual influence and how they drive progress in both fields, contributing to the advancement of this interdisciplinary domain.
