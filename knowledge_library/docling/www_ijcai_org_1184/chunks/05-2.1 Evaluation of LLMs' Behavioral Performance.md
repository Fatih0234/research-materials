## 2.1 Evaluation of LLMs' Behavioral Performance

Struggles of LLM in Matrix Games. Matrix games are a fundamental concept in game theory. In a matrix game, two players make simultaneous decisions, and the outcomes can be represented by a finite payoff matrix. Recent studies have investigated how LLMs respond to these games by converting them into natural language prompts. Despite significant advancements, their results show that LLMs such as GPT-4 struggle to consistently select the optimal strategy in 2 × 2 matrix games [Akata et al. , 2023; Herr et al. , 2024; Lor` e and Heydari, 2024; Wang et al. , 2024].

For instance, [Akata et al. , 2023] states that LLMs frequently fail to choose the optimal action in coordination games, like the Battle of the Sexes. Similarly, [Lor` e and Heydari, 2024] examines how contextual framing and utility matrices influence LLM decision-making, revealing significant biases. Furthermore, [Herr et al. , 2024] explores the impact of game descriptions, player positioning, and payoffs on LLM performance, highlighting consistent behavioral biases. In more dynamic settings, [Fan et al. , 2024] observes that LLMs struggle to predict optimal strategies in ring-network games. Additionally, the TMGBench benchmark, which evaluates LLMs across 144 distinct 2 × 2 matrix games, further confirms these limitations [Wang et al. , 2024].

The matrix game is a cornerstone of game theory and is the foundation for more intricate strategic challenges. Studying LLMs' behaviors in such games provides valuable insights into their broader limitations in complex reasoning tasks.

Human-like Strategies of LLM in Realistic Game Scenarios. Beyond classic matrix games, numerous studies have analyzed LLM performance in more realistic game settings. While these games feature greater contextual complexity, they are not necessarily more challenging for LLMs. This is because strategic inference based on textual content can sometimes replace explicit computation.

Research indicates that LLMs can exhibit strategic behavior in communication-based games. In deception and negotiation games, including Werewolf [Xu et al. , 2023; Du and Zhang, 2024] and Avalon [Wang et al. , 2023; Lan et al. , 2024], LLMs demonstrate behaviors such as deception, trust-building, and leadership-traits typically associated with human strategic thinking. These findings suggest that LLMs can function as sophisticated communication agents in games.

LLMs have also demonstrated strategic reasoning in economically significant scenarios such as bargaining and pricing games. For instance, [Deng et al. , 2024] finds that LLMs possess advanced negotiation skills, while [Fish et al. , 2024b] shows that LLM-based pricing agents can autonomously engage in collusion to set prices above competitive levels. In auction contexts, [Guo et al. , 2024] finds that LLMs can formulate rational bidding strategies based on historical data, often converging toward a Nash equilibrium. Similarly, [Chen et al. , 2023] introduces AucArena, a platform where LLMs effectively manage budgets and optimize auction strategies.

Comprehensive Benchmarks for Game Performance. Several benchmarks that cover a diverse range of game scenarios have been developed to make a systematic assessment of LLM. Notable examples include GTBench [Duan et al. ,

Figure 1: A taxonomy of the intersection between game theory and Large Language Models.

<!-- image -->

2024b], γ -bench [Huang et al. , 2024], GameBench [Hua et al. , 2024], GLEE [Shapira et al. , 2024], and TMGBench [Wang et al. , 2024]. These benchmarks serve to identify both the strengths and weaknesses of LLMs in different strategic environments, offering valuable insights into their potential improvements and real-world applications.
