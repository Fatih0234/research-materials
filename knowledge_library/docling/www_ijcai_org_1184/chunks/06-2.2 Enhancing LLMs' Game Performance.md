## 2.2 Enhancing LLMs' Game Performance

Building on the evaluation of LLMs' performance in various games, numerous studies have explored methods to enhance their strategic reasoning and decision-making. These works address key challenges LLMs face in gameplay and propose general frameworks for improving their capabilities. Below, we outline two significant approaches.

Recursively Thinking. In games requiring long-term or multi-level reasoning, LLMs often struggle to retain and build upon previous information, leading to suboptimal decisionmaking. To mitigate this, researchers have developed techniques that encourage LLMs to engage in recursive thinking, enabling them to leverage past information better when formulating strategies.

For instance, [Wang et al. , 2023] introduces the Recursive Contemplation (ReCon) framework. The framework prompts LLMs to engage in first-order and second-order perspectivetaking during Avalon gameplay. This helps them avoid common pitfalls, such as deception. Similarly, [Duan et al. , 2024a] proposes a method where LLMs predict future moves in multiturn games, improving their ability to anticipate opponents' strategies. Additionally, [Zhang et al. , 2024a] advances LLM reasoning through k-level rationality, which enhances multilevel thinking and significantly increases their win rates in competitive settings. These findings suggest that recursive reasoning can substantially improve LLMs' strategic capabilities.

Auxiliary Modules. As language models, LLMs often struggle in games that require complex mathematical calculations or historical data retrieval. Several studies have proposed integrating auxiliary modules that assist LLMs during gameplay to overcome these limitations.

For example, [Gandhi et al. , 2023] introduces a 'prompt

compiler', which systematically guides LLMs in evaluating actions and forming beliefs, enabling them to generalize to new scenarios with minimal in-context learning. In the game Werewolf, [Xu et al. , 2023] integrates an additional BERT model to encode both historical and current game states, allowing LLMs to make more informed decisions.

In bargaining games, the OG-Narrator framework [Xia et al. , 2024] generates external offers, allowing the LLM to focus solely on negotiation language. More recently, [Hua et al. , 2024] developed a structured workflow to assist LLMs in solving game-theoretic problems, including computing Nash equilibria and optimizing strategies in complex negotiation tasks.

These auxiliary modules significantly improve LLMs' performance in various game settings, demonstrating that integrating additional computational tools can enhance their strategic decision-making.
