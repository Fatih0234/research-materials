## LLM-based Agents with Comprehensive Game Abilities.

Existing research has explored the evaluation of LLM agents across various game scenarios and developed methods to enhance their reasoning capabilities. However, while some of these methods demonstrate general applicability, their validation remains highly scenario-specific. A key future direction is to develop LLM agents proficient in game-theoretic reasoning, capable of applying their knowledge across diverse game settings without explicit customization. Achieving this requires advancements in rule comprehension, external environment modeling, and multi-agent reasoning. Key technical aspects include constructing a game-theoretic corpus, refining finetuning strategies, and incorporating tool-learning techniques.

Moving Beyond Human-Oriented Evaluation Frameworks. Game theory provides well-established evaluation criteria for rationality and strategic reasoning, such as K-level rationality, which has been widely adopted to assess LLM intelligence. However, these evaluation methods were originally designed for human cognition and may not fully capture the reasoning processes of next-token prediction models. To assess LLMs comprehensively from a game-theoretic perspective, it is crucial to move beyond existing human-oriented metrics and develop evaluation frameworks tailored to neural network-based models. This remains an underexplored area with the potential to improve our understanding of LLMs' decision-making significantly.

Theoretical Understanding of LLMs' Strategic Behavior. The application of game-theoretic concepts, such as the Shapley Value, to understanding LLMs' text generation behavior is still in its early stages. Most studies on LLMs' strategic behavior in real-world scenarios rely on empirical observations rather than systematic theoretical interpretations. For example,

[Park et al. , 2025] has introduced hypothetical models to explain why LLMs struggle to achieve the performance level of no-regret learners in repeated games. Extending such theoretical investigations to more complex scenarios, including games like Werewolf, Avalon, or bargaining games, is essential. A deeper theoretical understanding of LLM strategic behavior will help to define their capability boundaries and provide insights for further improving their reasoning abilities.

Capturing Cooperative Games in LLM Optimization. Many studies leveraging game theory for optimizing LLM training, as discussed in Section 3.2, primarily focus on noncooperative game settings. While non-cooperative approaches are a natural fit, cooperative game-theoretic methods offer additional insights into LLM optimization. For instance, different expert networks can be seen as participants in a cooperative game in the Mixture of Expert models. Adopting suitable payoff allocation mechanisms, such as the Shapley Value or the core concept, could optimize expert selection and task allocation, reducing redundancy while enhancing computational efficiency. Similarly, in ensemble learning and knowledge distillation, different sub-models can be treated as cooperative agents working together to refine decision boundaries or transfer knowledge. Effective reward allocation and weight adjustment strategies could enhance collaboration among submodels, reducing redundant computation while improving generalization. Integrating cooperative game-theoretic methods into LLM training and optimization could offer new theoretical insights and practical solutions.

Modeling Cooperation Between Multi-LLMs and Humans. As discussed in Section 4.1, previous studies have primarily been focused on modeling competitive interactions between LLMs and humans, yielding valuable insights into their societal implications. However, beyond competition, understanding cooperative dynamics between multiple LLMs and humans remains an important research direction. One key challenge is to design mechanisms that incentivize LLMs to collaborate in fulfilling human-assigned tasks while considering their objectives. A theoretical characterization of LLM agents' goals and behaviors is essential for bridging the gap between game-theoretic mechanism design and real-world deployment. Advancing this line of research could facilitate the development of LLMs that align more effectively with human objectives and contribute positively to society.

Leveraging LLMs as Oracles to Extend Theoretical Game Models. As discussed in Section 4.3, several studies have explored how LLMs can be used to extend classical gametheoretic models. The key insight behind these works is that LLMs, with their strong language understanding and generative capabilities, can serve as oracles with specific functionalities in game-theoretic frameworks. This perspective opens up new opportunities to relax idealized assumptions or replace theoretical oracles in various game models using LLMs. By doing so, models that previously remained purely theoretical can now be practically implemented while preserving approximate theoretical properties. Systematic exploration of how LLMs can function as adaptable oracles in different theoretical models could bridge the gap between abstract game-theoretic concepts and real-world applications.
