## References

1. Brants, T., Popat, A., Xu, P., Och, F. J. &amp; Dean, J. Large language models in machine translation. In Proc. 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL) 858-867 (Association for Computational Linguistics, 2007).

2. Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. Bert: Pre-training of deep bidirectional transformers for language understanding. In Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies Vol. 1 (Long and Short Papers) 4171-4186 (Association for Computational Linguistics, 2019).
3. Radford, A. et al. Improving Language Understanding by Generative Pre-training (OpenAI, 2018).
4. Brown, T. et al. Language models are few-shot learners. Adv. Neural Inform. Process. Syst. 33 , 1877-1901 (2020).
5. Wei, J. et al. Emergent abilities of large language models. Preprint at https://arxiv.org/abs/2206.07682 (2022).
6. Webb, T., Holyoak, K. J. &amp; Lu, H. Emergent analogical reasoning in large language models. Nat. Hum. Behav. 7 , 1526-1541 (2023).
7. Chen, M. et al. Evaluating large language models trained on code. Preprint at https://arxiv.org/abs/2107.03374 (2021).
8. Bubeck, S. et al. Sparks of artificial general intelligence: early experiments with GPT-4. Preprint at https://arxiv.org/abs/ 2303.12712 (2023).
9. Coda-Forno, J. et al. Meta-in-context learning in large language models. Adv. Neural Inform. Process. Syst. 36 , 65189-65201 (2023).
10. Bommasani, R. et al. On the opportunities and risks of foundation models. Preprint at https://arxiv.org/abs/2108.07258 (2021).
11. Fudenberg, D., Rand, D. G. &amp; Dreber, A. Slow to anger and fast to forgive: cooperation in an uncertain world. Am. Econ. Rev. 102 , 720-749 (2012).
12. Mailath, G. J. &amp; Morris, S. Coordination failure in repeated games with almost-public monitoring. Cowles Foundation Discussion Papers , 1761 https://elischolar.library.yale.edu/ cowles-discussion-paper-series/1761 (2004).
13. Camerer, C. F. Behavioral Game Theory: Experiments in Strategic Interaction (Princeton University Press, 2011).
14. Fudenberg, D. &amp; Tirole, J. Game Theory (MIT Press, 1991).
15. Von Neumann, J. &amp; Morgenstern, O. Theory of Games and Economic Behavior (Princeton Univ. Press, 1944).
16. Camerer, C. F. Progress in behavioral game theory. J. Econ. Perspect. 11 , 167-188 (1997).
17. Henrich, J. et al. In search of homo economicus: behavioral experiments in 15 small-scale societies. Am. Econ. Rev. 91 , 73-78 (2001).
18. Rousseau, D. M., Sitkin, S. B., Burt, R. S. &amp; Camerer, C. Not so different after all: a cross-discipline view of trust. Acad. Manag. Rev. 23 , 393-404 (1998).
19. Johnson, T. &amp; Obradovich, N. Measuring an artificial intelligence language model's trust in humans using machine incentives. J. Phys. Complex. 5 , 015003 (2024).
20. Achiam, J. et al. GPT-4 technical report. Preprint at https://arxiv.org/abs/2303.08774 (2023).
21. Owen, G. Game Theory (Emerald Group Publishing, 2013).
22. Robinson, D. &amp; Goforth, D. The Topology of the 2 × 2 Games: A New Periodic Table vol. 3 (Psychology Press, 2005).
23. Jones, G. Are smarter groups more cooperative? Evidence from prisoner's dilemma experiments, 1959-2003. J. Econ. Behav. Org. 68 , 489-497 (2008).
24. Axelrod, R. &amp; Hamilton, W. D. The evolution of cooperation. Science 211 , 1390-1396 (1981).
25. Hawkins, R. X. &amp; Goldstone, R. L. The formation of social conventions in real-time environments. PLoS ONE 11 , e0151670 (2016).
26. Young, H. P. The economics of convention. J. Econ. Perspect. 10 , 105-122 (1996).
27. Andalman, A. &amp; Kemp, C. Alternation in the Repeated Battle of the Sexes . 9.29, Spring 2004, MIT (MIT Press, 2004).
28. Lau, S.-H. P. &amp; Mui, V.-L. Using turn taking to mitigate coordination and conflict problems in the repeated battle of the sexes game. Theory Decis. 65 , 153-183 (2008).
29. McKelvey, R. D. &amp; Palfrey, T. R. Playing in the Dark: Information, Learning, and Coordination in Repeated Games (California Institute of Technology, 2001).
30.  Arifovic, J. &amp; Ledyard, J. Learning to alternate. Exp. Econ. 21 , 692-721 (2018).
31. Swettenham, J. What's inside someone's head? Conceiving of the mind as a camera helps children with autism acquire an alternative to a theory of mind. Cogn. Neuropsychiatry 1 , 73-88 (1996).
32. Westby, C. &amp; Robinson, L. A developmental perspective for promoting theory of mind. Top. Lang. Disord. 34 , 362-382 (2014).
33. Begeer, S. et al. Theory of mind training in children with autism: a randomized controlled trial. J. Autism Dev. Disord. 41 , 997-1006 (2011).
34.  Moghaddam, S. R. &amp; Honey, C. J. Boosting theory-of-mind performance in large language models via prompting. Preprint at https://arxiv.org/abs/2304.11490 (2023).
35. Ouyang, L. et al. Training language models to follow instructions with human feedback. Adv. Neural Inform. Process. Syst. 35 , 27730-27744 (2022).
36.  Wolf, Y., Wies, N., Levine, Y. &amp; Shashua, A. Fundamental limitations of alignment in large language models. Preprint at https://arxiv. org/abs/2304.11082 (2023).
37. Ullman, T. Large language models fail on trivial alterations to theory-of-mind tasks. Preprint at https://arxiv.org/abs/2302.08399 (2023).
38. Le, M., Boureau, Y.-L. &amp; Nickel, M. Revisiting the evaluation of theory of mind through question answering. In Proc. 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) 5872-5877 (Association for Computational Linguistics, 2019).
39.  Kosinski, M. Evaluating large language models in theory of mind tasks. Proc. Natl Acad. Sci. USA 121 , e2405460121 (2024).
40.  Horton, J. J. Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus? (National Bureau of Economic Research, 2023).
41. Aher, G. V., Arriaga, R. I. &amp; Kalai, A. T . Using large language models to simulate multiple humans and replicate human subject studies. In International Conference on Machine Learning 337-371 (PMLR, 2023).
42. Dal Bó, P. &amp; Fréchette, G. R. The evolution of cooperation in infinitely repeated games: experimental evidence. Am. Econ. Rev. 101 , 411-429 (2011).
43.  Nowak, M. A. &amp; Sigmund, K. Evolution of indirect reciprocity. Nature 437 , 1291-1298 (2005).
44.  Radford, A. et al. Language models are unsupervised multitask learners. OpenAI Blog https://cdn.openai.com/ better-language-models/language\_models\_are\_unsupervised\_ multitask\_learners.pdf (2019).
45. Nowak, M. A. Five rules for the evolution of cooperation. Science 314 , 1560-1563 (2006).
46.  Wei, J. et al. Chain-of-thought prompting elicits reasoning in large language models. Adv. Neural Inform. Process. Syst. 35 , 2482424837 (2022).
47. Engle-Warnick, J. &amp; Slonim, R. L. The evolution of strategies in a repeated trust game. J. Econ. Behav. Org. 55 , 553-573 (2004).
48.  Rankin, D. J., Bargum, K. &amp; Kokko, H. The tragedy of the commons in evolutionary biology. Trends Ecol. Evol. 22 , 643-651 (2007).
49. Rahwan, I. et al. in Machine Learning and the City: Applications in Architecture and Urban Design 143-166 (John Wiley &amp; Sons, 2022).
50.  Schulz, E. &amp; Dayan, P. Computational psychiatry for computers. iScience 23 , 101772 (2020).
51. Binz, M. &amp; Schulz, E. Using cognitive psychology to understand GPT-3. Proc. Natl Acad. Sci. USA 120 , e2218523120 (2023).

52. Coda-Forno, J. et al. Inducing anxiety in large language models increases exploration and bias. Preprint at https://arxiv.org/ abs/2304.11111 (2023).
53. Kojima, T., Gu, S. S., Reid, M., Matsuo, Y. &amp; Iwasawa, Y. Large language models are zero-shot reasoners. Adv. Neural Inform. Process. Syst. 35 , 22199-22213 (2022).
54. Rabinowitz, N. et al. Machine theory of mind. In Proc. 35th International Conference on Machine Learning (eds Dy, J. &amp; Krause, A.) 80:4218-4227 (PMLR, 2018).
55. Cuzzolin, F., Morelli, A., Cirstea, B. &amp; Sahakian, B. J. Knowing me, knowing you: theory of mind in AI. Psychol. Med. 50 , 1057-1061 (2020).
56. Alon, N., Schulz, L., Dayan, P. &amp; Rosenschein, J. A (dis-)information theory of revealed and unrevealed preferences. In NeurIPS 2022 Workshop on Information-Theoretic Principles in Cognitive Systems https://openreview.net/pdf?id=vcpQW\_fGaj5 (2022).
57. Frith, C. &amp; Frith, U. Theory of mind. Curr. Biol. 15 , R644-R645 (2005).
58.  Vélez, N. &amp; Gweon, H. Learning from other minds: an optimistic critique of reinforcement learning models of social learning. Curr. Opin. Behav. Sci. 38 , 110-115 (2021).
59. Lissek, S. et al. Cooperation and deception recruit different subsets of the theory-of-mind network. PLoS ONE 3 , e2023 (2008).
60.  Hula, A., Montague, P. R. &amp; Dayan, P. Monte carlo planning method estimates planning horizons during interactive social exchange. PLoS Comput. Biol. 11 , e1004254 (2015).
61. Ho, M. K., Saxe, R. &amp; Cushman, F. Planning with theory of mind. Trends Cogn. Sci. 26 , 959-971 (2022).
62. Han, T. A., Perret, C. &amp; Powers, S. T. When to (or not to) trust intelligent machines: Insights from an evolutionary game theory analysis of trust in repeated games. Cogn. Syst. Res. 68 , 111-124 (2021).
63.  Chan, A., Riché, M. &amp; Clifton, J. Towards the scalable evaluation of cooperativeness in language models. Preprint at https://arxiv.org/ abs/2303.13360 (2023).
64.  Lampinen, A. K. et al. Language models, like humans, show content effects on reasoning tasks. PNAS Nexus 3 , pgae233 (2024).
65. Crandall, J. W. &amp; Goodrich, M. A. Learning to compete, coordinate, and cooperate in repeated games using reinforcement learning. Mach. Learn. 82 , 281-314 (2011).
66.  Goodfellow, I. et al. Generative adversarial networks. Commun. ACM 63 , 139-144 (2020).
67. Santos, F. P. Prosocial dynamics in multiagent systems. AI Mag. 45 , 131-138 (2024).
68.  Guo, H. et al. Facilitating cooperation in human-agent hybrid populations through autonomous agents. iScience 26 , 108179 (2023).
69. Powers, S. T. et al. The stuff we swim in: regulation alone will not lead to justifiable trust in AI. IEEE Technol. Soc. Mag. 42 , 95-106 (2023).
70. Palan, S. &amp; Schitter, C. Prolific.ac-a subject pool for online experiments. J. Behav. Exp. Finance 17 , 22-27 (2018).
71. Normann, H.-T. &amp; Wallace, B. The impact of the termination rule on cooperation in a prisoner's dilemma experiment. Int. J. Game Theory 41 , 707-718 (2012).
72. Charness, G. &amp; Rabin, M. Understanding social preferences with simple tests. Q. J. Econ. 117 , 817-869 (2002).
73. Wong, R. Y .-m &amp; Hong, Y .-y Dynamic influences of culture on cooperation in the prisoner' s dilemma. Psychol. Sci. 16 ,  429-434 (2005).
74. Liu, P. et al. Pre-train, prompt, and predict: a systematic survey of prompting methods in natural language processing. ACM Comput. Surv. 55 , 1-35 (2023).
75. Rouder, J. N., Speckman, P. L., Sun, D., Morey, R. D. &amp; Iverson, G. Bayesian t tests for accepting and rejecting the null hypothesis. Psychon. Bull. Rev. 16 , 225-237 (2009).
