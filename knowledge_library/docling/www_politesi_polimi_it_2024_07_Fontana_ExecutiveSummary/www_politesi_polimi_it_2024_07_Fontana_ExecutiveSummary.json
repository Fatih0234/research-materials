{
  "schema_name": "DoclingDocument",
  "version": "1.9.0",
  "name": "www_politesi_polimi_it_2024_07_Fontana_ExecutiveSummary",
  "origin": {
    "mimetype": "application/pdf",
    "binary_hash": 17945296366243314092,
    "filename": "www_politesi_polimi_it_2024_07_Fontana_ExecutiveSummary.pdf"
  },
  "furniture": {
    "self_ref": "#/furniture",
    "children": [],
    "content_layer": "furniture",
    "name": "_root_",
    "label": "unspecified"
  },
  "body": {
    "self_ref": "#/body",
    "children": [
      {
        "$ref": "#/pictures/0"
      },
      {
        "$ref": "#/texts/0"
      },
      {
        "$ref": "#/texts/1"
      },
      {
        "$ref": "#/texts/2"
      },
      {
        "$ref": "#/groups/0"
      },
      {
        "$ref": "#/texts/11"
      },
      {
        "$ref": "#/texts/12"
      },
      {
        "$ref": "#/texts/13"
      },
      {
        "$ref": "#/texts/14"
      },
      {
        "$ref": "#/texts/15"
      },
      {
        "$ref": "#/texts/16"
      },
      {
        "$ref": "#/texts/17"
      },
      {
        "$ref": "#/texts/18"
      },
      {
        "$ref": "#/texts/19"
      },
      {
        "$ref": "#/texts/20"
      },
      {
        "$ref": "#/texts/21"
      },
      {
        "$ref": "#/texts/22"
      },
      {
        "$ref": "#/texts/23"
      },
      {
        "$ref": "#/groups/1"
      },
      {
        "$ref": "#/texts/30"
      },
      {
        "$ref": "#/texts/31"
      },
      {
        "$ref": "#/texts/32"
      },
      {
        "$ref": "#/texts/33"
      },
      {
        "$ref": "#/texts/34"
      },
      {
        "$ref": "#/texts/35"
      },
      {
        "$ref": "#/texts/36"
      },
      {
        "$ref": "#/texts/37"
      },
      {
        "$ref": "#/texts/38"
      },
      {
        "$ref": "#/texts/39"
      },
      {
        "$ref": "#/texts/40"
      },
      {
        "$ref": "#/texts/41"
      },
      {
        "$ref": "#/texts/42"
      },
      {
        "$ref": "#/texts/43"
      },
      {
        "$ref": "#/texts/44"
      },
      {
        "$ref": "#/texts/45"
      },
      {
        "$ref": "#/texts/46"
      },
      {
        "$ref": "#/texts/47"
      },
      {
        "$ref": "#/texts/48"
      },
      {
        "$ref": "#/tables/0"
      },
      {
        "$ref": "#/texts/50"
      },
      {
        "$ref": "#/texts/51"
      },
      {
        "$ref": "#/texts/52"
      },
      {
        "$ref": "#/pictures/1"
      },
      {
        "$ref": "#/pictures/2"
      },
      {
        "$ref": "#/texts/100"
      },
      {
        "$ref": "#/texts/101"
      },
      {
        "$ref": "#/texts/102"
      },
      {
        "$ref": "#/texts/103"
      },
      {
        "$ref": "#/texts/104"
      },
      {
        "$ref": "#/texts/105"
      },
      {
        "$ref": "#/pictures/3"
      },
      {
        "$ref": "#/texts/129"
      },
      {
        "$ref": "#/texts/130"
      },
      {
        "$ref": "#/texts/131"
      },
      {
        "$ref": "#/texts/132"
      },
      {
        "$ref": "#/texts/133"
      },
      {
        "$ref": "#/texts/134"
      },
      {
        "$ref": "#/pictures/4"
      },
      {
        "$ref": "#/texts/169"
      },
      {
        "$ref": "#/texts/170"
      },
      {
        "$ref": "#/texts/171"
      },
      {
        "$ref": "#/texts/172"
      },
      {
        "$ref": "#/texts/173"
      },
      {
        "$ref": "#/texts/174"
      },
      {
        "$ref": "#/pictures/5"
      },
      {
        "$ref": "#/pictures/6"
      },
      {
        "$ref": "#/texts/223"
      },
      {
        "$ref": "#/texts/224"
      },
      {
        "$ref": "#/texts/225"
      },
      {
        "$ref": "#/texts/226"
      },
      {
        "$ref": "#/texts/227"
      },
      {
        "$ref": "#/groups/2"
      },
      {
        "$ref": "#/texts/233"
      }
    ],
    "content_layer": "body",
    "name": "_root_",
    "label": "unspecified"
  },
  "groups": [
    {
      "self_ref": "#/groups/0",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/3"
        },
        {
          "$ref": "#/texts/4"
        },
        {
          "$ref": "#/texts/5"
        },
        {
          "$ref": "#/texts/6"
        },
        {
          "$ref": "#/texts/7"
        },
        {
          "$ref": "#/texts/8"
        },
        {
          "$ref": "#/texts/9"
        },
        {
          "$ref": "#/texts/10"
        }
      ],
      "content_layer": "body",
      "name": "group",
      "label": "key_value_area"
    },
    {
      "self_ref": "#/groups/1",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/24"
        },
        {
          "$ref": "#/texts/25"
        },
        {
          "$ref": "#/texts/26"
        },
        {
          "$ref": "#/texts/27"
        },
        {
          "$ref": "#/texts/28"
        },
        {
          "$ref": "#/texts/29"
        }
      ],
      "content_layer": "body",
      "name": "list",
      "label": "list"
    },
    {
      "self_ref": "#/groups/2",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/228"
        },
        {
          "$ref": "#/texts/229"
        },
        {
          "$ref": "#/texts/230"
        },
        {
          "$ref": "#/texts/231"
        },
        {
          "$ref": "#/texts/232"
        }
      ],
      "content_layer": "body",
      "name": "list",
      "label": "list"
    }
  ],
  "texts": [
    {
      "self_ref": "#/texts/0",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 56.693,
            "t": 616.5740146484375,
            "r": 237.015,
            "b": 612.1090146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            31
          ]
        }
      ],
      "orig": "Executive Summary of the Thesis",
      "text": "Executive Summary of the Thesis"
    },
    {
      "self_ref": "#/texts/1",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 56.693,
            "t": 595.5720146484375,
            "r": 538.589,
            "b": 564.9570146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            98
          ]
        }
      ],
      "orig": "LLM's Dilemma: analyzing the behaviors of Large Language Models in the Iterated Prisoner's Dilemma",
      "text": "LLM's Dilemma: analyzing the behaviors of Large Language Models in the Iterated Prisoner's Dilemma"
    },
    {
      "self_ref": "#/texts/2",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 56.693,
            "t": 545.7680146484375,
            "r": 507.332,
            "b": 541.3030146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            78
          ]
        }
      ],
      "orig": "Laurea Magistrale in Computer Science and Engineering - Ingegneria Informatica",
      "text": "Laurea Magistrale in Computer Science and Engineering - Ingegneria Informatica"
    },
    {
      "self_ref": "#/texts/3",
      "parent": {
        "$ref": "#/groups/0"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 56.693,
            "t": 524.8130146484375,
            "r": 93.234,
            "b": 516.8870146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            7
          ]
        }
      ],
      "orig": "Author:",
      "text": "Author:"
    },
    {
      "self_ref": "#/texts/4",
      "parent": {
        "$ref": "#/groups/0"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 97.949,
            "t": 523.0910146484375,
            "r": 182.803,
            "b": 518.6260146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            14
          ]
        }
      ],
      "orig": "Nicol\u00f2 Fontana",
      "text": "Nicol\u00f2 Fontana"
    },
    {
      "self_ref": "#/texts/5",
      "parent": {
        "$ref": "#/groups/0"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 56.693,
            "t": 507.8050146484375,
            "r": 95.648,
            "b": 499.87901464843753,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            8
          ]
        }
      ],
      "orig": "Advisor:",
      "text": "Advisor:"
    },
    {
      "self_ref": "#/texts/6",
      "parent": {
        "$ref": "#/groups/0"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 100.365,
            "t": 506.08301464843754,
            "r": 227.273,
            "b": 501.6180146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            22
          ]
        }
      ],
      "orig": "Prof. Francesco Pierri",
      "text": "Prof. Francesco Pierri"
    },
    {
      "self_ref": "#/texts/7",
      "parent": {
        "$ref": "#/groups/0"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 56.693,
            "t": 490.79701464843754,
            "r": 109.597,
            "b": 482.8710146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            11
          ]
        }
      ],
      "orig": "Co-advisor:",
      "text": "Co-advisor:"
    },
    {
      "self_ref": "#/texts/8",
      "parent": {
        "$ref": "#/groups/0"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 114.313,
            "t": 489.0750146484375,
            "r": 374.296,
            "b": 484.6100146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            53
          ]
        }
      ],
      "orig": "Prof. Luca Maria Aiello (IT University of Copenhagen)",
      "text": "Prof. Luca Maria Aiello (IT University of Copenhagen)"
    },
    {
      "self_ref": "#/texts/9",
      "parent": {
        "$ref": "#/groups/0"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 56.693,
            "t": 473.7890146484375,
            "r": 127.723,
            "b": 465.8630146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            14
          ]
        }
      ],
      "orig": "Academic year:",
      "text": "Academic year:"
    },
    {
      "self_ref": "#/texts/10",
      "parent": {
        "$ref": "#/groups/0"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 132.435,
            "t": 472.0670146484375,
            "r": 182.401,
            "b": 467.6020146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            9
          ]
        }
      ],
      "orig": "2023-2024",
      "text": "2023-2024"
    },
    {
      "self_ref": "#/texts/11",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 56.693,
            "t": 427.0900146484375,
            "r": 171.45,
            "b": 414.40801464843753,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            15
          ]
        }
      ],
      "orig": "1. Introduction",
      "text": "1. Introduction",
      "level": 1
    },
    {
      "self_ref": "#/texts/12",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 56.693,
            "t": 405.4550146484375,
            "r": 282.7,
            "b": 57.093014648437475,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1203
          ]
        },
        {
          "page_no": 1,
          "bbox": {
            "l": 312.582,
            "t": 426.3010146484375,
            "r": 538.589,
            "b": 64.3900146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            1204,
            2460
          ]
        }
      ],
      "orig": "Large Language Models (LLMs) are computational models trained on vast datasets of texts to achieve natural language generation capabilities, and that have demonstrated remarkable abilities in understanding and generating human-like text. However, their behavior as artificial social agents is largely unexplored, and we still lack extensive evidence of how these agents react to simple social stimuli. Therefore, it is crucial to rigorously test and understand their behaviors before integrating them into critical decision-making processes. Historically, Game Theory and in particular the Iterated Prisoner's Dilemma (IPD) have proven valuable tools to model the interactions between rational agents and investigate the behaviors of humans in controlled competitive and cooperative environments. Early interdisciplinary research has already tested the use of LLMs in the context of classical economic games, showing valuable results [1, 3, 4]. However, they suffer different limitations. First, they generally lack prompt validation procedures, leading to the implicit assumption that LLMs can understand the rules and state of the game described in the prompt. Second, the duration of the games is of- ten limited to a few rounds, and the models are initialized with predefined 'personas'. These elements hamper the LLMs' ability to discern the patterns of other participants and limit the exploration of their baseline behavior. Finally, the majority of those studies focus on simple behavioral metrics, overlooking higher-level patterns that could enhance understanding of player behaviors. The combined effect of these limitations has led to findings that are sometimes inconclusive and contradictory calling for more systematic evidence on the behavior of LLMs in iterated games. The aim of this work is to investigate the cooperative behavior of Llama2, Llama3, and GPT3.5 when playing the Iterated Prisoner's Dilemma against random adversaries displaying various levels of hostility. I introduce a systematic methodology to evaluate an LLM's comprehension of the game's rules and state, showing the impact that different framing can have. After refining a prompt that allowed the models to interpret the relevant information correctly, I conducted extensive simulations over 100-rounds-long games and analyzed the LLM's decisions in terms of dimensions defined in the behavioral economics literature. I find that Llama2 and GPT3.5 exhibit more coopera-",
      "text": "Large Language Models (LLMs) are computational models trained on vast datasets of texts to achieve natural language generation capabilities, and that have demonstrated remarkable abilities in understanding and generating human-like text. However, their behavior as artificial social agents is largely unexplored, and we still lack extensive evidence of how these agents react to simple social stimuli. Therefore, it is crucial to rigorously test and understand their behaviors before integrating them into critical decision-making processes. Historically, Game Theory and in particular the Iterated Prisoner's Dilemma (IPD) have proven valuable tools to model the interactions between rational agents and investigate the behaviors of humans in controlled competitive and cooperative environments. Early interdisciplinary research has already tested the use of LLMs in the context of classical economic games, showing valuable results [1, 3, 4]. However, they suffer different limitations. First, they generally lack prompt validation procedures, leading to the implicit assumption that LLMs can understand the rules and state of the game described in the prompt. Second, the duration of the games is of- ten limited to a few rounds, and the models are initialized with predefined 'personas'. These elements hamper the LLMs' ability to discern the patterns of other participants and limit the exploration of their baseline behavior. Finally, the majority of those studies focus on simple behavioral metrics, overlooking higher-level patterns that could enhance understanding of player behaviors. The combined effect of these limitations has led to findings that are sometimes inconclusive and contradictory calling for more systematic evidence on the behavior of LLMs in iterated games. The aim of this work is to investigate the cooperative behavior of Llama2, Llama3, and GPT3.5 when playing the Iterated Prisoner's Dilemma against random adversaries displaying various levels of hostility. I introduce a systematic methodology to evaluate an LLM's comprehension of the game's rules and state, showing the impact that different framing can have. After refining a prompt that allowed the models to interpret the relevant information correctly, I conducted extensive simulations over 100-rounds-long games and analyzed the LLM's decisions in terms of dimensions defined in the behavioral economics literature. I find that Llama2 and GPT3.5 exhibit more coopera-"
    },
    {
      "self_ref": "#/texts/13",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_footer",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 294.926,
            "t": 34.32101464843754,
            "r": 300.35,
            "b": 24.689014648437478,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "1",
      "text": "1"
    },
    {
      "self_ref": "#/texts/14",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_header",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 70.866,
            "t": 794.1990146484375,
            "r": 178.525,
            "b": 784.5560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            17
          ]
        }
      ],
      "orig": "Executive summary",
      "text": "Executive summary"
    },
    {
      "self_ref": "#/texts/15",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_header",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 442.099,
            "t": 794.1990146484375,
            "r": 524.415,
            "b": 784.5560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            14
          ]
        }
      ],
      "orig": "Nicol\u00f2 Fontana",
      "text": "Nicol\u00f2 Fontana"
    },
    {
      "self_ref": "#/texts/16",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 56.693,
            "t": 753.4080146484375,
            "r": 282.699,
            "b": 567.6360146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            658
          ]
        }
      ],
      "orig": "tive behavior than humans at every level of opponent hostility, although they maintain a cautious approach, requiring an opponent defection rate below 30% to significantly engage in cooperation. In contrast, Llama3 demonstrates behaviors more aligned with human results, showing greater strategic thinking, less cooperation, and more exploitative tendencies. These results indicate substantial variability in responses among different models, even in identical environments, games, and framings. My systematic approach to studying LLMs in game theoretical scenarios is a step towards using these simulations to inform practices of LLM auditing and alignment.",
      "text": "tive behavior than humans at every level of opponent hostility, although they maintain a cautious approach, requiring an opponent defection rate below 30% to significantly engage in cooperation. In contrast, Llama3 demonstrates behaviors more aligned with human results, showing greater strategic thinking, less cooperation, and more exploitative tendencies. These results indicate substantial variability in responses among different models, even in identical environments, games, and framings. My systematic approach to studying LLMs in game theoretical scenarios is a step towards using these simulations to inform practices of LLM auditing and alignment."
    },
    {
      "self_ref": "#/texts/17",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 56.693,
            "t": 552.3270146484375,
            "r": 167.22,
            "b": 539.6450146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            13
          ]
        }
      ],
      "orig": "2. Background",
      "text": "2. Background",
      "level": 1
    },
    {
      "self_ref": "#/texts/18",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 56.693,
            "t": 529.8410146484375,
            "r": 282.691,
            "b": 519.2730146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            36
          ]
        }
      ],
      "orig": "2.1. The Iterated Prisoner's Dilemma",
      "text": "2.1. The Iterated Prisoner's Dilemma",
      "level": 1
    },
    {
      "self_ref": "#/texts/19",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 56.693,
            "t": 510.8630146484375,
            "r": 282.7,
            "b": 108.30501464843746,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1371
          ]
        }
      ],
      "orig": "The Prisoner's Dilemma (PD) is a classic thought experiment in Game Theory (the branch of mathematics that studies the interaction between rational agents and their modeling) and serves as a paradigm for analyzing conflict and cooperation between two players. In this scenario, two players who cannot communicate with each other can choose between two actions ( Cooperate and Defect ), and depending on the combination of chosen actions they receive a payoff. Mutual cooperation results in the highest collective payoff, with a reward R for both. If one player defects while the other cooperates, the defector receives a higher temptation payoff of T while the cooperator receives the lower sucker's payoff of S . If both defect, they each receive a punishment payoff of P for failing to cooperate. This game's structure is traditionally defined by the hierarchy T > R > P > S , which typically encourages rational players to prefer defection as it is their dominant strategy. In its iterated version (IPD), if the number of rounds is finite and known to both players, the game has one theoretical solution which is to always choose Defect , if it is infinite or unknown no strategy universally outperforms all others. Interestingly, human subjects tend to play more cooperatively than the optimal solution regardless of the number of rounds and their knowledge about it.",
      "text": "The Prisoner's Dilemma (PD) is a classic thought experiment in Game Theory (the branch of mathematics that studies the interaction between rational agents and their modeling) and serves as a paradigm for analyzing conflict and cooperation between two players. In this scenario, two players who cannot communicate with each other can choose between two actions ( Cooperate and Defect ), and depending on the combination of chosen actions they receive a payoff. Mutual cooperation results in the highest collective payoff, with a reward R for both. If one player defects while the other cooperates, the defector receives a higher temptation payoff of T while the cooperator receives the lower sucker's payoff of S . If both defect, they each receive a punishment payoff of P for failing to cooperate. This game's structure is traditionally defined by the hierarchy T > R > P > S , which typically encourages rational players to prefer defection as it is their dominant strategy. In its iterated version (IPD), if the number of rounds is finite and known to both players, the game has one theoretical solution which is to always choose Defect , if it is infinite or unknown no strategy universally outperforms all others. Interestingly, human subjects tend to play more cooperatively than the optimal solution regardless of the number of rounds and their knowledge about it."
    },
    {
      "self_ref": "#/texts/20",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 312.582,
            "t": 753.4190146484375,
            "r": 434.858,
            "b": 743.7760146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            21
          ]
        }
      ],
      "orig": "2.1.1 Main strategies",
      "text": "2.1.1 Main strategies",
      "level": 1
    },
    {
      "self_ref": "#/texts/21",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 312.582,
            "t": 732.8130146484375,
            "r": 538.589,
            "b": 533.4920146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            638
          ]
        }
      ],
      "orig": "The main strategies that best describe human approaches are: Always Cooperate , Always Defect , Tit For Tat (where the player starts with Cooperate and then mimics the opponent's previous action), Suspicious Tit For Tat (like TFT , but starts with Defect ), Grim Trigger (where the player starts with Cooperate and chooses Defect for the rest of the game, once the opponent has defected), and Win -Stay Lose -Shift (where the player starts with Cooperate and then repeats the previous action if the payoff was R or T . otherwise the other action is chosen). More than 75% of the time, humans play a combination of AD , GRIM , and TFT [5].",
      "text": "The main strategies that best describe human approaches are: Always Cooperate , Always Defect , Tit For Tat (where the player starts with Cooperate and then mimics the opponent's previous action), Suspicious Tit For Tat (like TFT , but starts with Defect ), Grim Trigger (where the player starts with Cooperate and chooses Defect for the rest of the game, once the opponent has defected), and Win -Stay Lose -Shift (where the player starts with Cooperate and then repeats the previous action if the payoff was R or T . otherwise the other action is chosen). More than 75% of the time, humans play a combination of AD , GRIM , and TFT [5]."
    },
    {
      "self_ref": "#/texts/22",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 312.582,
            "t": 514.3210146484375,
            "r": 499.964,
            "b": 504.6780146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            33
          ]
        }
      ],
      "orig": "2.1.2 Behavioral characterization",
      "text": "2.1.2 Behavioral characterization",
      "level": 1
    },
    {
      "self_ref": "#/texts/23",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 312.582,
            "t": 493.7150146484375,
            "r": 538.588,
            "b": 456.9850146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            107
          ]
        }
      ],
      "orig": "Different dimensions can be used to characterize the behaviors displayed by the players. In my work, I use:",
      "text": "Different dimensions can be used to characterize the behaviors displayed by the players. In my work, I use:"
    },
    {
      "self_ref": "#/texts/24",
      "parent": {
        "$ref": "#/groups/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "list_item",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 323.491,
            "t": 453.1230146484375,
            "r": 538.58,
            "b": 429.8870146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            72
          ]
        }
      ],
      "orig": "\u00b7 Cooperative : fraction of rounds in which the player chose Cooperate .",
      "text": "Cooperative : fraction of rounds in which the player chose Cooperate .",
      "enumerated": false,
      "marker": "\u00b7"
    },
    {
      "self_ref": "#/texts/25",
      "parent": {
        "$ref": "#/groups/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "list_item",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 323.491,
            "t": 426.0240146484375,
            "r": 538.588,
            "b": 402.7880146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            61
          ]
        }
      ],
      "orig": "\u00b7 Nice : 0 if the player is the first to defect, 1 otherwise.",
      "text": "Nice : 0 if the player is the first to defect, 1 otherwise.",
      "enumerated": false,
      "marker": "\u00b7"
    },
    {
      "self_ref": "#/texts/26",
      "parent": {
        "$ref": "#/groups/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "list_item",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 323.491,
            "t": 402.4520146484375,
            "r": 538.588,
            "b": 307.9440146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            322
          ]
        }
      ],
      "orig": "\u00b7 Forgiving : # forgiven _ defection # opponent _ defection +# penalties , representing the propensity to cooperate again after an opponent's defection ( # penalties corresponds to the times that, after defecting, the opponent sought forgiveness by cooperating and the player did not forgive them, thus keeping defecting).",
      "text": "Forgiving : # forgiven _ defection # opponent _ defection +# penalties , representing the propensity to cooperate again after an opponent's defection ( # penalties corresponds to the times that, after defecting, the opponent sought forgiveness by cooperating and the player did not forgive them, thus keeping defecting).",
      "enumerated": false,
      "marker": "\u00b7"
    },
    {
      "self_ref": "#/texts/27",
      "parent": {
        "$ref": "#/groups/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "list_item",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 323.491,
            "t": 306.9730146484376,
            "r": 538.589,
            "b": 267.29601464843745,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            123
          ]
        }
      ],
      "orig": "\u00b7 Retaliatory : # reactions # provocations , representing the propensity to defect immediately after an uncalled defection.",
      "text": "Retaliatory : # reactions # provocations , representing the propensity to defect immediately after an uncalled defection.",
      "enumerated": false,
      "marker": "\u00b7"
    },
    {
      "self_ref": "#/texts/28",
      "parent": {
        "$ref": "#/groups/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "list_item",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 323.491,
            "t": 266.96001464843744,
            "r": 538.583,
            "b": 197.9770146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            239
          ]
        }
      ],
      "orig": "\u00b7 Troublemaking : # uncalled _ defection # occasions _ to _ provoke , representing the propensity to provoke (i.e., defect unprovoked) ( # occasions _ to _ provoke is the number of times that the opponent cooperated in the previous round).",
      "text": "Troublemaking : # uncalled _ defection # occasions _ to _ provoke , representing the propensity to provoke (i.e., defect unprovoked) ( # occasions _ to _ provoke is the number of times that the opponent cooperated in the previous round).",
      "enumerated": false,
      "marker": "\u00b7"
    },
    {
      "self_ref": "#/texts/29",
      "parent": {
        "$ref": "#/groups/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "list_item",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 323.491,
            "t": 197.00601464843749,
            "r": 538.583,
            "b": 130.2310146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            183
          ]
        }
      ],
      "orig": "\u00b7 Emulative : # mimic N -1 , representing the propensity to copy the opponent's last move ( # mimic is any time the player copied the opponent's last move, N is the number of rounds).",
      "text": "Emulative : # mimic N -1 , representing the propensity to copy the opponent's last move ( # mimic is any time the player copied the opponent's last move, N is the number of rounds).",
      "enumerated": false,
      "marker": "\u00b7"
    },
    {
      "self_ref": "#/texts/30",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 312.582,
            "t": 126.36901464843754,
            "r": 538.589,
            "b": 62.48501464843753,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            231
          ]
        }
      ],
      "orig": "Axelrod [2] showed that strategies that are Nice , Forgiving , and Retaliatory perform best against a wide variety of opponents, and TFT is one of them. The Strategy Frequency Estimation Method (SFEM) I used is a maximum likelihood",
      "text": "Axelrod [2] showed that strategies that are Nice , Forgiving , and Retaliatory perform best against a wide variety of opponents, and TFT is one of them. The Strategy Frequency Estimation Method (SFEM) I used is a maximum likelihood"
    },
    {
      "self_ref": "#/texts/31",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_footer",
      "prov": [
        {
          "page_no": 2,
          "bbox": {
            "l": 294.926,
            "t": 34.32101464843754,
            "r": 300.35,
            "b": 24.689014648437478,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "2",
      "text": "2"
    },
    {
      "self_ref": "#/texts/32",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_header",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 70.866,
            "t": 794.1990146484375,
            "r": 178.525,
            "b": 784.5560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            17
          ]
        }
      ],
      "orig": "Executive summary",
      "text": "Executive summary"
    },
    {
      "self_ref": "#/texts/33",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_header",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 442.099,
            "t": 794.1990146484375,
            "r": 524.415,
            "b": 784.5560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            14
          ]
        }
      ],
      "orig": "Nicol\u00f2 Fontana",
      "text": "Nicol\u00f2 Fontana"
    },
    {
      "self_ref": "#/texts/34",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 56.693,
            "t": 753.4080146484375,
            "r": 282.699,
            "b": 676.0300146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            268
          ]
        }
      ],
      "orig": "estimation approach that, given a set of candidate strategies and a sequence of actions, assigns a score between 0 and 1 to each strategy in the set. The scores (that do not need to sum up to 1) represent how well a certain strategy can explain the given sequence [5].",
      "text": "estimation approach that, given a set of candidate strategies and a sequence of actions, assigns a score between 0 and 1 to each strategy in the set. The scores (that do not need to sum up to 1) represent how well a certain strategy can explain the given sequence [5]."
    },
    {
      "self_ref": "#/texts/35",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 56.693,
            "t": 663.0550146484375,
            "r": 231.158,
            "b": 652.4870146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            26
          ]
        }
      ],
      "orig": "2.2. Large Language Models",
      "text": "2.2. Large Language Models",
      "level": 1
    },
    {
      "self_ref": "#/texts/36",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 56.693,
            "t": 644.0770146484375,
            "r": 282.7,
            "b": 322.8140146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1082
          ]
        }
      ],
      "orig": "LLMs are algorithms, often implemented as Artificial Neural Networks and designed to predict and generate sequences of tokens (i.e. words or parts of words) based on patterns learned from vast amounts of text data. Given a certain input, LLMs are trained to align their outputs with the expectations of the developers. To do this, during the training phase, every time they generate an output they receive numerical feedback and use it to update their estimation of the probability distribution of tokens. When the training is completed and the distribution is learned, the models have gained comprehensive knowledge of syntax, semantics, and contextual understanding, enabling them to perform a wide range of downstream tasks like text completion, classification, and question answering. Their abilities have been used by many studies to power agents that simulate human behaviors in various contexts. These LLM-powered agents showed great potential to replace human subjects in many experiments, offering an affordable test bed for testing sociological and psychological theories.",
      "text": "LLMs are algorithms, often implemented as Artificial Neural Networks and designed to predict and generate sequences of tokens (i.e. words or parts of words) based on patterns learned from vast amounts of text data. Given a certain input, LLMs are trained to align their outputs with the expectations of the developers. To do this, during the training phase, every time they generate an output they receive numerical feedback and use it to update their estimation of the probability distribution of tokens. When the training is completed and the distribution is learned, the models have gained comprehensive knowledge of syntax, semantics, and contextual understanding, enabling them to perform a wide range of downstream tasks like text completion, classification, and question answering. Their abilities have been used by many studies to power agents that simulate human behaviors in various contexts. These LLM-powered agents showed great potential to replace human subjects in many experiments, offering an affordable test bed for testing sociological and psychological theories."
    },
    {
      "self_ref": "#/texts/37",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 56.693,
            "t": 307.50401464843753,
            "r": 282.699,
            "b": 276.8900146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            39
          ]
        }
      ],
      "orig": "3. Proposed Solution and Implementation",
      "text": "3. Proposed Solution and Implementation",
      "level": 1
    },
    {
      "self_ref": "#/texts/38",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 56.693,
            "t": 267.0860146484375,
            "r": 222.397,
            "b": 256.51801464843743,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            24
          ]
        }
      ],
      "orig": "3.1. LLMs and game setup",
      "text": "3.1. LLMs and game setup",
      "level": 1
    },
    {
      "self_ref": "#/texts/39",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 56.693,
            "t": 248.10801464843757,
            "r": 282.7,
            "b": 62.3370146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            644
          ]
        },
        {
          "page_no": 3,
          "bbox": {
            "l": 312.582,
            "t": 753.4080146484375,
            "r": 538.587,
            "b": 648.9310146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            645,
            999
          ]
        }
      ],
      "orig": "I used two open-source models (Llama2, Llama3 through the Inference API provided by Hugging Face) and one closed-source (GPT3.5 through the API provided by OpenAI). I made the models play games that consisted of N = 100 rounds each (repeated for k = 100 times due to the stochastic nature of LLMs) and here I report the average results along with 95% confidence intervals. To evaluate the LLM's adaptability to different degrees of environmental hostility, I repeated the experiment by matching the LLMs against Random opponents with varying probability of cooperation \u03b1 \u2208 [0 , 1] . The final outcome of each game is a sequence containing pairs of binary values representing the actions of the LLM (player A ) and the opponent (player B ) at each round i ( G \u03b1 k ). From G \u03b1,A k (i.e. the sequence of the LLM's actions), I extracted the empirical probability of the LLM to cooperate at round i , calculated as the average of the fraction of i th rounds in which the LLM cooperated over the k trials:",
      "text": "I used two open-source models (Llama2, Llama3 through the Inference API provided by Hugging Face) and one closed-source (GPT3.5 through the API provided by OpenAI). I made the models play games that consisted of N = 100 rounds each (repeated for k = 100 times due to the stochastic nature of LLMs) and here I report the average results along with 95% confidence intervals. To evaluate the LLM's adaptability to different degrees of environmental hostility, I repeated the experiment by matching the LLMs against Random opponents with varying probability of cooperation \u03b1 \u2208 [0 , 1] . The final outcome of each game is a sequence containing pairs of binary values representing the actions of the LLM (player A ) and the opponent (player B ) at each round i ( G \u03b1 k ). From G \u03b1,A k (i.e. the sequence of the LLM's actions), I extracted the empirical probability of the LLM to cooperate at round i , calculated as the average of the fraction of i th rounds in which the LLM cooperated over the k trials:"
    },
    {
      "self_ref": "#/texts/40",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "formula",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 369.506,
            "t": 649.4760146484375,
            "r": 538.584,
            "b": 619.7690146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            42
          ]
        }
      ],
      "orig": "p \u03b1 coop ( i ) = 1 k \u2211 k G \u03b1,A k ( i ) (1)",
      "text": ""
    },
    {
      "self_ref": "#/texts/41",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 312.582,
            "t": 612.7310146484375,
            "r": 538.585,
            "b": 576.0010146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            109
          ]
        }
      ],
      "orig": "I calculated the average cooperation probability throughout a game by averaging p \u03b1 coop ( i ) over N rounds:",
      "text": "I calculated the average cooperation probability throughout a game by averaging p \u03b1 coop ( i ) over N rounds:"
    },
    {
      "self_ref": "#/texts/42",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "formula",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 374.215,
            "t": 575.0310146484375,
            "r": 538.584,
            "b": 541.3410146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            42
          ]
        }
      ],
      "orig": "p \u03b1 coop = 1 N N \u2211 i =1 p \u03b1 coop ( i ) (2)",
      "text": ""
    },
    {
      "self_ref": "#/texts/43",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 312.582,
            "t": 534.3030146484375,
            "r": 538.589,
            "b": 362.08101464843753,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            591
          ]
        }
      ],
      "orig": "To query the models, I iteratively designed a prompt composed of 3 main components: system prompt (fixed part to explain the game rules), contextual prompt (representing the state of the game and acting as a memory for the LLM), and instructing prompt (used to assign to the LLM an instruction to be executed or a query to be answered). In formulating the memory component, I explored various window sizes to provide the LLM with information from only the n most recent rounds and determined the optimal window size of 10 through targeted experiments that matched the LLM against AD players.",
      "text": "To query the models, I iteratively designed a prompt composed of 3 main components: system prompt (fixed part to explain the game rules), contextual prompt (representing the state of the game and acting as a memory for the LLM), and instructing prompt (used to assign to the LLM an instruction to be executed or a query to be answered). In formulating the memory component, I explored various window sizes to provide the LLM with information from only the n most recent rounds and determined the optimal window size of 10 through targeted experiments that matched the LLM against AD players."
    },
    {
      "self_ref": "#/texts/44",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 312.582,
            "t": 349.10701464843754,
            "r": 443.604,
            "b": 338.5390146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            19
          ]
        }
      ],
      "orig": "3.2. Meta-prompting",
      "text": "3.2. Meta-prompting",
      "level": 1
    },
    {
      "self_ref": "#/texts/45",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 312.582,
            "t": 330.12901464843753,
            "r": 538.589,
            "b": 63.062014648437525,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            918
          ]
        }
      ],
      "orig": "The first problem I addressed relates to the evolving field of prompting. Although numerous benchmarks exist to assess LLMs' tasksolving abilities, these downstream evaluations can be compromised by the models' tendencies to hallucinate. My approach involves designing task- and prompt-specific meta-questions to assess the model's understanding of the prompt, reducing the risk of collecting subsequent hallucinating answers when the actual task is provided. It is particularly relevant for a generative task like playing the IPD, where any sequence of Cooperate and Defect actions could be considered plausible, making it difficult to discern whether LLM-generated sequences reflect a proper understanding of the game's rules or are merely the product of the model hallucinating. In particular, I formulated a set of comprehension questions that address three key aspects of the prompt (see Table 1): the game rules,",
      "text": "The first problem I addressed relates to the evolving field of prompting. Although numerous benchmarks exist to assess LLMs' tasksolving abilities, these downstream evaluations can be compromised by the models' tendencies to hallucinate. My approach involves designing task- and prompt-specific meta-questions to assess the model's understanding of the prompt, reducing the risk of collecting subsequent hallucinating answers when the actual task is provided. It is particularly relevant for a generative task like playing the IPD, where any sequence of Cooperate and Defect actions could be considered plausible, making it difficult to discern whether LLM-generated sequences reflect a proper understanding of the game's rules or are merely the product of the model hallucinating. In particular, I formulated a set of comprehension questions that address three key aspects of the prompt (see Table 1): the game rules,"
    },
    {
      "self_ref": "#/texts/46",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_footer",
      "prov": [
        {
          "page_no": 3,
          "bbox": {
            "l": 294.926,
            "t": 34.32101464843754,
            "r": 300.35,
            "b": 24.689014648437478,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "3",
      "text": "3"
    },
    {
      "self_ref": "#/texts/47",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_header",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 70.866,
            "t": 794.1990146484375,
            "r": 178.525,
            "b": 784.5560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            17
          ]
        }
      ],
      "orig": "Executive summary",
      "text": "Executive summary"
    },
    {
      "self_ref": "#/texts/48",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_header",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 442.099,
            "t": 794.1990146484375,
            "r": 524.415,
            "b": 784.5560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            14
          ]
        }
      ],
      "orig": "Nicol\u00f2 Fontana",
      "text": "Nicol\u00f2 Fontana"
    },
    {
      "self_ref": "#/texts/49",
      "parent": {
        "$ref": "#/tables/0"
      },
      "children": [],
      "content_layer": "body",
      "label": "caption",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 56.693,
            "t": 486.2890146484375,
            "r": 282.699,
            "b": 463.1080146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            53
          ]
        }
      ],
      "orig": "Table 1: Templates of prompt comprehension questions.",
      "text": "Table 1: Templates of prompt comprehension questions."
    },
    {
      "self_ref": "#/texts/50",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 56.693,
            "t": 437.7910146484375,
            "r": 282.7,
            "b": 333.3150146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            325
          ]
        }
      ],
      "orig": "the chronological sequence of actions within the game history, and some cumulative game statistics. To assess the LLM's proficiency in responding to meta-prompting questions, I conducted 1 game of 100 rounds against RND opponents where I posed the questions at each round and computed the average accuracy of LLMs' responses.",
      "text": "the chronological sequence of actions within the game history, and some cumulative game statistics. To assess the LLM's proficiency in responding to meta-prompting questions, I conducted 1 game of 100 rounds against RND opponents where I posed the questions at each round and computed the average accuracy of LLMs' responses."
    },
    {
      "self_ref": "#/texts/51",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 56.693,
            "t": 320.34001464843755,
            "r": 148.728,
            "b": 309.77201464843756,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            14
          ]
        }
      ],
      "orig": "3.3. Behaviors",
      "text": "3.3. Behaviors",
      "level": 1
    },
    {
      "self_ref": "#/texts/52",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 56.693,
            "t": 301.3620146484375,
            "r": 282.7,
            "b": 61.39401464843752,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            816
          ]
        }
      ],
      "orig": "The second problem pertains to understanding the embedded behaviors of state-of-the-art LLMs to align them with human values. While GT and the IPD can serve this scope, there is no commonly used behavioral framework to characterize the choice patterns displayed by LLMs, and more structural effort is needed. Therefore my work represents an initial step in this direction. Given a game history, I profiled the LLMs' behavior in two ways. First, for each dimension d (\u00a7 2.1), I computed the score against each \u03b1 and its average distance from the RND score. Second, I used the SFEM to find which strategies best explained the player's sequence of actions. For this, I used the following set of candidate strategies and averaged the scores over all the histories analyzed: AC , AD , RND , TFT , STFT , GRIM , and WSLS .",
      "text": "The second problem pertains to understanding the embedded behaviors of state-of-the-art LLMs to align them with human values. While GT and the IPD can serve this scope, there is no commonly used behavioral framework to characterize the choice patterns displayed by LLMs, and more structural effort is needed. Therefore my work represents an initial step in this direction. Given a game history, I profiled the LLMs' behavior in two ways. First, for each dimension d (\u00a7 2.1), I computed the score against each \u03b1 and its average distance from the RND score. Second, I used the SFEM to find which strategies best explained the player's sequence of actions. For this, I used the following set of candidate strategies and averaged the scores over all the histories analyzed: AC , AD , RND , TFT , STFT , GRIM , and WSLS ."
    },
    {
      "self_ref": "#/texts/53",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "caption",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 312.582,
            "t": 631.9200146484375,
            "r": 538.584,
            "b": 595.1890146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            106
          ]
        }
      ],
      "orig": "Figure 1: All three models' accuracy on the comprehension questions using the final version of the prompt.",
      "text": "Figure 1: All three models' accuracy on the comprehension questions using the final version of the prompt."
    },
    {
      "self_ref": "#/texts/54",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 335.969,
            "t": 675.9440146484375,
            "r": 343.282,
            "b": 647.2860146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            7
          ]
        }
      ],
      "orig": "min_max",
      "text": "min_max"
    },
    {
      "self_ref": "#/texts/55",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 362.062,
            "t": 675.9480146484375,
            "r": 369.376,
            "b": 653.3480146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            7
          ]
        }
      ],
      "orig": "actions",
      "text": "actions"
    },
    {
      "self_ref": "#/texts/56",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 388.067,
            "t": 675.9420146484375,
            "r": 395.381,
            "b": 656.1290146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "payoff",
      "text": "payoff"
    },
    {
      "self_ref": "#/texts/57",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 414.072,
            "t": 675.9690146484376,
            "r": 421.386,
            "b": 657.7370146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            5
          ]
        }
      ],
      "orig": "round",
      "text": "round"
    },
    {
      "self_ref": "#/texts/58",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 439.927,
            "t": 674.2380146484376,
            "r": 447.241,
            "b": 654.9120146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "action",
      "text": "action"
    },
    {
      "self_ref": "#/texts/59",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 442.707,
            "t": 675.5180146484375,
            "r": 447.826,
            "b": 674.2960146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "i",
      "text": "i"
    },
    {
      "self_ref": "#/texts/60",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 465.824,
            "t": 674.1930146484375,
            "r": 473.138,
            "b": 654.9120146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "points",
      "text": "points"
    },
    {
      "self_ref": "#/texts/61",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 468.604,
            "t": 675.4750146484375,
            "r": 473.724,
            "b": 674.2540146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "i",
      "text": "i"
    },
    {
      "self_ref": "#/texts/62",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 492.087,
            "t": 675.9460146484375,
            "r": 499.401,
            "b": 648.0850146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            8
          ]
        }
      ],
      "orig": "#actions",
      "text": "#actions"
    },
    {
      "self_ref": "#/texts/63",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 518.092,
            "t": 675.9420146484375,
            "r": 525.406,
            "b": 651.3960146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            7
          ]
        }
      ],
      "orig": "#points",
      "text": "#points"
    },
    {
      "self_ref": "#/texts/64",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 315.97,
            "t": 689.7190146484376,
            "r": 324.954,
            "b": 683.1370146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.7",
      "text": "0.7"
    },
    {
      "self_ref": "#/texts/65",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 315.97,
            "t": 706.6710146484376,
            "r": 324.954,
            "b": 700.0890146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.8",
      "text": "0.8"
    },
    {
      "self_ref": "#/texts/66",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 315.97,
            "t": 723.6230146484376,
            "r": 324.954,
            "b": 717.0400146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.9",
      "text": "0.9"
    },
    {
      "self_ref": "#/texts/67",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 315.97,
            "t": 740.5740146484375,
            "r": 324.954,
            "b": 733.9920146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/68",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 356.127,
            "t": 753.4360146484375,
            "r": 373.068,
            "b": 746.1220146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            5
          ]
        }
      ],
      "orig": "Rules",
      "text": "Rules"
    },
    {
      "self_ref": "#/texts/69",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 435.972,
            "t": 753.4360146484375,
            "r": 451.337,
            "b": 746.1220146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "Time",
      "text": "Time"
    },
    {
      "self_ref": "#/texts/70",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 503.998,
            "t": 753.4360146484375,
            "r": 520.615,
            "b": 746.1220146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            5
          ]
        }
      ],
      "orig": "State",
      "text": "State"
    },
    {
      "self_ref": "#/texts/71",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 343.412,
            "t": 699.9890146484375,
            "r": 359.544,
            "b": 694.8690146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Llama2",
      "text": "Llama2"
    },
    {
      "self_ref": "#/texts/72",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 343.412,
            "t": 693.5400146484375,
            "r": 359.544,
            "b": 688.4200146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Llama3",
      "text": "Llama3"
    },
    {
      "self_ref": "#/texts/73",
      "parent": {
        "$ref": "#/pictures/1"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 343.412,
            "t": 687.0900146484375,
            "r": 358.643,
            "b": 681.9710146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Gpt35t",
      "text": "Gpt35t"
    },
    {
      "self_ref": "#/texts/74",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "caption",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 312.582,
            "t": 433.7550146484375,
            "r": 538.587,
            "b": 383.47501464843754,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            168
          ]
        }
      ],
      "orig": "Figure 2: Llama2 average cooperation against AD with memory window sizes of 100 and 10 rounds. Inset: Llama2 average cooperation against AD with different window sizes.",
      "text": "Figure 2: Llama2 average cooperation against AD with memory window sizes of 100 and 10 rounds. Inset: Llama2 average cooperation against AD with different window sizes."
    },
    {
      "self_ref": "#/texts/75",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 354.616,
            "t": 465.1780146484375,
            "r": 358.609,
            "b": 457.8640146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "0",
      "text": "0"
    },
    {
      "self_ref": "#/texts/76",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 382.345,
            "t": 465.1780146484375,
            "r": 390.33,
            "b": 457.8640146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "20",
      "text": "20"
    },
    {
      "self_ref": "#/texts/77",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 412.069,
            "t": 465.1780146484375,
            "r": 420.055,
            "b": 457.8640146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "40",
      "text": "40"
    },
    {
      "self_ref": "#/texts/78",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 441.794,
            "t": 465.1780146484375,
            "r": 449.779,
            "b": 457.8640146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "60",
      "text": "60"
    },
    {
      "self_ref": "#/texts/79",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 471.519,
            "t": 465.1780146484375,
            "r": 479.504,
            "b": 457.8640146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "80",
      "text": "80"
    },
    {
      "self_ref": "#/texts/80",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 499.247,
            "t": 465.1780146484375,
            "r": 511.225,
            "b": 457.8640146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "100",
      "text": "100"
    },
    {
      "self_ref": "#/texts/81",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 419.754,
            "t": 458.0600146484375,
            "r": 443.598,
            "b": 449.2840146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            5
          ]
        }
      ],
      "orig": "Round",
      "text": "Round"
    },
    {
      "self_ref": "#/texts/82",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 338.564,
            "t": 474.83301464843754,
            "r": 348.545,
            "b": 467.5190146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/83",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 338.564,
            "t": 495.1200146484375,
            "r": 348.545,
            "b": 487.80701464843753,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.2",
      "text": "0.2"
    },
    {
      "self_ref": "#/texts/84",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 338.564,
            "t": 515.4080146484375,
            "r": 348.545,
            "b": 508.0940146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.4",
      "text": "0.4"
    },
    {
      "self_ref": "#/texts/85",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 338.564,
            "t": 535.6950146484376,
            "r": 348.545,
            "b": 528.3820146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.6",
      "text": "0.6"
    },
    {
      "self_ref": "#/texts/86",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 338.564,
            "t": 555.9830146484375,
            "r": 348.545,
            "b": 548.6690146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.8",
      "text": "0.8"
    },
    {
      "self_ref": "#/texts/87",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 338.564,
            "t": 576.2710146484375,
            "r": 348.545,
            "b": 568.9570146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/88",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 367.001,
            "t": 574.6840146484375,
            "r": 382.667,
            "b": 569.5640146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "ws 100",
      "text": "ws 100"
    },
    {
      "self_ref": "#/texts/89",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 367.001,
            "t": 568.2340146484376,
            "r": 379.872,
            "b": 563.1150146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            5
          ]
        }
      ],
      "orig": "ws 10",
      "text": "ws 10"
    },
    {
      "self_ref": "#/texts/90",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 451.305,
            "t": 505.2510146484375,
            "r": 454.1,
            "b": 500.1320146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "0",
      "text": "0"
    },
    {
      "self_ref": "#/texts/91",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 463.467,
            "t": 505.2510146484375,
            "r": 469.057,
            "b": 500.1320146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "10",
      "text": "10"
    },
    {
      "self_ref": "#/texts/92",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 477.027,
            "t": 505.2510146484375,
            "r": 482.617,
            "b": 500.1320146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "20",
      "text": "20"
    },
    {
      "self_ref": "#/texts/93",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 490.587,
            "t": 505.2510146484375,
            "r": 496.177,
            "b": 500.1320146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "30",
      "text": "30"
    },
    {
      "self_ref": "#/texts/94",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 504.147,
            "t": 505.2510146484375,
            "r": 509.737,
            "b": 500.1320146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "40",
      "text": "40"
    },
    {
      "self_ref": "#/texts/95",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 462.306,
            "t": 499.9590146484375,
            "r": 497.343,
            "b": 493.3760146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            11
          ]
        }
      ],
      "orig": "Window size",
      "text": "Window size"
    },
    {
      "self_ref": "#/texts/96",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 443.516,
            "t": 512.0240146484375,
            "r": 450.503,
            "b": 506.9050146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/97",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 443.516,
            "t": 523.6470146484376,
            "r": 450.503,
            "b": 518.5280146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.2",
      "text": "0.2"
    },
    {
      "self_ref": "#/texts/98",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 443.516,
            "t": 535.2700146484375,
            "r": 450.503,
            "b": 530.1510146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.4",
      "text": "0.4"
    },
    {
      "self_ref": "#/texts/99",
      "parent": {
        "$ref": "#/pictures/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 443.516,
            "t": 546.8930146484375,
            "r": 450.503,
            "b": 541.7740146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.6",
      "text": "0.6"
    },
    {
      "self_ref": "#/texts/100",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 312.582,
            "t": 358.9470146484375,
            "r": 489.41,
            "b": 346.2650146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            23
          ]
        }
      ],
      "orig": "4. Experimental Results",
      "text": "4. Experimental Results",
      "level": 1
    },
    {
      "self_ref": "#/texts/101",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 312.582,
            "t": 338.31901464843753,
            "r": 538.585,
            "b": 288.0400146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            177
          ]
        }
      ],
      "orig": "After iteratively trying different variations of prompts, the final version allowed all three models to achieve near-perfect accuracy in all the questions, as reported in Fig. 1",
      "text": "After iteratively trying different variations of prompts, the final version allowed all three models to achieve near-perfect accuracy in all the questions, as reported in Fig. 1"
    },
    {
      "self_ref": "#/texts/102",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 312.582,
            "t": 284.12301464843745,
            "r": 538.589,
            "b": 57.70301464843749,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            792
          ]
        }
      ],
      "orig": "Due to Llama2 displaying different responses depending on the length of the history present in the prompt (see Fig 2), I also tried different window sizes and found that around 10 the model showed the most strategic behavior (see Inset of Fig. 2). Therefore I adopted a window over the last 10 rounds in all the following experiments. As seen in Fig. 3, among the three models, Llama3 exhibits the most strategic approach, maintaining a very low cooperation level even when the opponent is nearly always cooperating ( p coop < 0 . 3 for every \u03b1 < 1 ). In contrast, Llama2's behavior follows a sigmoidal curve with the inflection point between 0 . 6 and 0 . 7 suggesting a cautious approach in interpreting the opponent's actions, though not as cautious as Llama3. GPT3.5 displays an even less",
      "text": "Due to Llama2 displaying different responses depending on the length of the history present in the prompt (see Fig 2), I also tried different window sizes and found that around 10 the model showed the most strategic behavior (see Inset of Fig. 2). Therefore I adopted a window over the last 10 rounds in all the following experiments. As seen in Fig. 3, among the three models, Llama3 exhibits the most strategic approach, maintaining a very low cooperation level even when the opponent is nearly always cooperating ( p coop < 0 . 3 for every \u03b1 < 1 ). In contrast, Llama2's behavior follows a sigmoidal curve with the inflection point between 0 . 6 and 0 . 7 suggesting a cautious approach in interpreting the opponent's actions, though not as cautious as Llama3. GPT3.5 displays an even less"
    },
    {
      "self_ref": "#/texts/103",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_footer",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 294.926,
            "t": 34.32101464843754,
            "r": 300.35,
            "b": 24.689014648437478,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "4",
      "text": "4"
    },
    {
      "self_ref": "#/texts/104",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_header",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 70.866,
            "t": 794.1990146484375,
            "r": 178.525,
            "b": 784.5560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            17
          ]
        }
      ],
      "orig": "Executive summary",
      "text": "Executive summary"
    },
    {
      "self_ref": "#/texts/105",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_header",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 442.099,
            "t": 794.1990146484375,
            "r": 524.415,
            "b": 784.5560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            14
          ]
        }
      ],
      "orig": "Nicol\u00f2 Fontana",
      "text": "Nicol\u00f2 Fontana"
    },
    {
      "self_ref": "#/texts/106",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "caption",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 56.693,
            "t": 636.4380146484375,
            "r": 282.698,
            "b": 599.7080146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            112
          ]
        }
      ],
      "orig": "Figure 3: Average level of cooperation of all three models against opponents with different levels of hostility.",
      "text": "Figure 3: Average level of cooperation of all three models against opponents with different levels of hostility."
    },
    {
      "self_ref": "#/texts/107",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 100.15,
            "t": 670.5590146484375,
            "r": 109.733,
            "b": 663.5380146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/108",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 114.41,
            "t": 670.5590146484375,
            "r": 123.993,
            "b": 663.5380146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.1",
      "text": "0.1"
    },
    {
      "self_ref": "#/texts/109",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 128.67,
            "t": 670.5590146484375,
            "r": 138.252,
            "b": 663.5380146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.2",
      "text": "0.2"
    },
    {
      "self_ref": "#/texts/110",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 142.929,
            "t": 670.5590146484375,
            "r": 152.512,
            "b": 663.5380146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.3",
      "text": "0.3"
    },
    {
      "self_ref": "#/texts/111",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 157.189,
            "t": 670.5590146484375,
            "r": 166.772,
            "b": 663.5380146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.4",
      "text": "0.4"
    },
    {
      "self_ref": "#/texts/112",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 171.449,
            "t": 670.5590146484375,
            "r": 181.031,
            "b": 663.5380146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/113",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 185.708,
            "t": 670.5590146484375,
            "r": 195.291,
            "b": 663.5380146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.6",
      "text": "0.6"
    },
    {
      "self_ref": "#/texts/114",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 199.968,
            "t": 670.5590146484375,
            "r": 209.551,
            "b": 663.5380146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.7",
      "text": "0.7"
    },
    {
      "self_ref": "#/texts/115",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 214.228,
            "t": 670.5590146484375,
            "r": 223.81,
            "b": 663.5380146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.8",
      "text": "0.8"
    },
    {
      "self_ref": "#/texts/116",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 228.487,
            "t": 670.5590146484375,
            "r": 238.07,
            "b": 663.5380146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.9",
      "text": "0.9"
    },
    {
      "self_ref": "#/texts/117",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 242.747,
            "t": 670.5590146484375,
            "r": 252.33,
            "b": 663.5380146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/118",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 110.451,
            "t": 662.8840146484375,
            "r": 234.252,
            "b": 654.6920146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            34
          ]
        }
      ],
      "orig": "Opponent cooperation probability (",
      "text": "Opponent cooperation probability ("
    },
    {
      "self_ref": "#/texts/119",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 238.888,
            "t": 662.8840146484375,
            "r": 241.63,
            "b": 654.6920146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": ")",
      "text": ")"
    },
    {
      "self_ref": "#/texts/120",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 84.71,
            "t": 679.9280146484375,
            "r": 94.293,
            "b": 672.9070146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/121",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 84.71,
            "t": 694.1770146484375,
            "r": 94.293,
            "b": 687.1560146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.2",
      "text": "0.2"
    },
    {
      "self_ref": "#/texts/122",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 84.71,
            "t": 708.4260146484376,
            "r": 94.293,
            "b": 701.4050146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.4",
      "text": "0.4"
    },
    {
      "self_ref": "#/texts/123",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 84.71,
            "t": 722.6740146484375,
            "r": 94.293,
            "b": 715.6530146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.6",
      "text": "0.6"
    },
    {
      "self_ref": "#/texts/124",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 84.71,
            "t": 736.9230146484375,
            "r": 94.293,
            "b": 729.9020146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.8",
      "text": "0.8"
    },
    {
      "self_ref": "#/texts/125",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 84.71,
            "t": 751.1720146484375,
            "r": 94.293,
            "b": 744.1510146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/126",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 116.398,
            "t": 747.7580146484376,
            "r": 134.835,
            "b": 741.9070146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Llama2",
      "text": "Llama2"
    },
    {
      "self_ref": "#/texts/127",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 116.398,
            "t": 740.3900146484375,
            "r": 134.835,
            "b": 734.5390146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Llama3",
      "text": "Llama3"
    },
    {
      "self_ref": "#/texts/128",
      "parent": {
        "$ref": "#/pictures/3"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 116.398,
            "t": 733.0210146484375,
            "r": 136.341,
            "b": 727.1700146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            7
          ]
        }
      ],
      "orig": "GPT3.5t",
      "text": "GPT3.5t"
    },
    {
      "self_ref": "#/texts/129",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 56.693,
            "t": 574.3910146484375,
            "r": 282.7,
            "b": 429.2670146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            508
          ]
        }
      ],
      "orig": "strategic approach, maintaining a low but still significant cooperation level ( 0 . 2 < p coop < 0 . 4 ) for low \u03b1 ( < 0 . 5 ) and not reaching full cooperation even when the opponent is AC . Overall, all three models exhibit non-linear behaviors but with different characteristics, where the only common trend is to increase cooperation as \u03b1 grows. These findings, especially for Llama3 and GPT3.5, support previous research that highlights the cautious response patterns of LLMs in repeated game scenarios.",
      "text": "strategic approach, maintaining a low but still significant cooperation level ( 0 . 2 < p coop < 0 . 4 ) for low \u03b1 ( < 0 . 5 ) and not reaching full cooperation even when the opponent is AC . Overall, all three models exhibit non-linear behaviors but with different characteristics, where the only common trend is to increase cooperation as \u03b1 grows. These findings, especially for Llama3 and GPT3.5, support previous research that highlights the cautious response patterns of LLMs in repeated game scenarios."
    },
    {
      "self_ref": "#/texts/130",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 56.693,
            "t": 425.35001464843754,
            "r": 282.698,
            "b": 402.1690146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            61
          ]
        }
      ],
      "orig": "The rest of the analysis is shown only for Llama3 and GPT3.5.",
      "text": "The rest of the analysis is shown only for Llama3 and GPT3.5."
    },
    {
      "self_ref": "#/texts/131",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 56.693,
            "t": 389.19401464843753,
            "r": 178.759,
            "b": 378.6260146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            18
          ]
        }
      ],
      "orig": "4.1. SFEM analysis",
      "text": "4.1. SFEM analysis",
      "level": 1
    },
    {
      "self_ref": "#/texts/132",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 56.693,
            "t": 370.2160146484375,
            "r": 282.7,
            "b": 130.24801464843745,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            812
          ]
        }
      ],
      "orig": "Fig. 4 illustrates which strategies best explain the behaviors of GPT3.5 and Llama3 as the values of \u03b1 increase. Llama3 consistently aligns with GRIM , displaying an exploitative approach even when the opponent tends to cooperate for the majority of the time. GPT3.5 shifts from GRIM to AC once the opponent's probability of cooperation exceeds 0 . 6 . Interestingly, GPT3.5's approach for cooperative scenarios can be explained by AC even if it never reaches a full cooperation pattern, being another sign of non-strategic behavior. If compared with humans (who play AD in non-cooperative contexts and a mixture of TFT and GRIM in cooperative ones), GPT3.5 is consistently more cooperative than them. Differently, Llama3 is still more cooperative in hostile environments but less when cooperation is encouraged.",
      "text": "Fig. 4 illustrates which strategies best explain the behaviors of GPT3.5 and Llama3 as the values of \u03b1 increase. Llama3 consistently aligns with GRIM , displaying an exploitative approach even when the opponent tends to cooperate for the majority of the time. GPT3.5 shifts from GRIM to AC once the opponent's probability of cooperation exceeds 0 . 6 . Interestingly, GPT3.5's approach for cooperative scenarios can be explained by AC even if it never reaches a full cooperation pattern, being another sign of non-strategic behavior. If compared with humans (who play AD in non-cooperative contexts and a mixture of TFT and GRIM in cooperative ones), GPT3.5 is consistently more cooperative than them. Differently, Llama3 is still more cooperative in hostile environments but less when cooperation is encouraged."
    },
    {
      "self_ref": "#/texts/133",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 56.693,
            "t": 117.27401464843751,
            "r": 207.008,
            "b": 106.70601464843753,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            25
          ]
        }
      ],
      "orig": "4.2. Behavioral profiling",
      "text": "4.2. Behavioral profiling",
      "level": 1
    },
    {
      "self_ref": "#/texts/134",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 56.693,
            "t": 98.29601464843756,
            "r": 282.697,
            "b": 61.566014648437545,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            134
          ]
        }
      ],
      "orig": "Fig. 5 presents the scores for all the other dimensions outlined in \u00a7 2.1, and computed for both Llama3 and GPT3.5 as \u03b1 varies. Llama3",
      "text": "Fig. 5 presents the scores for all the other dimensions outlined in \u00a7 2.1, and computed for both Llama3 and GPT3.5 as \u03b1 varies. Llama3"
    },
    {
      "self_ref": "#/texts/135",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "caption",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 312.582,
            "t": 600.2780146484375,
            "r": 538.587,
            "b": 563.5480146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            93
          ]
        }
      ],
      "orig": "Figure 4: Llama3 and GPT3.5 SFEM scores against opponents with different levels of hostility.",
      "text": "Figure 4: Llama3 and GPT3.5 SFEM scores against opponents with different levels of hostility."
    },
    {
      "self_ref": "#/texts/136",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 366.01,
            "t": 698.8450146484375,
            "r": 375.592,
            "b": 691.8240146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.1",
      "text": "0.1"
    },
    {
      "self_ref": "#/texts/137",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 382.452,
            "t": 698.8450146484375,
            "r": 392.034,
            "b": 691.8240146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.2",
      "text": "0.2"
    },
    {
      "self_ref": "#/texts/138",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 398.894,
            "t": 698.8450146484375,
            "r": 408.476,
            "b": 691.8240146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.3",
      "text": "0.3"
    },
    {
      "self_ref": "#/texts/139",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 415.336,
            "t": 698.8450146484375,
            "r": 424.918,
            "b": 691.8240146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.4",
      "text": "0.4"
    },
    {
      "self_ref": "#/texts/140",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 431.777,
            "t": 698.8450146484375,
            "r": 441.36,
            "b": 691.8240146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/141",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 448.219,
            "t": 698.8450146484375,
            "r": 457.802,
            "b": 691.8240146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.6",
      "text": "0.6"
    },
    {
      "self_ref": "#/texts/142",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 464.661,
            "t": 698.8450146484375,
            "r": 474.244,
            "b": 691.8240146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.7",
      "text": "0.7"
    },
    {
      "self_ref": "#/texts/143",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 481.103,
            "t": 698.8450146484375,
            "r": 490.686,
            "b": 691.8240146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.8",
      "text": "0.8"
    },
    {
      "self_ref": "#/texts/144",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 497.545,
            "t": 698.8450146484375,
            "r": 507.128,
            "b": 691.8240146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.9",
      "text": "0.9"
    },
    {
      "self_ref": "#/texts/145",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 349.479,
            "t": 706.9290146484375,
            "r": 359.061,
            "b": 699.9080146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/146",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 349.479,
            "t": 729.6930146484375,
            "r": 359.061,
            "b": 722.6720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/147",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 349.479,
            "t": 752.4580146484375,
            "r": 359.061,
            "b": 745.4370146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/148",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 339.478,
            "t": 739.2930146484375,
            "r": 347.669,
            "b": 713.4810146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Llama3",
      "text": "Llama3"
    },
    {
      "self_ref": "#/texts/149",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 381.166,
            "t": 733.3510146484375,
            "r": 398.041,
            "b": 727.5000146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Others",
      "text": "Others"
    },
    {
      "self_ref": "#/texts/150",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 381.166,
            "t": 725.9820146484375,
            "r": 394.365,
            "b": 720.1310146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "GRIM",
      "text": "GRIM"
    },
    {
      "self_ref": "#/texts/151",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 366.01,
            "t": 634.3990146484375,
            "r": 375.592,
            "b": 627.3780146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.1",
      "text": "0.1"
    },
    {
      "self_ref": "#/texts/152",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 382.452,
            "t": 634.3990146484375,
            "r": 392.034,
            "b": 627.3780146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.2",
      "text": "0.2"
    },
    {
      "self_ref": "#/texts/153",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 398.894,
            "t": 634.3990146484375,
            "r": 408.476,
            "b": 627.3780146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.3",
      "text": "0.3"
    },
    {
      "self_ref": "#/texts/154",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 415.336,
            "t": 634.3990146484375,
            "r": 424.918,
            "b": 627.3780146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.4",
      "text": "0.4"
    },
    {
      "self_ref": "#/texts/155",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 431.777,
            "t": 634.3990146484375,
            "r": 441.36,
            "b": 627.3780146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/156",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 448.219,
            "t": 634.3990146484375,
            "r": 457.802,
            "b": 627.3780146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.6",
      "text": "0.6"
    },
    {
      "self_ref": "#/texts/157",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 464.661,
            "t": 634.3990146484375,
            "r": 474.244,
            "b": 627.3780146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.7",
      "text": "0.7"
    },
    {
      "self_ref": "#/texts/158",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 481.103,
            "t": 634.3990146484375,
            "r": 490.686,
            "b": 627.3780146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.8",
      "text": "0.8"
    },
    {
      "self_ref": "#/texts/159",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 497.545,
            "t": 634.3990146484375,
            "r": 507.128,
            "b": 627.3780146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.9",
      "text": "0.9"
    },
    {
      "self_ref": "#/texts/160",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 370.78,
            "t": 626.7240146484376,
            "r": 494.581,
            "b": 618.5320146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            34
          ]
        }
      ],
      "orig": "Opponent cooperation probability (",
      "text": "Opponent cooperation probability ("
    },
    {
      "self_ref": "#/texts/161",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 499.217,
            "t": 626.7240146484376,
            "r": 501.959,
            "b": 618.5320146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": ")",
      "text": ")"
    },
    {
      "self_ref": "#/texts/162",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 349.479,
            "t": 642.4830146484375,
            "r": 359.061,
            "b": 635.4610146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/163",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 349.479,
            "t": 665.2470146484375,
            "r": 359.061,
            "b": 658.2260146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/164",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 349.479,
            "t": 688.0120146484375,
            "r": 359.061,
            "b": 680.9910146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/165",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 339.478,
            "t": 674.5250146484375,
            "r": 347.669,
            "b": 649.3610146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "GPT3.5",
      "text": "GPT3.5"
    },
    {
      "self_ref": "#/texts/166",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 381.166,
            "t": 661.8650146484375,
            "r": 398.041,
            "b": 656.0140146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Others",
      "text": "Others"
    },
    {
      "self_ref": "#/texts/167",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 381.166,
            "t": 654.4970146484375,
            "r": 388.021,
            "b": 648.6460146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            2
          ]
        }
      ],
      "orig": "AC",
      "text": "AC"
    },
    {
      "self_ref": "#/texts/168",
      "parent": {
        "$ref": "#/pictures/4"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 381.166,
            "t": 647.1280146484376,
            "r": 394.365,
            "b": 641.2770146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "GRIM",
      "text": "GRIM"
    },
    {
      "self_ref": "#/texts/169",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 312.582,
            "t": 538.2860146484375,
            "r": 538.585,
            "b": 393.10701464843754,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            493
          ]
        }
      ],
      "orig": "is extremely Nice but not particularly Retaliatory and even less Forgiving . It tends to score high in Troublemaking , suggesting it often initiates unprovoked defections. Finally, it displays lower levels of emulation as \u03b1 grows (except when facing AC ). GPT3.5 is more Forgiving , less Retaliatory , and less Troublemaking than Llama3. These findings align with the higher cooperation observed in Fig. 3. Fig. 6 shows that GPT3.5 exhibits behaviors closer to the random baseline than Llama3.",
      "text": "is extremely Nice but not particularly Retaliatory and even less Forgiving . It tends to score high in Troublemaking , suggesting it often initiates unprovoked defections. Finally, it displays lower levels of emulation as \u03b1 grows (except when facing AC ). GPT3.5 is more Forgiving , less Retaliatory , and less Troublemaking than Llama3. These findings align with the higher cooperation observed in Fig. 3. Fig. 6 shows that GPT3.5 exhibits behaviors closer to the random baseline than Llama3."
    },
    {
      "self_ref": "#/texts/170",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 312.582,
            "t": 377.79701464843754,
            "r": 422.315,
            "b": 365.1150146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            14
          ]
        }
      ],
      "orig": "5. Conclusions",
      "text": "5. Conclusions",
      "level": 1
    },
    {
      "self_ref": "#/texts/171",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 312.582,
            "t": 357.1690146484375,
            "r": 538.589,
            "b": 63.00401464843753,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1026
          ]
        }
      ],
      "orig": "My study contributes to the broad literature on behavioral studies of LLMs as artificial social agents and adds a new benchmark in the body of work that explored the outcomes of iterated games. I introduce a systematic experimental setup that incorporates quantitative checks to align the LLM responses to the complex task description. I have shown that aspects like prompt comprehension, memory representation, and duration of the simulation play crucial roles, with the potential to significantly distort the experimental outcomes if left unchecked. When analyzing the behaviors displayed by the models, it emerges that they all show a propensity toward cooperation although with high variability in the approaches taken. Under conditions that disincentivize cooperation, all LLMs exhibit an initial trust in the opponent by playing GRIM instead of the human choice of AD . When the environment is more favorable to cooperative play, Llama2 and GPT3.5 tend towards a consistently cooperative approach, while Llama3 maintains",
      "text": "My study contributes to the broad literature on behavioral studies of LLMs as artificial social agents and adds a new benchmark in the body of work that explored the outcomes of iterated games. I introduce a systematic experimental setup that incorporates quantitative checks to align the LLM responses to the complex task description. I have shown that aspects like prompt comprehension, memory representation, and duration of the simulation play crucial roles, with the potential to significantly distort the experimental outcomes if left unchecked. When analyzing the behaviors displayed by the models, it emerges that they all show a propensity toward cooperation although with high variability in the approaches taken. Under conditions that disincentivize cooperation, all LLMs exhibit an initial trust in the opponent by playing GRIM instead of the human choice of AD . When the environment is more favorable to cooperative play, Llama2 and GPT3.5 tend towards a consistently cooperative approach, while Llama3 maintains"
    },
    {
      "self_ref": "#/texts/172",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_footer",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 294.926,
            "t": 34.32101464843754,
            "r": 300.35,
            "b": 24.689014648437478,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "5",
      "text": "5"
    },
    {
      "self_ref": "#/texts/173",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_header",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 70.866,
            "t": 794.1990146484375,
            "r": 178.525,
            "b": 784.5560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            17
          ]
        }
      ],
      "orig": "Executive summary",
      "text": "Executive summary"
    },
    {
      "self_ref": "#/texts/174",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_header",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 442.099,
            "t": 794.1990146484375,
            "r": 524.415,
            "b": 784.5560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            14
          ]
        }
      ],
      "orig": "Nicol\u00f2 Fontana",
      "text": "Nicol\u00f2 Fontana"
    },
    {
      "self_ref": "#/texts/175",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "caption",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 56.693,
            "t": 507.6710146484375,
            "r": 282.696,
            "b": 470.88601464843754,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            111
          ]
        }
      ],
      "orig": "Figure 5: Random , Llama3, and GPT3.5 behavioral profiles against opponents with different levels of hostility.",
      "text": "Figure 5: Random , Llama3, and GPT3.5 behavioral profiles against opponents with different levels of hostility."
    },
    {
      "self_ref": "#/texts/176",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 719.3440146484376,
            "r": 104.494,
            "b": 713.8580146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/177",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 735.8080146484375,
            "r": 104.494,
            "b": 730.3230146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/178",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 752.2730146484375,
            "r": 104.494,
            "b": 746.7870146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/179",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 88.698,
            "t": 739.4100146484375,
            "r": 95.281,
            "b": 727.0310146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "Nice",
      "text": "Nice"
    },
    {
      "self_ref": "#/texts/180",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 676.1550146484375,
            "r": 104.494,
            "b": 670.6690146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/181",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 692.6190146484375,
            "r": 104.494,
            "b": 687.1340146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/182",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 709.0840146484375,
            "r": 104.494,
            "b": 703.5980146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/183",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 88.698,
            "t": 703.0190146484375,
            "r": 95.281,
            "b": 677.0400146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            9
          ]
        }
      ],
      "orig": "Forgiving",
      "text": "Forgiving"
    },
    {
      "self_ref": "#/texts/184",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 632.9650146484375,
            "r": 104.494,
            "b": 627.4800146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/185",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 649.4300146484375,
            "r": 104.494,
            "b": 643.9450146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/186",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 665.8950146484375,
            "r": 104.494,
            "b": 660.4090146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/187",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 88.698,
            "t": 662.2200146484375,
            "r": 95.281,
            "b": 631.4460146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            11
          ]
        }
      ],
      "orig": "Retaliatory",
      "text": "Retaliatory"
    },
    {
      "self_ref": "#/texts/188",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 589.7760146484375,
            "r": 104.494,
            "b": 584.2910146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/189",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 606.2410146484375,
            "r": 104.494,
            "b": 600.7560146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/190",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 622.7050146484376,
            "r": 104.494,
            "b": 617.2200146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/191",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 88.698,
            "t": 624.3930146484375,
            "r": 95.281,
            "b": 582.9080146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            13
          ]
        }
      ],
      "orig": "Troublemaking",
      "text": "Troublemaking"
    },
    {
      "self_ref": "#/texts/192",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 110.291,
            "t": 539.8570146484375,
            "r": 117.777,
            "b": 534.3720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/193",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 122.777,
            "t": 539.8570146484375,
            "r": 130.263,
            "b": 534.3720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.1",
      "text": "0.1"
    },
    {
      "self_ref": "#/texts/194",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 135.263,
            "t": 539.8570146484375,
            "r": 142.749,
            "b": 534.3720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.2",
      "text": "0.2"
    },
    {
      "self_ref": "#/texts/195",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 147.749,
            "t": 539.8570146484375,
            "r": 155.235,
            "b": 534.3720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.3",
      "text": "0.3"
    },
    {
      "self_ref": "#/texts/196",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 160.234,
            "t": 539.8570146484375,
            "r": 167.721,
            "b": 534.3720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.4",
      "text": "0.4"
    },
    {
      "self_ref": "#/texts/197",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 172.72,
            "t": 539.8570146484375,
            "r": 180.207,
            "b": 534.3720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/198",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 185.206,
            "t": 539.8570146484375,
            "r": 192.692,
            "b": 534.3720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.6",
      "text": "0.6"
    },
    {
      "self_ref": "#/texts/199",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 197.692,
            "t": 539.8570146484375,
            "r": 205.178,
            "b": 534.3720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.7",
      "text": "0.7"
    },
    {
      "self_ref": "#/texts/200",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 210.178,
            "t": 539.8570146484375,
            "r": 217.664,
            "b": 534.3720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.8",
      "text": "0.8"
    },
    {
      "self_ref": "#/texts/201",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 222.664,
            "t": 539.8570146484375,
            "r": 230.15,
            "b": 534.3720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.9",
      "text": "0.9"
    },
    {
      "self_ref": "#/texts/202",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 235.149,
            "t": 539.8570146484375,
            "r": 242.636,
            "b": 534.3720146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/203",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 114.785,
            "t": 533.7350146484375,
            "r": 230.848,
            "b": 526.0560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            34
          ]
        }
      ],
      "orig": "Opponent cooperation probability (",
      "text": "Opponent cooperation probability ("
    },
    {
      "self_ref": "#/texts/204",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 235.194,
            "t": 533.7350146484375,
            "r": 237.765,
            "b": 526.0560146484376,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": ")",
      "text": ")"
    },
    {
      "self_ref": "#/texts/205",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 546.5870146484375,
            "r": 104.494,
            "b": 541.1020146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/206",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 563.0520146484375,
            "r": 104.494,
            "b": 557.5670146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/207",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 97.008,
            "t": 579.5160146484375,
            "r": 104.494,
            "b": 574.0310146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/208",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 88.698,
            "t": 574.6140146484375,
            "r": 95.281,
            "b": 546.3180146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            9
          ]
        }
      ],
      "orig": "Emulative",
      "text": "Emulative"
    },
    {
      "self_ref": "#/texts/209",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 125.873,
            "t": 553.8660146484375,
            "r": 146.615,
            "b": 547.2830146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Llama3",
      "text": "Llama3"
    },
    {
      "self_ref": "#/texts/210",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 170.915,
            "t": 553.8660146484375,
            "r": 193.351,
            "b": 547.2830146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            7
          ]
        }
      ],
      "orig": "GPT3.5t",
      "text": "GPT3.5t"
    },
    {
      "self_ref": "#/texts/211",
      "parent": {
        "$ref": "#/pictures/5"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 217.649,
            "t": 553.8660146484375,
            "r": 241.052,
            "b": 547.2830146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Random",
      "text": "Random"
    },
    {
      "self_ref": "#/texts/212",
      "parent": {
        "$ref": "#/pictures/6"
      },
      "children": [],
      "content_layer": "body",
      "label": "caption",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 56.693,
            "t": 336.5700146484375,
            "r": 282.695,
            "b": 313.3890146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            81
          ]
        }
      ],
      "orig": "Figure 6: Average distance of Llama3 and GPT3.5 profiles from the Random profile.",
      "text": "Figure 6: Average distance of Llama3 and GPT3.5 profiles from the Random profile."
    },
    {
      "self_ref": "#/texts/213",
      "parent": {
        "$ref": "#/pictures/6"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 108.283,
            "t": 398.5780146484375,
            "r": 125.553,
            "b": 381.3080146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            4
          ]
        }
      ],
      "orig": "nice",
      "text": "nice"
    },
    {
      "self_ref": "#/texts/214",
      "parent": {
        "$ref": "#/pictures/6"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 123.077,
            "t": 398.5890146484375,
            "r": 152.777,
            "b": 368.8900146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            9
          ]
        }
      ],
      "orig": "forgiving",
      "text": "forgiving"
    },
    {
      "self_ref": "#/texts/215",
      "parent": {
        "$ref": "#/pictures/6"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 146.178,
            "t": 398.60501464843753,
            "r": 180.005,
            "b": 364.77801464843753,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            11
          ]
        }
      ],
      "orig": "retaliatory",
      "text": "retaliatory"
    },
    {
      "self_ref": "#/texts/216",
      "parent": {
        "$ref": "#/pictures/6"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 162.293,
            "t": 398.6030146484375,
            "r": 207.216,
            "b": 353.6800146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            13
          ]
        }
      ],
      "orig": "troublemaking",
      "text": "troublemaking"
    },
    {
      "self_ref": "#/texts/217",
      "parent": {
        "$ref": "#/pictures/6"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 201.613,
            "t": 398.58101464843753,
            "r": 234.406,
            "b": 365.7880146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            9
          ]
        }
      ],
      "orig": "emulative",
      "text": "emulative"
    },
    {
      "self_ref": "#/texts/218",
      "parent": {
        "$ref": "#/pictures/6"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 89.504,
            "t": 407.62401464843754,
            "r": 101.482,
            "b": 398.8470146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.0",
      "text": "0.0"
    },
    {
      "self_ref": "#/texts/219",
      "parent": {
        "$ref": "#/pictures/6"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 89.504,
            "t": 430.51601464843753,
            "r": 101.482,
            "b": 421.7390146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "0.5",
      "text": "0.5"
    },
    {
      "self_ref": "#/texts/220",
      "parent": {
        "$ref": "#/pictures/6"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 89.504,
            "t": 453.40801464843753,
            "r": 101.482,
            "b": 444.6310146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            3
          ]
        }
      ],
      "orig": "1.0",
      "text": "1.0"
    },
    {
      "self_ref": "#/texts/221",
      "parent": {
        "$ref": "#/pictures/6"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 230.204,
            "t": 447.8900146484375,
            "r": 248.641,
            "b": 442.0390146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            6
          ]
        }
      ],
      "orig": "Llama3",
      "text": "Llama3"
    },
    {
      "self_ref": "#/texts/222",
      "parent": {
        "$ref": "#/pictures/6"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 230.204,
            "t": 440.5220146484375,
            "r": 250.147,
            "b": 434.6710146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            7
          ]
        }
      ],
      "orig": "GPT3.5t",
      "text": "GPT3.5t"
    },
    {
      "self_ref": "#/texts/223",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 56.693,
            "t": 288.1270146484376,
            "r": 282.7,
            "b": 61.653014648437534,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            792
          ]
        },
        {
          "page_no": 6,
          "bbox": {
            "l": 312.582,
            "t": 753.4080146484375,
            "r": 538.589,
            "b": 608.2840146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            793,
            1304
          ]
        }
      ],
      "orig": "an approach comparable with GRIM (unless it faces AC ). In that same context, humans play a mixture of GRIM and TFT . The results of my work are in line with early experiments involving LLMs, which indicated a tendency for these models to cooperate. However, it appears that newer models tend to behave more strategically, showing uncooperative behaviors even in highly cooperative environments. This opens the door to exploitative attitudes in LLMs, conflicting with alignment objectives. Nevertheless, it is important to acknowledge the limitations of my work. First, the pool of three LLMs used to conduct my analysis is small when compared to the pace of development of new models. Second, my study's scope was limited to opponent random strategies, a fixed payoff structure, and a single agent. Exploring the LLM's interactions under more complex conditions and within synthetic societies would enable us to better delineate their behavioral boundaries. Despite its limitations, my work expands our knowledge of the inherent biases of LLMs in social situations, crucial to informing their deployment across contexts, and provides a principled way to approach game theoretical simulations with LLMs, constituting a step forward for their use as reliable and reproducible tools to test LLMs alignment.",
      "text": "an approach comparable with GRIM (unless it faces AC ). In that same context, humans play a mixture of GRIM and TFT . The results of my work are in line with early experiments involving LLMs, which indicated a tendency for these models to cooperate. However, it appears that newer models tend to behave more strategically, showing uncooperative behaviors even in highly cooperative environments. This opens the door to exploitative attitudes in LLMs, conflicting with alignment objectives. Nevertheless, it is important to acknowledge the limitations of my work. First, the pool of three LLMs used to conduct my analysis is small when compared to the pace of development of new models. Second, my study's scope was limited to opponent random strategies, a fixed payoff structure, and a single agent. Exploring the LLM's interactions under more complex conditions and within synthetic societies would enable us to better delineate their behavioral boundaries. Despite its limitations, my work expands our knowledge of the inherent biases of LLMs in social situations, crucial to informing their deployment across contexts, and provides a principled way to approach game theoretical simulations with LLMs, constituting a step forward for their use as reliable and reproducible tools to test LLMs alignment."
    },
    {
      "self_ref": "#/texts/224",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 312.582,
            "t": 592.9740146484376,
            "r": 463.824,
            "b": 580.2920146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            18
          ]
        }
      ],
      "orig": "6. Acknowledgments",
      "text": "6. Acknowledgments",
      "level": 1
    },
    {
      "self_ref": "#/texts/225",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 312.582,
            "t": 572.3460146484375,
            "r": 538.587,
            "b": 494.96801464843753,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            245
          ]
        }
      ],
      "orig": "I would like to thank my supervisors Francesco and Luca, the NERDS group, my friends (old and new), and my family for all the support, love, and precious advice that I received. A special thanks goes to Ivano for all his assistance and patience.",
      "text": "I would like to thank my supervisors Francesco and Luca, the NERDS group, my friends (old and new), and my family for all the support, love, and precious advice that I received. A special thanks goes to Ivano for all his assistance and patience."
    },
    {
      "self_ref": "#/texts/226",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "text",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 312.582,
            "t": 491.0510146484375,
            "r": 538.589,
            "b": 400.12401464843754,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            303
          ]
        }
      ],
      "orig": "I would like to acknowledge the support from the Danish Data Science Academy through the DDSA Visit Grant (Grant ID: 2023-1856) and from Politecnico di Milano through the scholarship 'Tesi all'estero a.a. 2023/24-Primo bando'. I would like to acknowledge the aid of ChatGPT in revising the writing work.",
      "text": "I would like to acknowledge the support from the Danish Data Science Academy through the DDSA Visit Grant (Grant ID: 2023-1856) and from Politecnico di Milano through the scholarship 'Tesi all'estero a.a. 2023/24-Primo bando'. I would like to acknowledge the aid of ChatGPT in revising the writing work."
    },
    {
      "self_ref": "#/texts/227",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "section_header",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 312.582,
            "t": 384.8150146484375,
            "r": 386.224,
            "b": 372.1330146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            10
          ]
        }
      ],
      "orig": "References",
      "text": "References",
      "level": 1
    },
    {
      "self_ref": "#/texts/228",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "list_item",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 312.582,
            "t": 363.1800146484375,
            "r": 538.588,
            "b": 312.9000146484375,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            162
          ]
        }
      ],
      "orig": "[1] Akata, E., Schulz, L., Coda-Forno, J., Oh, S. J., Bethge, M., and Schulz, E. (2023). Playing repeated games with large language models. arXiv:2305.16867 [cs].",
      "text": "Akata, E., Schulz, L., Coda-Forno, J., Oh, S. J., Bethge, M., and Schulz, E. (2023). Playing repeated games with large language models. arXiv:2305.16867 [cs].",
      "enumerated": true,
      "marker": "[1]"
    },
    {
      "self_ref": "#/texts/229",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "list_item",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 312.582,
            "t": 300.01701464843745,
            "r": 538.587,
            "b": 263.28601464843746,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            120
          ]
        }
      ],
      "orig": "[2] Axelrod, R. (1980). More effective choice in the prisoner's dilemma. Journal of Conflict Resolution , 24(3):379-403.",
      "text": "Axelrod, R. (1980). More effective choice in the prisoner's dilemma. Journal of Conflict Resolution , 24(3):379-403.",
      "enumerated": true,
      "marker": "[2]"
    },
    {
      "self_ref": "#/texts/230",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "list_item",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 312.582,
            "t": 250.40301464843753,
            "r": 538.588,
            "b": 186.57401464843747,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            201
          ]
        }
      ],
      "orig": "[3] Mei, Q., Xie, Y., Yuan, W., and Jackson, M. O. (2024). A turing test of whether ai chatbots are behaviorally similar to humans. Proceedings of the National Academy of Sciences , 121(9):e2313925121.",
      "text": "Mei, Q., Xie, Y., Yuan, W., and Jackson, M. O. (2024). A turing test of whether ai chatbots are behaviorally similar to humans. Proceedings of the National Academy of Sciences , 121(9):e2313925121.",
      "enumerated": true,
      "marker": "[3]"
    },
    {
      "self_ref": "#/texts/231",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "list_item",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 312.582,
            "t": 173.69001464843745,
            "r": 538.587,
            "b": 123.41101464843746,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            173
          ]
        }
      ],
      "orig": "[4] Phelps, S. and Russell, Y. I. (2023). Investigating emergent goal-like behaviour in large language models using experimental economics. arXiv preprint arXiv:2305.07970 .",
      "text": "Phelps, S. and Russell, Y. I. (2023). Investigating emergent goal-like behaviour in large language models using experimental economics. arXiv preprint arXiv:2305.07970 .",
      "enumerated": true,
      "marker": "[4]"
    },
    {
      "self_ref": "#/texts/232",
      "parent": {
        "$ref": "#/groups/2"
      },
      "children": [],
      "content_layer": "body",
      "label": "list_item",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 312.582,
            "t": 110.52701464843756,
            "r": 538.584,
            "b": 60.24801464843756,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            156
          ]
        }
      ],
      "orig": "[5] Romero, J. and Rosokha, Y. (2018). Constructing strategies in the indefinitely repeated prisoner's dilemma game. European Economic Review , 104:185-219.",
      "text": "Romero, J. and Rosokha, Y. (2018). Constructing strategies in the indefinitely repeated prisoner's dilemma game. European Economic Review , 104:185-219.",
      "enumerated": true,
      "marker": "[5]"
    },
    {
      "self_ref": "#/texts/233",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "furniture",
      "label": "page_footer",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 294.926,
            "t": 34.32101464843754,
            "r": 300.35,
            "b": 24.689014648437478,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            1
          ]
        }
      ],
      "orig": "6",
      "text": "6"
    }
  ],
  "pictures": [
    {
      "self_ref": "#/pictures/0",
      "parent": {
        "$ref": "#/body"
      },
      "children": [],
      "content_layer": "body",
      "label": "picture",
      "prov": [
        {
          "page_no": 1,
          "bbox": {
            "l": 60.69828796386719,
            "t": 736.1587448120117,
            "r": 298.4813232421875,
            "b": 650.6030731201172,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/1",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/53"
        },
        {
          "$ref": "#/texts/54"
        },
        {
          "$ref": "#/texts/55"
        },
        {
          "$ref": "#/texts/56"
        },
        {
          "$ref": "#/texts/57"
        },
        {
          "$ref": "#/texts/58"
        },
        {
          "$ref": "#/texts/59"
        },
        {
          "$ref": "#/texts/60"
        },
        {
          "$ref": "#/texts/61"
        },
        {
          "$ref": "#/texts/62"
        },
        {
          "$ref": "#/texts/63"
        },
        {
          "$ref": "#/texts/64"
        },
        {
          "$ref": "#/texts/65"
        },
        {
          "$ref": "#/texts/66"
        },
        {
          "$ref": "#/texts/67"
        },
        {
          "$ref": "#/texts/68"
        },
        {
          "$ref": "#/texts/69"
        },
        {
          "$ref": "#/texts/70"
        },
        {
          "$ref": "#/texts/71"
        },
        {
          "$ref": "#/texts/72"
        },
        {
          "$ref": "#/texts/73"
        }
      ],
      "content_layer": "body",
      "label": "picture",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 314.37310791015625,
            "t": 754.8291778564453,
            "r": 535.0592651367188,
            "b": 647.2548675537109,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/53"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/2",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/74"
        },
        {
          "$ref": "#/texts/75"
        },
        {
          "$ref": "#/texts/76"
        },
        {
          "$ref": "#/texts/77"
        },
        {
          "$ref": "#/texts/78"
        },
        {
          "$ref": "#/texts/79"
        },
        {
          "$ref": "#/texts/80"
        },
        {
          "$ref": "#/texts/81"
        },
        {
          "$ref": "#/texts/82"
        },
        {
          "$ref": "#/texts/83"
        },
        {
          "$ref": "#/texts/84"
        },
        {
          "$ref": "#/texts/85"
        },
        {
          "$ref": "#/texts/86"
        },
        {
          "$ref": "#/texts/87"
        },
        {
          "$ref": "#/texts/88"
        },
        {
          "$ref": "#/texts/89"
        },
        {
          "$ref": "#/texts/90"
        },
        {
          "$ref": "#/texts/91"
        },
        {
          "$ref": "#/texts/92"
        },
        {
          "$ref": "#/texts/93"
        },
        {
          "$ref": "#/texts/94"
        },
        {
          "$ref": "#/texts/95"
        },
        {
          "$ref": "#/texts/96"
        },
        {
          "$ref": "#/texts/97"
        },
        {
          "$ref": "#/texts/98"
        },
        {
          "$ref": "#/texts/99"
        }
      ],
      "content_layer": "body",
      "label": "picture",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 336.6073913574219,
            "t": 578.6222229003906,
            "r": 513.3251342773438,
            "b": 450.24139404296875,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/74"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/3",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/106"
        },
        {
          "$ref": "#/texts/107"
        },
        {
          "$ref": "#/texts/108"
        },
        {
          "$ref": "#/texts/109"
        },
        {
          "$ref": "#/texts/110"
        },
        {
          "$ref": "#/texts/111"
        },
        {
          "$ref": "#/texts/112"
        },
        {
          "$ref": "#/texts/113"
        },
        {
          "$ref": "#/texts/114"
        },
        {
          "$ref": "#/texts/115"
        },
        {
          "$ref": "#/texts/116"
        },
        {
          "$ref": "#/texts/117"
        },
        {
          "$ref": "#/texts/118"
        },
        {
          "$ref": "#/texts/119"
        },
        {
          "$ref": "#/texts/120"
        },
        {
          "$ref": "#/texts/121"
        },
        {
          "$ref": "#/texts/122"
        },
        {
          "$ref": "#/texts/123"
        },
        {
          "$ref": "#/texts/124"
        },
        {
          "$ref": "#/texts/125"
        },
        {
          "$ref": "#/texts/126"
        },
        {
          "$ref": "#/texts/127"
        },
        {
          "$ref": "#/texts/128"
        }
      ],
      "content_layer": "body",
      "label": "picture",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 83.00566101074219,
            "t": 752.5105819702148,
            "r": 255.48915100097656,
            "b": 653.9422454833984,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/106"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/4",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/135"
        },
        {
          "$ref": "#/texts/136"
        },
        {
          "$ref": "#/texts/137"
        },
        {
          "$ref": "#/texts/138"
        },
        {
          "$ref": "#/texts/139"
        },
        {
          "$ref": "#/texts/140"
        },
        {
          "$ref": "#/texts/141"
        },
        {
          "$ref": "#/texts/142"
        },
        {
          "$ref": "#/texts/143"
        },
        {
          "$ref": "#/texts/144"
        },
        {
          "$ref": "#/texts/145"
        },
        {
          "$ref": "#/texts/146"
        },
        {
          "$ref": "#/texts/147"
        },
        {
          "$ref": "#/texts/148"
        },
        {
          "$ref": "#/texts/149"
        },
        {
          "$ref": "#/texts/150"
        },
        {
          "$ref": "#/texts/151"
        },
        {
          "$ref": "#/texts/152"
        },
        {
          "$ref": "#/texts/153"
        },
        {
          "$ref": "#/texts/154"
        },
        {
          "$ref": "#/texts/155"
        },
        {
          "$ref": "#/texts/156"
        },
        {
          "$ref": "#/texts/157"
        },
        {
          "$ref": "#/texts/158"
        },
        {
          "$ref": "#/texts/159"
        },
        {
          "$ref": "#/texts/160"
        },
        {
          "$ref": "#/texts/161"
        },
        {
          "$ref": "#/texts/162"
        },
        {
          "$ref": "#/texts/163"
        },
        {
          "$ref": "#/texts/164"
        },
        {
          "$ref": "#/texts/165"
        },
        {
          "$ref": "#/texts/166"
        },
        {
          "$ref": "#/texts/167"
        },
        {
          "$ref": "#/texts/168"
        }
      ],
      "content_layer": "body",
      "label": "picture",
      "prov": [
        {
          "page_no": 5,
          "bbox": {
            "l": 338.3369445800781,
            "t": 753.0725173950195,
            "r": 511.3443908691406,
            "b": 617.9476470947266,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/135"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/5",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/175"
        },
        {
          "$ref": "#/texts/176"
        },
        {
          "$ref": "#/texts/177"
        },
        {
          "$ref": "#/texts/178"
        },
        {
          "$ref": "#/texts/179"
        },
        {
          "$ref": "#/texts/180"
        },
        {
          "$ref": "#/texts/181"
        },
        {
          "$ref": "#/texts/182"
        },
        {
          "$ref": "#/texts/183"
        },
        {
          "$ref": "#/texts/184"
        },
        {
          "$ref": "#/texts/185"
        },
        {
          "$ref": "#/texts/186"
        },
        {
          "$ref": "#/texts/187"
        },
        {
          "$ref": "#/texts/188"
        },
        {
          "$ref": "#/texts/189"
        },
        {
          "$ref": "#/texts/190"
        },
        {
          "$ref": "#/texts/191"
        },
        {
          "$ref": "#/texts/192"
        },
        {
          "$ref": "#/texts/193"
        },
        {
          "$ref": "#/texts/194"
        },
        {
          "$ref": "#/texts/195"
        },
        {
          "$ref": "#/texts/196"
        },
        {
          "$ref": "#/texts/197"
        },
        {
          "$ref": "#/texts/198"
        },
        {
          "$ref": "#/texts/199"
        },
        {
          "$ref": "#/texts/200"
        },
        {
          "$ref": "#/texts/201"
        },
        {
          "$ref": "#/texts/202"
        },
        {
          "$ref": "#/texts/203"
        },
        {
          "$ref": "#/texts/204"
        },
        {
          "$ref": "#/texts/205"
        },
        {
          "$ref": "#/texts/206"
        },
        {
          "$ref": "#/texts/207"
        },
        {
          "$ref": "#/texts/208"
        },
        {
          "$ref": "#/texts/209"
        },
        {
          "$ref": "#/texts/210"
        },
        {
          "$ref": "#/texts/211"
        }
      ],
      "content_layer": "body",
      "label": "picture",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 87.72206115722656,
            "t": 752.881965637207,
            "r": 245.8217010498047,
            "b": 525.6687927246094,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/175"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    },
    {
      "self_ref": "#/pictures/6",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/212"
        },
        {
          "$ref": "#/texts/213"
        },
        {
          "$ref": "#/texts/214"
        },
        {
          "$ref": "#/texts/215"
        },
        {
          "$ref": "#/texts/216"
        },
        {
          "$ref": "#/texts/217"
        },
        {
          "$ref": "#/texts/218"
        },
        {
          "$ref": "#/texts/219"
        },
        {
          "$ref": "#/texts/220"
        },
        {
          "$ref": "#/texts/221"
        },
        {
          "$ref": "#/texts/222"
        }
      ],
      "content_layer": "body",
      "label": "picture",
      "prov": [
        {
          "page_no": 6,
          "bbox": {
            "l": 88.16964721679688,
            "t": 453.3059387207031,
            "r": 255.87518310546875,
            "b": 355.35845947265625,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/212"
        }
      ],
      "references": [],
      "footnotes": [],
      "annotations": []
    }
  ],
  "tables": [
    {
      "self_ref": "#/tables/0",
      "parent": {
        "$ref": "#/body"
      },
      "children": [
        {
          "$ref": "#/texts/49"
        }
      ],
      "content_layer": "body",
      "label": "table",
      "prov": [
        {
          "page_no": 4,
          "bbox": {
            "l": 56.01640701293945,
            "t": 756.7213592529297,
            "r": 289.3582763671875,
            "b": 500.4684143066406,
            "coord_origin": "BOTTOMLEFT"
          },
          "charspan": [
            0,
            0
          ]
        }
      ],
      "captions": [
        {
          "$ref": "#/texts/49"
        }
      ],
      "references": [],
      "footnotes": [],
      "data": {
        "table_cells": [
          {
            "bbox": {
              "l": 80.295,
              "t": 86.99699999999996,
              "r": 112.177,
              "b": 96.63999999999999,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "Name",
            "column_header": true,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 185.704,
              "t": 86.99699999999996,
              "r": 234.067,
              "b": 96.63999999999999,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 0,
            "end_row_offset_idx": 1,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "Question",
            "column_header": true,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 80.295,
              "t": 101.80700000000002,
              "r": 119.752,
              "b": 110.894,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "min_max",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 134.77,
              "t": 100.95600000000002,
              "r": 285.01,
              "b": 137.68600000000004,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 1,
            "end_row_offset_idx": 2,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "What is the lowest/highest pay- off player A can get in a single round?",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 80.295,
              "t": 142.45399999999995,
              "r": 119.752,
              "b": 151.54099999999994,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "actions",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 134.77,
              "t": 141.60299999999995,
              "r": 285.006,
              "b": 164.784,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 2,
            "end_row_offset_idx": 3,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "Which actions is player A al- lowed to play?",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 80.295,
              "t": 169.553,
              "r": 114.115,
              "b": 178.64,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "payoff",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 134.77,
              "t": 168.702,
              "r": 285.007,
              "b": 205.43200000000002,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 3,
            "end_row_offset_idx": 4,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "Which is player X's payoff in a single round if X plays p and Y plays q ?",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 80.295,
              "t": 210.59899999999993,
              "r": 108.479,
              "b": 219.68600000000004,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 4,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "round",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 134.77,
              "t": 209.74799999999993,
              "r": 285.01,
              "b": 232.92899999999997,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 4,
            "end_row_offset_idx": 5,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "Which is the current round of the game?",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 80.295,
              "t": 237.697,
              "r": 117.001,
              "b": 247.51999999999998,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 5,
            "end_row_offset_idx": 6,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "action i",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 134.77,
              "t": 236.846,
              "r": 285.003,
              "b": 260.02699999999993,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 5,
            "end_row_offset_idx": 6,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "Which action did player X play in round i ?",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 80.295,
              "t": 264.79499999999996,
              "r": 117.001,
              "b": 274.619,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 6,
            "end_row_offset_idx": 7,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "points i",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 134.77,
              "t": 263.94399999999996,
              "r": 284.15,
              "b": 287.126,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 6,
            "end_row_offset_idx": 7,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "How many points did player X collect in round i ?",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 80.295,
              "t": 292.29200000000003,
              "r": 125.389,
              "b": 301.379,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 7,
            "end_row_offset_idx": 8,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "#actions",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 134.77,
              "t": 291.44100000000003,
              "r": 284.15,
              "b": 314.62299999999993,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 7,
            "end_row_offset_idx": 8,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "How many times did player X choose p ?",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 80.295,
              "t": 319.39099999999996,
              "r": 119.752,
              "b": 328.47799999999995,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 8,
            "end_row_offset_idx": 9,
            "start_col_offset_idx": 0,
            "end_col_offset_idx": 1,
            "text": "#points",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          },
          {
            "bbox": {
              "l": 134.77,
              "t": 318.53999999999996,
              "r": 285.007,
              "b": 341.721,
              "coord_origin": "TOPLEFT"
            },
            "row_span": 1,
            "col_span": 1,
            "start_row_offset_idx": 8,
            "end_row_offset_idx": 9,
            "start_col_offset_idx": 1,
            "end_col_offset_idx": 2,
            "text": "What is player X 's current total payoff?",
            "column_header": false,
            "row_header": false,
            "row_section": false,
            "fillable": false
          }
        ],
        "num_rows": 9,
        "num_cols": 2,
        "grid": [
          [
            {
              "bbox": {
                "l": 80.295,
                "t": 86.99699999999996,
                "r": 112.177,
                "b": 96.63999999999999,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "Name",
              "column_header": true,
              "row_header": false,
              "row_section": false,
              "fillable": false
            },
            {
              "bbox": {
                "l": 185.704,
                "t": 86.99699999999996,
                "r": 234.067,
                "b": 96.63999999999999,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 0,
              "end_row_offset_idx": 1,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "Question",
              "column_header": true,
              "row_header": false,
              "row_section": false,
              "fillable": false
            }
          ],
          [
            {
              "bbox": {
                "l": 80.295,
                "t": 101.80700000000002,
                "r": 119.752,
                "b": 110.894,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "min_max",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            },
            {
              "bbox": {
                "l": 134.77,
                "t": 100.95600000000002,
                "r": 285.01,
                "b": 137.68600000000004,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 1,
              "end_row_offset_idx": 2,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "What is the lowest/highest pay- off player A can get in a single round?",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            }
          ],
          [
            {
              "bbox": {
                "l": 80.295,
                "t": 142.45399999999995,
                "r": 119.752,
                "b": 151.54099999999994,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "actions",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            },
            {
              "bbox": {
                "l": 134.77,
                "t": 141.60299999999995,
                "r": 285.006,
                "b": 164.784,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 2,
              "end_row_offset_idx": 3,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "Which actions is player A al- lowed to play?",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            }
          ],
          [
            {
              "bbox": {
                "l": 80.295,
                "t": 169.553,
                "r": 114.115,
                "b": 178.64,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "payoff",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            },
            {
              "bbox": {
                "l": 134.77,
                "t": 168.702,
                "r": 285.007,
                "b": 205.43200000000002,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 3,
              "end_row_offset_idx": 4,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "Which is player X's payoff in a single round if X plays p and Y plays q ?",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            }
          ],
          [
            {
              "bbox": {
                "l": 80.295,
                "t": 210.59899999999993,
                "r": 108.479,
                "b": 219.68600000000004,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 4,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "round",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            },
            {
              "bbox": {
                "l": 134.77,
                "t": 209.74799999999993,
                "r": 285.01,
                "b": 232.92899999999997,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 4,
              "end_row_offset_idx": 5,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "Which is the current round of the game?",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            }
          ],
          [
            {
              "bbox": {
                "l": 80.295,
                "t": 237.697,
                "r": 117.001,
                "b": 247.51999999999998,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 5,
              "end_row_offset_idx": 6,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "action i",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            },
            {
              "bbox": {
                "l": 134.77,
                "t": 236.846,
                "r": 285.003,
                "b": 260.02699999999993,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 5,
              "end_row_offset_idx": 6,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "Which action did player X play in round i ?",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            }
          ],
          [
            {
              "bbox": {
                "l": 80.295,
                "t": 264.79499999999996,
                "r": 117.001,
                "b": 274.619,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 6,
              "end_row_offset_idx": 7,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "points i",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            },
            {
              "bbox": {
                "l": 134.77,
                "t": 263.94399999999996,
                "r": 284.15,
                "b": 287.126,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 6,
              "end_row_offset_idx": 7,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "How many points did player X collect in round i ?",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            }
          ],
          [
            {
              "bbox": {
                "l": 80.295,
                "t": 292.29200000000003,
                "r": 125.389,
                "b": 301.379,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 7,
              "end_row_offset_idx": 8,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "#actions",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            },
            {
              "bbox": {
                "l": 134.77,
                "t": 291.44100000000003,
                "r": 284.15,
                "b": 314.62299999999993,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 7,
              "end_row_offset_idx": 8,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "How many times did player X choose p ?",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            }
          ],
          [
            {
              "bbox": {
                "l": 80.295,
                "t": 319.39099999999996,
                "r": 119.752,
                "b": 328.47799999999995,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 8,
              "end_row_offset_idx": 9,
              "start_col_offset_idx": 0,
              "end_col_offset_idx": 1,
              "text": "#points",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            },
            {
              "bbox": {
                "l": 134.77,
                "t": 318.53999999999996,
                "r": 285.007,
                "b": 341.721,
                "coord_origin": "TOPLEFT"
              },
              "row_span": 1,
              "col_span": 1,
              "start_row_offset_idx": 8,
              "end_row_offset_idx": 9,
              "start_col_offset_idx": 1,
              "end_col_offset_idx": 2,
              "text": "What is player X 's current total payoff?",
              "column_header": false,
              "row_header": false,
              "row_section": false,
              "fillable": false
            }
          ]
        ]
      },
      "annotations": []
    }
  ],
  "key_value_items": [],
  "form_items": [],
  "pages": {
    "1": {
      "size": {
        "width": 595.2760009765625,
        "height": 841.8900146484375
      },
      "page_no": 1
    },
    "2": {
      "size": {
        "width": 595.2760009765625,
        "height": 841.8900146484375
      },
      "page_no": 2
    },
    "3": {
      "size": {
        "width": 595.2760009765625,
        "height": 841.8900146484375
      },
      "page_no": 3
    },
    "4": {
      "size": {
        "width": 595.2760009765625,
        "height": 841.8900146484375
      },
      "page_no": 4
    },
    "5": {
      "size": {
        "width": 595.2760009765625,
        "height": 841.8900146484375
      },
      "page_no": 5
    },
    "6": {
      "size": {
        "width": 595.2760009765625,
        "height": 841.8900146484375
      },
      "page_no": 6
    }
  }
}