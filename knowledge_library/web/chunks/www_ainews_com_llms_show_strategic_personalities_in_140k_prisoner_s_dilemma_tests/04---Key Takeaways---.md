## **Key Takeaways:**
  * Researchers conducted 140,000 rounds of the Prisoner’s Dilemma, pitting Gemini, Claude, and OpenAI’s models against each other.
  * Each model generated written justifications before decisions, revealing pattern analysis and match-ending probability calculations that influenced their choices. 
  * Gemini acted ruthlessly adaptive; OpenAI’s models leaned cooperative even under exploitation. 
  * OpenAI’s ChatGPT models favored long-term cooperation, even when short-term betrayal would have yielded higher payoffs.
  * Anthropic’s Claude demonstrated the highest level of forgiveness after betrayals. 
  * Distinct strategic “fingerprints” emerge across models, suggesting evolving reasoning abilities. 
  * As LLMs take on tasks like negotiations and resource allocation, their unique strategies could dramatically shape outcomes.
